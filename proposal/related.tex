\chapter{Related Work}
\label{chap:related}

This chapter provides a brief tour of the related work.

\section{History of Stateless Model Checking}

{\bf Hall of Fame.}
Stateless model checking dates back to Verisoft \cite{verisoft}, the 1997 tool which first attempted to exhaustively explore the possibile ways to interleave threads.
Since then, researchers have built many tools along the same lines to test many kinds of programs.
%list of mcs follows
The most popular model checker, according to citation count, is Microsoft Research's CHESS \cite{chess},
a checker for userspace C++ programs which preempts at synchronization APIs.
%which introduced the Iterative Context Bounding technique \cite{chess-icb} for heuristically ordering the search to uncover bugs faster.
%
Other checkers include MaceMC \cite{macemc}, MoDist \cite{modist}, SAMC \cite{samc}, ETA \cite{dbug-retreat},
each of which limit thread communication to the boundaries of a message-passing API;
%
dBug \cite{dbug-ssv}, another CMU original, similar to CHESS;
%
and finally SPIN \cite{spin} and Inspect \cite{inspect} which can preempt at any shared variable access.
%
Perhaps by now, Landslide itself deserves a spot on this list: I first introduced it in my MS thesis \cite{landslide},
and it is most notable for checking all shared memory accesses and supporting kernel-level code through the use of a simulator.

{\bf Search Strategies}
To date a number of techniques have been proposed to mitigate exponential explosion, the Sisyphean rock of stateless model checkers.
Dynamic Partial Order Reduction (DPOR) \cite{dpor}, the baseline approach, prunes redundant interleavings by identifying independent thread transitions which can commute without changing the program state.
It is a {\em sound} reduction algorithm, meaning it will never fail to test a possible program behavior, despite skipping many execution sequences.
DPOR has since been extended in several ways:
a provably optimal version which guarantees to explore no more than one interleaving from each equivalence class \cite{optimal-dpor},
% TODO: a 3rd example?
and an extension of the algorithm to include nondeterminism arising from weak memory models \cite{tsopso}.
Recently, SATCheck and Maximal Causality Reduction have emerged as better-performing alternatives to DPOR.
These algorithms use SMT solvers \cite{z3} to identify additional equivalences by analyzing the values read and written by each memory access.

{\bf Other theoretical advances.}
A number of other techniques address the problem that even with DPOR, a state space may be too large.
Iterative Context Bounding (ICB) \cite{chess-icb} is a search ordering heuristic which prioritizes interleavings with fewer preemptions,
according to the insight that most bugs require fewer preemptions to expose.
Bounded Partial Order Reduction \cite{bpor} adapts DPOR to be soundly compatible with ICB.
Preemption Sealing \cite{sealing} allows programmers to exclude preemption points arising from trusted source code modules,
reducing the state space by limiting the scope of the test.
Probabilistic Concurrency Testing \cite{randomized-scheduler} eschews DPOR's depth-first approach entirely (as well as any potential for completing the state space), randomly sampling a broad cross-section of the state space and providing probabilistic bounds on uncovering bugs.

\section{Concurrency in Education}

I built Landslide upon the Pebbles \cite{kspec} curriculum and concurrency model, naturally, as it is closest to home. % but also, it's the best.
Pintos \cite{pintos} has recently emerged as the most popular educational kernel
(by count of top CS schools in the USA who teach by it);
it trades off the prevalence of its concurrency challenges to cover various OS topics more broadly,
especially advanced scheduling algorithms.
Pintos is the stand-alone evolution of its predecessor, Nachos \cite{nachos}, which originally ran as a UNIX process with simulated device drivers.
%
Xv6 \cite{xv6}, from MIT, is another major educational kernel, which is also UNIX-like and runs in QEMU,
and a natural target for model checking in future work.
Recently, Columbia introduced a new Android-focused OS course \cite{teaching-android},
which perhaps highlights the importance of related work on model-checking event-driven applications \cite{r4}.

To my knowledge, this is the first study of model checking in an educational setting, although teaching concurrency is not itself an unstudied problem.
Eytani et al.~\cite{towards-a-framework} present a promising framework for testing concurrent programs,
which can incorporate model checking as well as static analysis, resource exhaustion, data-race analysis, and coverage analysis.
However, it lacks an evaluation, and makes mention of its educational value only in its future work remarks.
%
L\"{o}nnberg et al.~\cite{how-studence} present a survey of how students think about concurrent program behaviour and debugging,
while Kolikant \cite{learning-concurrency} investigates how students form cognitive patterns about concurrent programming that could either aid or stunt their reasoning.
Both of these studies could help optimize Landslide's bug reports for clarity and student enlightenment.


\section{Other Concurrency Techniques}

Data race analysis, originating with the lockset-only analysis of Eraser \cite{eraser},
has since grown into a mature field.
Race detectors are largely distinguished by their particular flavour of the Happens-Before (HB) relation:
some tools \cite{fasttrack,djit} soundly avoid false positives using ``Pure'' HB in the Lamport sense \cite{lamport-clocks};
others \cite{tsan,hybriddatarace} introduced the ``Limited'' HB relation to find more potential races in a single pass.
I implemented both approaches in Landslide and evaluated their trade-offs in Section~\ref{sec:quicksand-eval}.
%
Recently, the Causally-Precedes relation \cite{predictive-dr} emerged as a refinement of Limited HB which avoids the most common cases of false positives; it would be a welcome enhancement in Landslide.

Replay analysis extends single-pass data-race analysis to apply model checking (in limited quantities) to classify data-race candidates by their impact on program behaviour.
It was first introduced by Narayanasamy et al.~\cite{recordreplaydrs}, which compares the program states immediately after the access pair for differences, preferring still to err on the side of false positives.
RaceFuzzer \cite{racefuzzer} avoids false positives by requiring an actual failure be exhibited, as we do,
although it uses random schedule fuzzing rather than model checking.
%
Portend \cite{portend} is closest in spirit to Quicksand:
it tests alternate executions based on single-pass data-race candidates to classify them in a taxonomy of likely severity.
It uses symbolic execution to test input nondeterminism as well as schedule nondeterminism,
although its verification properties are not as strong as Quicksand's.

% TODO: Devote a paragraph to symbolic execution, including mention of e.g. concolic testing. Cite klee, z3, etc.

\section{Transactional Memory}
\label{sec:related-tm}

Transactional memory (TM), first introduced in 1993 \cite{transactional-memory},
has received renewed attention in recent years with the announcement of Intel's Haswell architecture \cite{htm-haswell},
which supports hardware transactions using new x86 instructions.
Because hardware transactions can fail for any reason, not just on memory conflicts,
software TM remains relevant,
and recent works \cite{hybrid-htm-stm,stm-relaxed-memory} enhance it to be nested with hardware transactions, or to be used on weak memory architectures, respectively;
which in turn produce ever more complicated concurrency models for people like me to tackle.
%
Testing approaches for transactional programs are sparsely represented in the literature so far.
%The Weakest Reasonable Condition
Several related works \cite{tm-correctness,tm-completeness,specifying-verifying-tm} are building up to formal proofs of the correctness of TM {\em implementations},
but not that of client programs which use TM.
SI-TM \cite{si-tm} introduces techniques for reducing HTM's abort rates, but without fully eliminating aborts, MCs must still consider them possible anywhere.
Getting closer, McRT STM \cite{mc-tm-with-spin} uses SPIN \cite{spin} to model check an STM implementation
up to 2 threads running 1 transaction each with up to 3 memory accesses.
This kind of verification is an important stepping stone for trusting the results Landslide will provide.
% TODO: make this point once you've added discussion of mutex_test to chap:quicksand.
% This kind of verification is analogous to the {\tt mutex\_test}
%
{\em Learning from Mistakes} \cite{learning-from-mistakes} studies the characteristics of many types of concurrency bugs;
it found that TM could potentially fix some, but not all, of the studied bugs,
although in some cases it must be combined with other concurrency primitives,
which indicates a major need for verifying transactional code with model checking.
