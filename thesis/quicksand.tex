% TODO: scan for abbrs like PP, MC, SSS-MC - well mc is ok but rephrase if necessary anyway
\chapter{Quicksand}
\label{chap:quicksand}

% https://tex.stackexchange.com/questions/186746/define-shearbox-with-rotatebox-and-scalebox
\newcommand\xshearbox[2]{%
  \FPeval{\sheark}{(root(2,(#1)*(#1)+4)+#1)/2}\FPeval{\shearl}{1/\sheark}%
  \FPeval{\sheara}{arctan(-\sheark)*180/pi}\FPeval{\shearb}{90+\sheara}%
  \rotatebox{\shearb}{\scalebox{\sheark}[\shearl]{{\rotatebox{\sheara}{\smash{#2}}}}}%
}

\inspirationalquote{
% original - on second thought, i'm not actually gonna put this in
% the nuance in japanese is more desperate, more disorganized, and less generally heroic-seeming
% i think the english translation actually works better for an inspirational quote
%{\footnotesize 嫌な事も悲しい事もあったけど、守りたい物だってたくさんこの世界にはあったから。} \\
There are awful, sad things in this world.
But there are a lot of things worth protecting, too.
}
%{Kaname Madoka, Mahou Shoujo Madoka{\raisebox{0.1em}{$\scriptstyle \bigstar$}}Magica}
{Kaname Madoka, Puella Magi Madoka{\raisebox{0.1em}{\scalebox{0.65}{\xshearbox{0.25}{$\bigstar$}}}}Magica}
%\inspirationalquote{Always, somewhere, someone is fighting for you.
%As long as you remember her, you are not alone.}
%{Mahou Shoujo Madoka{\raisebox{0.1em}{$\scriptstyle \bigstar$}}Magica}

\vspace{2em}
\qrevision{There is a fundamental disconnect between existing stateless model checkers
and human users
when it comes to testing concurrent code meaningfully within a fixed CPU budget.
Existing tools
%are configured to
test systems according to a fixed preemption strategy,
leading to runtime dependent entirely on the complexity of the test program,
which may range from minutes to tens of thousands of years.
Meanwhile, users approach testing with a finite amount of patience,
%usually in the rough order of magnitude of a day:
usually not varying from one test cycle to another as their code changes and evolves:
students frantically testing last-minute changes facing a project deadline
will likely wait no longer than an hour for test results,
while a company preparing its product for production deployment % its, not their. companies arent people :triumph:
may spend upwards of weeks on rigorous stability testing.
Regardless of the use case,
a stateless model checker committing in advance to test whichever single state space arises from its fixed strategy
is certain to either under- or over-shoot its user's needs.
A model checker which preempts the system too often will fail to complete the test in time,
and one which preempts infrequently enough to complete with time to spare will leave the user wondering if it overlooked any bugs.

This chapter presents Quicksand,
an execution framework for model checking to manage this trade-off at run-time.
Given a fixed CPU budget,
representing the user's patience for testing,
Quicksand dynamically alters its preemption strategy based on data race analysis
(\cite{tsan,fasttrack}, \cref{sec:landslide-datarace})
and optimizes the size of state spaces on the fly,
guided by state space estimation
(\cite{estimation}, \cref{sec:landslide-estimate}),
to best match that budget.
I will discuss the trade-off inherent in number of preemption points used
(\cref{sec:quicksand-motivation}),
introduce {\em Iterative Deepening},
the algorithm that Quicksand uses to automatically navigate that trade-off
(\cref{sec:quicksand-id}),
prove its soundness relative to the more expensive full verification approach
(\cref{sec:quicksand-soundness}),
and present a large evaluation of Quicksand against several
state-of-the-art approaches % implemented under Landslide
in which Quicksand performs best on both bug-finding and verification
(\cref{sec:quicksand-eval}).
% justifying the claim that model checkers should navigate said tradeoff at runtime
}

The contributions of this chapter were published as
{\em Stateless Model Checking with Data-Race Preemption Points}
in OOPSLA 2016 \cite{quicksand}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}
\label{sec:quicksand-motivation}

\qrevision{When configuring a model checker's preemption strategy,
or indeed,
choosing a model checker to begin with,
the resulting state space is {\em parameterized} by the set of preemption points.
%
In the first example of \Cref{fig:tree}
I constructed the state space by expanding both threads' {\tt x++} operations into three pseudo-assembly instructions,
then designating every instruction as a possible preemption point,
yielding ${3+3 \choose 3} = 20$ total interleavings.
Later, \cref{sec:landslide-dpor} showed that DPOR prunes 16 of those as equivalent,
although the reduced state space size is still combinatorial
in the number of {\em conflicting} events, rather than the total number.
For larger tests, %with hundreds or thousands of conflicting events in any given execution,
committing in advance to test all possible interleavings quickly becomes impractical.
Accordingly, many existing model checkers opt for preempting on only a subset of execution events,
such as synchronization API boundaries.

\subsection{Preemption points}
\label{sec:quicksand-pps}

Consider the new example program in \Cref{fig:pps-example}(a),
in which one thread protects its accesses to {\tt count} with a mutex,
while the other protects its accesses with atomic increment instructions.
Assuming {\tt count} is only ever incremented, never decremented,
the assertion in Thread 2 expects both of its preceding increments to be visible,
no matter how many other threads come incrementing % incrementしてくる
{\tt count} simultaneously.
However, this assumes any other accesses to {\tt count} use the same protection mechanism,
i.e., {\tt atomic\_xadd()},
but since Thread 1 uses a mutex (which Thread 2 never touches),
the threads can interleave to cause the assert to fail,
as shown in \Cref{fig:pps-example}(b).
%
\Cref{fig:pps-statespace} shows the resulting state space
supposing the model checker preempts only on synchronization APIs.%
\footnote{Most modern C/C++ programs invoke atomic memory instructions by using compiler intrinsics,
which could themselves be instrumented as a known synchronization API.
However, not all programs are guaranteed to use well-understood interfaces;
in fact, in the 15-410 class projects to be tested in the upcoming evaluation (\cref{sec:quicksand-eval-suite}),
students are encouraged to roll their own atomics to get more experience writing x86 assembly.
For the sake of this example, I leave {\tt atomic\_xadd()} uninstrumented.}
However, \Cref{fig:pps-example}(b)'s interleaving involves
preempting Thread 1 between its load and store of {\tt count},
which is not a known synchronization call, but rather a data race.
Hence, none of the interleavings in \Cref{fig:pps-statespace}'s state space
will expose the failure;
a {\em data-race preemption point} is required to find this bug.

\begin{figure}[t]
	\begin{center}
		\begin{tabular}{p{0.91\textwidth}} % dont hyphenate 'overwrite'
			\begin{center}
			\begin{tabular}{rlcrl}
				\multicolumn{5}{c}{Initially {\tt int count = \const{0}; mutex\_t m;}} \\
				\\
				& {\bf Thread 1} & & & {\bf Thread 2} \\
				\hline
				11 & \texttt{\hilight{darkorange}{mutex\_lock}(\&m);} & &
						21 & \texttt{atomic\_xadd(\&count, \const{1});} \\
				12 & \texttt{count++;}                                & &
						22 & \texttt{\hilight{olivegreen}{yield}();} \\
				13 & \texttt{\hilight{darkblue}{mutex\_unlock}(\&m);} & &
						23 & \texttt{atomic\_xadd(\&count, \const{1});} \\
				14 & \texttt{assert(count >= \const{1});}             & &
						24 & \texttt{assert(count >= \const{2});} \\
			\end{tabular}
			\end{center}
			\\
			\begin{center}
			(a) Example program with synchronization API calls highlighted.
			\end{center}
			\\
			\begin{center}
			\begin{tabular}{llllc}
				& {\bf Thread 1} & & {\bf Thread 2} & {\bf Value of {\tt count}} \\
				\hline
				11 & \texttt{\hilight{darkorange}{mutex\_lock}(\&m);} & & & 0 \\
				12a & \texttt{int tmp = count;} & & & 0 \\
							& & 21 & \texttt{atomic\_xadd(\&count, \const{1});} & 1 \\
							& & 22 & \texttt{\hilight{olivegreen}{yield}();} & 1 \\
							& & 23 & \texttt{atomic\_xadd(\&count, \const{1});} & 2 \\
				12b & \texttt{count = tmp + 1;} & & & 1 \\
				13 & \texttt{\hilight{darkblue}{mutex\_unlock}(\&m);} & & & 1 \\
				14 & \texttt{assert(count >= \const{1});} & & & 1 \\
							& & 24 & \texttt{\hilight{assertfail}{assert(count >= 2);}} & 1 \\
			\end{tabular}
			\end{center}
			\\
			%(b) Interleaving of (a) in which Thread 2's assertion fails,
			%as the single increment of Thread 1 overwrites both those of Thread 2.
			(b) Buggy interleaving of (a) in which
			the single increment of Thread 1 overwrites both those of Thread 2.
			Note the data-race preemption at 12a-12b.
		\end{tabular}
	\end{center}
	\caption[Example bug requiring data-race preemption points to expose.]
	{Example bug requiring data-race preemption points to expose.
	Because the two threads use different modes of synchronization to protect their respective accesses to {\tt count},
	preempting on synchronization calls alone is insufficient to expose the bug.
	Rather, Thread 1 must be preempted between its non-atomic load and store of {\tt count}.
	}
	\label{fig:pps-example}
\end{figure}

\begin{figure}[ht!] % TODO: check placement
	\begin{center}
		\includegraphics[width=0.98\textwidth]{dr-statespace.pdf}
	\end{center}
	\caption[State space of \Cref{fig:pps-example} with synchronization preemption points only.]
	{State space of \Cref{fig:pps-example} with synchronization preemption points only.
	Note that none of these interleavings preempt Thread 1 at the necessary place (between 12a and 12b)
	to trigger Thread 2's assertion failure.}
	\label{fig:pps-statespace}
\end{figure}
}

\qrevisionminor{How should a model checker know to instrument this particular data race for preemption
in order to find the assertion failure lurking underneath?}
Committing in advance to
preempt on every instruction is certain to include this data race,
but invites massive state space explosion.
Even as DPOR helps to skip equivalent interleavings of non-conflicting transitions,
DPOR itself is $O(n^2)$ in the number of preemption points in a single execution,
which is not compatible with such an approach.
Accordingly, stateless model checkers must find more efficient ways to be able to uncover bugs such as these.
%
In related work,
Portend~\cite{portend} proposed to combine data race analysis with preemption-driven artificial scheduling,
although it obtains its data race candidates from a stand-alone, single-pass analysis.
In order to
%make sure we
identify every
%one of a program's
data race that could possibly arise under the given test case,
a model checker must check many different interleavings to begin with,
perform the Portend approach for every data race it finds,
which may in turn uncover more data races
(hidden in flow control paths reachable only through interleavings of the first race, perhaps),
and then continue model checking those multiple races together
in a
%sort of
bidirectional feedback loop between the two algorithms.
Upcoming,
\cref{sec:quicksand-id} will show how I achieve this in Quicksand, and
\cref{sec:quicksand-soundness} will justify the technique's formal verification power.
In the evaluation, %(\cref{sec:quicksand-eval}),
\qrevisionminor{\cref{sec:quicksand-eval-bugs} and \cref{sec:quicksand-eval-verif}
will show that Quicksand strikes a healthy balance between fast bug-finding and full verification,
and
\cref{sec:quicksand-eval-nondets}
%in particular
will justify the need
for such a feedback loop %between model checking and data race analysis.
by showing that many
data races require model checking to reliably detect.
%bugs require nondeterministic data races to expose.
}

\subsection{Terminology}
\label{sec:quicksand-terminology}

\qrevision{For the rest of this chapter, I will use the following terminology as shorthand for the concepts explained above.

\begin{itemize}
	\item {\bf Single-state-space model checking} refers to the state-of-the-art model checking strategy,
		i.e., approaching each test with preemption points fixed in advance.
	\item {\bf Maximal state space} refers to the set of thread interleavings possible
		by preempting on all currently-known preemption points,
		whether synchronization or data-race,
		i.e., the singular state space tested by {\em single-state-space model checking}.
	\item {\bf Minimal state space} indicates the opposite:
		those thread interleavings requiring no more than Landslide's mandatory preemptions on voluntary context switches.
	\item {\bf Data-race bug}
		will refer to a concrete failure, such as \Cref{fig:pps-example}'s assertion failure above, whereas
	\item {\bf Data race} refers to the racing access pair itself (\cref{sec:landslide-datarace}).
	\item {\bf Data race candidate} shall refer specifically to
		potentially-racing accesses identified by Limited Happens-Before, %(\cref{sec:landslide-lhb}), % sub sub sec
		when disambiguation with {\em data races} is necessary.
	\item {\bf Data-race preemption point}
		denotes a custom model checker configuration,
		issued after finding a {\em data race},
		requesting it to preempt each involved thread just before its racing memory access
		(\cref{sec:quicksand-dr-pps}).
	\item {\bf Benign data races} are those that, when reordered in an alternate interleaving,
		do not lead to a {\em data-race bug}, while
	\item {\bf False positives} are {\em data race candidates} that,
		upon trying to reorder them,
		turn out not to exist in the alternate interleaving at all,
		such as in \Cref{fig:hb-example}(b).
	\item {\bf Nondeterministic data race}
		will refer to data races that cannot be exposed on the first thread interleaving,
		but require model checking to expose to begin with.
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Iterative Deepening}
\label{sec:quicksand-id}

To address the problem of choosing meaningful preemption points,
I have developed an algorithm called {\em Iterative Deepening},
implemented in a wrapper program specific to Landslide called {\em Quicksand}.
Named after the analogous technique in chess artificial intelligence \cite{iterative-deepening-chess-ai},
Iterative Deepening
is a search strategy
for exponentially-sized state spaces, in general,
which
makes progressively deeper searches of the state space until the CPU budget is exhausted.
In this context, the depth roughly corresponds to the subset of preemption points used.
Hence, Quicksand
schedules multiple Landslide instances in parallel to
test many different subsets of the available preemption points,

For the remainder of the chapter, I will use Iterative Deepening to refer to the algorithm in the abstract,
which could in principle apply to any stateless model checking domain,
and Quicksand to refer to the specific implementation,
which relies on data race analysis and specific heuristics to optimize its testing approach
for kernels and thread libraries.
I will also henceforth refer to each unique set of preemption points as a {\em job}.

%Note that
Iterative Deepening is a wrapper algorithm around stateless model checking.
A model checker is still used to test each state space, and other reduction techniques such as DPOR
(\cref{sec:landslide-dpor})
are still applicable in each.
Moreover, because Iterative Deepening treats the set of preemption points as mutable,
it can add new preemption points reactively based on any runtime analysis.
This chapter
will focus on run-time data race analysis~\cite{tsan,fasttrack} as the mechanism for finding new preemption candidates.
The next section (\cref{sec:quicksand-soundness})
will prove that in fact,
in addition to statically-known synchronization preemption points,
this suffices to provide at least as strong verification guarantees as any other possible preemption point set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Changing state spaces}

To introduce the Iterative Deepening algorithm,
I will first show a simple approach for handling new preemption points in the absence of any CPU budget restriction.

Given unlimited testing time, %for testing,
%one would always want to
switching to the new maximal state space whenever adding a new preemption point
\qrevisionminor{would be the quickest way to reach full verification}.
The maximal state space is guaranteed to subsume all execution sequences reachable in any subset state space,
so considering any incomplete subset of the known preemption points would be redundant work.
\Cref{alg:algorithm0} demonstrates this na\"ive approach.
It is seeded with the set of all statically-known synchronization API preemption points,
and invoked whenever a new data race candidate is found.
%
The upcoming proofs in \cref{sec:quicksand-soundness},
being concerned with the verification guarantee provided when the search may complete within the CPU budget,
are based on this simple version of Iterative Deepening.
The user may also wish to configure her testing tool to prefer this approach, at her discretion,
such as when she believes all bugs have been fixed and wants a verification as fast as possible;
\cref{sec:quicksand-impl-modes} discusses this execution mode further.

However, in many tests of even modestly-sized programs,
full verification is not feasible,
and focusing on the maximal state space alone is likely to be fruitless.
%
Hence, Iterative Deepening also allows for prioritizing subset jobs
based on number of preemption points, ETA, and whether data race candidates are included among their preemption points.
It relies on state-space estimation \cite{estimation}
to predict which jobs are likely to complete within a reasonable time,
before actually testing a large fraction of interleavings for each.
The overall goal is to decide automatically when to defer testing a state space,
so an inexpert user can provide only her total CPU budget as a test parameter,
and to enable completing appropriately-sized jobs within that budget.
Quicksand seeks to maximize completed state spaces,
as each one serves as a guarantee that all possible interleavings therein were tested;
\cref{sec:quicksand-discussion-partial} discusses some limitations of this approach.
The next three subsections will show how to schedule these smaller jobs
based on their preemption points and ETAs.

\newcommand\AllPPs{\ensuremath{\mathcal{A}}}
\newcommand\PendingJobs{\ensuremath{\mathcal{P}}}
\newcommand\SuspendedJobs{\ensuremath{\mathcal{S}}}
\newcommand\GetETA[1]{ETA(#1)}
\newcommand\GetPPSet[1]{PPSet(#1)}

\begin{algorithm}[t]
	\KwIn{$j$, the currently-running job}
	\KwIn{\AllPPs, the set of all known preemption points} %, sorted by decreasing heuristic priority}
	\eIf{$\exists p \in \AllPPs . p \not\in \GetPPSet{j}$}{
		return NewJob(\AllPPs) // New maximal state space; switch to it
	}{
		return $j$ // $j$ is still maximal
	}
	\caption{Na\"ive Iterative Deepening method}
	\label{alg:algorithm0}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Initial preemption points}
\label{sec:quicksand-initial-pps}

Iterative Deepening must be seeded with a set of initial state spaces,
which can be any number of subsets of the statically-available preemption points
that prior work model checkers would use.
The upcoming soundness proof relies on the maximal state space being included among these for verification's sake,
but to optimize for finding bugs faster,
implementations may wish to simultaneously to try testing subsets thereof.

For testing user-space code, Quicksand begins with the four
%jobs from \Cref{fig:id}:
\qrevisionminor{possible combinations of preemption points from \Cref{fig:pps-statespace}:}
$\{yield\}$,
$\{yield,lock\}$,
$\{yield,unlock\}$,
and $\{yield,lock,$ $unlock\}$, % FIXME argh
By extension, these also induce preemptions on any other primitives
which use
internal locks,
such as condition variables or semaphores.
Preempting on voluntary switches such as {\tt yield} is always necessary to maintain
Landslide's invariant that only one thread runs between consecutive preemption points,
so the {\tt yield} preemption point is always implicitly enabled.
%
For kernel-level testing, interrupt-disabling is analogous to locking,
so preemptions must also be introduced
just before a disable-interrupt opcode (on x86, {\tt cli})
and just after interrupts are re-enabled (on x86, {\tt sti}).
During data race analysis, {\tt cli} and {\tt sti} are treated as a single global lock
(note that {\tt cli}'d memory accesses can still race with others that have interrupts on).%
\footnote{Some kernels disable preemption without disabling interrupts,
which can be communicated to the model checker using manual annotations,
and must be treated similarly.
This also assumes uni-processor scheduling; for SMP kernels, replace {\tt cli}/{\tt sti} with spinlocks.}
Quicksand is configured to begin with
$\{yield\}$,
$\{yield,lock\}$,
$\{yield,unlock\}$,
$\{yield,cli\}$,
$\{yield,sti\}$,
and $\{yield,lock,$ $unlock,cli,sti\}$.
As a heuristic, it doesn't test every intermediate subset such as $\{lock,sti\}$,
which would result in $2^p$ jobs, %right off the bat,
although this could potentially be improved in future work (\cref{sec:quicksand-discussion-subsets}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data-race preemption points}
\label{sec:quicksand-dr-pps}

As discussed in \cref{sec:quicksand-pps},
%runtime data race detection (\cref{sec:background-datarace})
%may find candidate unsynchronized memory conflicts that should be investigated further.
data races may beget new interleavings not reachable by preempting on synchronization API boundaries alone.
Because each data race indicates an access pair that can interleave at instruction granularity,
different program behaviour may arise if the threads are preempted just before the racing instructions,
some of which the programmer may not have even expected, i.e., be bugs,
and it is logical to apply model checking to find or verify the absence of such bugs.
%it is logical to re-execute the test and issue preemptions just before those instructions
%to test alternate thread interleavings.

With Iterative Deepening,
this is a simple matter of creating a new state space
with an additional preemption point enabled on the racing instructions by each thread,
as shown in \Cref{alg:handledatarace}.
%I will term these {\em data-race preemption points},
%and they will
These {\em data-race preemption points} form the foundation of Quicksand's contribution.
Note that even though a data race may involve two different instructions,
$\alpha$ and $\beta$, Quicksand's strategy is to add new state spaces with only one new racing instruction at a time.
Rather than adding a single large state space,
configured to preempt on both involved instructions,
i.e., $AB =$ \GetPPSet{$j_0$} $\cup$ $\alpha$ $\cup$ $\beta$,
it prefers to add multiple smaller jobs which have a higher chance of completing in time, i.e.,
$A =$ \GetPPSet{$j_0$} $\cup$ $\alpha$ and
$B =$ \GetPPSet{$j_0$} $\cup$ $\beta$.
If $A$ and $B$ are bug-free, they will in turn add $AB$ later during their own execution.
The condition on line~1 ensures that we avoid duplicating any state spaces with multiple data-race preemption points;
for example, $AB$ is reachable by multiple paths through its different subsets $A$ and $B$,
but should of course be tested only once.

\newcommand\AllJobs{\ensuremath{\mathcal{J}}}
\begin{algorithm}[h]
	\KwIn{$j_0$, the currently-running job}
	\KwIn{\AllJobs, the set of all existing (or completed) jobs}
	\KwIn{$\alpha$, an instruction reported by the model checker as part of a data race}
	\If{$\forall j \in \AllJobs,$
	\GetPPSet{$j_0$} $\cup$ $\alpha$
	$\not\subseteq$
	\GetPPSet{$j$}
	}{
		AddNewJob(\GetPPSet{$j_0$} $\cup$ $\alpha$, HeuristicPriority($\alpha$)) \\
	}
	\If{$\forall j \in \AllJobs,$ \GetPPSet{$j$} $\neq \{yield, \alpha\}$}{
		AddNewJob($\{yield, \alpha\}$, HeuristicPriority($\alpha$))
	}
	\caption{Adding new jobs with data-race preemption points.}
	\label{alg:handledatarace}
\end{algorithm}

Furthermore,
Iterative Deepening allows not always strictly increasing the number of preemption points
whenever a new data race is identified.
For each instruction involved in a data race, Quicksand adds two new jobs:
a ``small'' job to preempt on that instruction only (line~5),
and a ``big'' job to preempt on that instruction as well as each preemption point used by the reporting job (line~2).
%
Hence,
each {\em pair} of racing accesses will spawn four new jobs.
\Cref{fig:new-dr-jobs} depicts the resulting overall workflow in Quicksand,
including the four such jobs resulting from one data race report.%
\footnote{As an optimization,
though the big jobs should be expected to uncover more data races and in turn
produce even bigger jobs still,
small jobs should be forbidden from ``reproducing'',
as their purpose is only fast heuristic bug-finding rather than exhaustive coverage;
see {\tt handle\_data\_race()} in {\tt messaging.c}.}%
\footnote{\qrevision{For visual simplicity,
fake state spaces are shown here %for each job
to convey only relative size differences, %among them,
but not the internal asymmetric structure inherent to interleavings of multiple threads
(compare to \Cref{fig:pps-statespace}).}}
%
The rationale of spawning multiple jobs is that one cannot know in advance which will be most fruitful:
while the big job risks not completing in time,
the small job risks missing the data race entirely if the original preemption points were required to expose it.
In practice, I have observed many bugs found quickly by these small jobs,
and many other bugs missed by the small jobs found eventually by the big jobs.
This phenomenon motivates Iterative Deepening to prioritize jobs at run-time.

\begin{figure}[t]
	\begin{center}
        \includegraphics[width=0.9\textwidth]{dr-jobs-v3.pdf}
	\end{center}
	\caption[Quicksand incorporates data races as new preemption points at run-time.]
		{Quicksand incorporates data races as new preemption points at run-time
		by managing the exploration of multiple state spaces,
		communicating with each Landslide instance to receive ETAs, data races, and bug reports.
                %When an access pair is reported as a data race candidate,
                When a data race is reported,
                a new preemption point is added for each involved memory access,
                and new jobs are added for later testing,
                corresponding to different combinations thereof with the existing preemption points.}
        \label{fig:new-dr-jobs}
\end{figure}

The new state spaces may expose a failure, in which case Iterative Deepening must stop and report a data-race bug,
or complete successfully, indicating a {\em benign} (i.e., false-positive) data race.
They may also uncover a new data race candidate entirely in some alternate interleaving,
in which case we may iteratively advance to a superset state space which will preempt at both racing access pairs.
Being constrained by a CPU budget,
Iterative Deepening may time out before completing a data race's associated state space,
in which case the data race remains neither confirmed nor refuted.
%Depending on how much burden the implementation wants to impose on the user,
%it may then report it as a
%report a potential false positive that the user must handle
In such cases, Quicksand elects to impose some burden on the user
by reporting it as a potential false positive
and recommend that she investigate it by hand to judge for herself whether it be a bug.
\cref{sec:quicksand-discussion-partial} will discuss future opportunities for improving
debugging output in cases of such {\em partial verification}.
However, experience shows that this interactivity pays off:
in the next chapter's educational user study (\cref{sec:education-eval}),
one student reported during the survey that they used this recommendation,
combined with their own intuition,
to find a bug that Quicksand was not able to find alone (\cref{sec:education-reasons-worthwhile}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Choosing the best job}
\label{sec:quicksand-choosing}

With a limited CPU budget, many larger tests are likely to be fail to complete in time,
and smaller tests are likely to be more fruitful at finding bugs quickly.
A model checker's state space estimation (\cref{sec:landslide-estimate})
can provide a hint to select between these jobs.
How to handle jobs whose ETAs are too high for the given CPU budget
is the heart of Iterative Deepening,
and is listed formally in \Cref{alg:shouldworkblock}.%
\footnote{
Though its worst-case performance is $O(|\mathcal{P}|\times|\mathcal{S}|)$,
%in the
%%number of pending and suspended jobs,
%sizes of $\mathcal{P}$ and $\mathcal{S}$,
in practice the non-constant portion beyond line~4 runs very infrequently
and is negligible compared to the exponentially-sized state spaces themselves.}

\begin{algorithm}[t]
	%\textbf{Function} GetBestJob($j_0$, PendingJobs, SuspendedJobs): \\
	\KwIn{$j_0$, the currently-running job}
	\KwIn{\PendingJobs, the list of pending jobs, sorted by decreasing heuristic priority}
	\KwIn{\SuspendedJobs, the list of already-suspended jobs, sorted by increasing ETA}
	\KwIn{$T$, the remaining time in the CPU budget}
	\If{\GetETA{$j_0$} $<$ HeuristicETAFactor $\times$ $T$}{
		return $j_0$ // Common case: job is expected to finish.
	}
	\ForEach{job $j_P \in$ \PendingJobs}{
		// Don't run a pending job if a subset of it is already suspended; its ETA would be at least as bad. \\
		\If {$\forall j_S \in$ \SuspendedJobs, \GetPPSet{$j_S$} $\not\subset$ \GetPPSet{$j_P$}}{
			return $j_P$
		}
	}
	%// no pending jobs; maybe resume a suspended job \\
	\ForEach{job $j_S \in$ \SuspendedJobs}{
		\If{\GetPPSet{$j_0$} $\not\subset$ \GetPPSet{$j_S$}
			$\land$
			\GetETA{$j_0$} $>$ \GetETA{$j_S$}}{
			// If a subset of $j_S$ is also suspended, don't run the larger one first. \\
			\If{$\forall j_{S2} \in$ \SuspendedJobs, \GetPPSet{$j_{S2}$} $\not\subset$ \GetPPSet{$j_S$}}{
				return $j_S$
			}
		}
	}
	return $j_0$ // \GetETA{$j_0$} was bad, but no other $j$ was better.
	\caption{Suspending exploration of a job in favor of a potentially smaller one.}
	\label{alg:shouldworkblock}
\end{algorithm}

Its main feature is understanding that if \GetPPSet{$j_1$} $\subset$ \GetPPSet{$j_2$},
and $j_1$ is suspended,
then $j_2$'s state space is guaranteed to be strictly larger, so $j_2$ will take at least as long.
Hence, as long as $j_1$ is suspended on account of being too big,
$j_2$ should not be tested either,
unless $j_1$ is later resumed and its ETA improves over time after further execution.
%reveals that it might finish in time after all.
Similarly, whenever a job finds a bug, all pending superset jobs may safely be cancelled,
as they are guaranteed to contain the same program behaviour, and likely to simply find the same bug again.
%
Implementation-wise,
Quicksand receives an updated estimate from each Landslide instance whenever it finishes executing a new interleaving,
and separates them accordingly
into a set of {\em suspended} jobs,
i.e., partially-explored state spaces with high ETAs,
and a set of {\em pending} jobs,
i.e., untested ones with unknown ETAs.
When Landslide reports an ETA too high for some job,
it is compared with other pending and suspended jobs to find another one more likely to complete in time.%
\footnote{Note that when Quicksand is configured to use multiple CPUs,
simultaneously-running jobs are not considered among the set of possible jbos to switch to,
so if there are fewer total jobs with ETA lower than the time budget than the allowed parallelism factor,
some CPUs may end up speculatively running large jobs
in hopes that the ETA turns out to be an overestimate.}

Iterative Deepening also accounts for the inherent inaccuracy of ETA estimates.
Line~1 heuristically scales up the time remaining to avoid suspending jobs too aggressively
in case their ETAs are actually overestimated.
Lines~12-15 account for the
%bizarre
possibility that among two suspended jobs,
%given two jobs,
%%$j_1,j_2$,
\GetPPSet{$j_1$} $\subset$ \GetPPSet{$j_2$}
but
\GetETA{$j_1$} $>$ \GetETA{$j_2$}.
This may seem surprising,
but can often arise because estimates tend to get more accurate over time,
and $j_1$ perhaps ran much longer, on account of being overall smaller,
before becoming suspended.
In such scenarios,
the algorithm heuristically assumes the smaller job's ETA is more accurate,
in order to avoid repeatedly resuming larger jobs briefly only to find that their ETAs keep getting worse and worse.%
\footnote{In order to avoid thrashing in Quicksand.} % ¯\_(ツ)_/¯

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Heuristics}
\label{sec:quicksand-heuristics}

As predicting the ETAs of state spaces of unknown size
and using that plus size of a set of preemption points as a proxy for how likely a job is to find bugs or complete
is a fundamentally messy process,
it is appropriate to equip the algorithm with some heuristics informed by experience.
\Cref{alg:shouldworkblock} allows the option to heuristically scale a job's ETA
when comparing it to the overall time budget,
which can compensate for any inaccuracy by the estimator.
Quicksand uses a scaling factor defaulting to 2,
chosen based on experiments from prior work \cite{estimation}.
%though we allow changing it via the command line.
It also includes a heuristic to
never suspend jobs before they pass a certain threshold of interleavings tested,
with a default of 32,
informed by my personal experience that ETAs require around that much progress into the state space
before they stabilize (at least relative to each other on similar state spaces,
not necessarily relative to the ultimate true size).%
\footnote{These two heuristics are configurable with the
{\tt -e} and {\tt -E} command-line options, respectively,
as discussed in \cref{sec:landslide-quicksand-options}.}

Landslide classifies data race candidates as {\em both-order} or {\em single-order},
as defined in prior work \cite{portend},
based on whether it observed the racing instructions ordered in both possible sequences or only one
in the original state space, respectively.
Single-order candidates are more likely to be false positives (\cref{sec:background-datarace}),
although preempting during the access itself is necessary to say for sure.
Hence, Quicskand add preemption points for both types of candidates,
and heuristically prioritizes jobs with both-order data races
over those with only single-order data races.
The HeuristicPriority($\alpha$) call in \Cref{alg:handledatarace} corresponds to this strategy.
For single-order races, Quicksand does not initially add a preemption point for the later access at all:
if preempting on the first access is capable of reordering the race,
it will be updated to both-order in the new state space, and the second preemption point will be added then.
\cref{sec:warpzone-heuristics} will discuss opportunities for future work to expand
these heuristics with more nuanced search strategies still.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Reallocation false positives}
\label{sec:quicksand-id-realloc}

Finally, I identified a particular class of false positive data race candidates
under the Limited Happens-Before analysis (\cref{sec:background-datarace})
in which the associated memory was recycled by re-allocation between the two accesses,
and claim that it is safe to completely disregard them when considering where to add new preemption points.
\Cref{fig:recycle} shows a common code pattern and interleaving which can expose such behaviour.
If the {\tt malloc()} on line~4 returns the same address passed to {\tt free()} on line~2,
then lines~1 and 7 will be flagged as a potential data race.
I term this a {\em reallocation false-positive data race candidiate}.
To the human eye, this is obviously a false positive:
reordering lines~4-7 before lines~1-2 will cause {\tt malloc()} to return a different region of allocated memory,
in turn causing {\tt x} and {\tt y} to no longer collide.
In studying a similar pattern, the Eraser tool from prior work \cite{eraser}
found that Thread 2's logic usually corresponds to an initialization pattern,
but for generality I have added an arbitrary {\tt publish} action to the example on line~6.

\begin{figure}[h]
	\begin{center}
	\begin{tabular}{rll}
		& \multicolumn{2}{c}{\texttt{\ctype{struct x} \{ \ctype{int} foo; \ctype{int} baz; \} *x;}} \\
		& \multicolumn{2}{c}{\texttt{\ctype{struct y} \{ \ctype{int} bar; \} *y;~~~~~~~~~}} \\
		\\
		& {\bf Thread 1} & {\bf Thread 2} \\
		1 & \texttt{\hilight{assertfail}{x->foo = ...;}} & \\
		2 & \texttt{\call{free}(x);} \\
		3 & & \texttt{\ccomment{// x's memory reallocated}} \\
		4 & & \texttt{y~=~\call{malloc}(\flow{sizeof} *y);} \\
		5 & & \texttt{\ccomment{// ...initialize...}}\\
		6 & & \texttt{\call{publish}(y);} \\
		7 & & \texttt{\hilight{assertfail}{y->bar = ...;}} \\
	\end{tabular}
	\end{center}
	\caption[Reallocation false positive pattern.]
	{Reallocation false positive pattern arising from
	{\tt malloc()} returning the same memory that was just {\tt free()}d.}
	\label{fig:recycle}
\end{figure}

As long as the allocation heap is properly synchronized,
a Pure Happens-Before analysis should identify a happens-before edge
between line~2's {\tt free()} and line~4's {\tt malloc()},
and report no race.
However, the upcoming evaluation will show that Limited Happens-Before retains some advantages over Pure
(\cref{sec:quicksand-eval-bugs}),
so it is useful to
%be able to
automatically suppress data race candidates
that are certain to end up being false positives when reordered.
Such collisions could instead be avoided with a hacked allocator which never recycles memory,
but that could unacceptably impact performance in {\tt malloc()}-heavy tests.

The ability to disregard reallocation false positives is unique to Iterative Deepening.
When limited to a single test execution, suppressing any data race candidate matching this pattern is unsound.
Consider the more unusual program in \Cref{fig:recycle-bug},
in which the memory is recycled the same way, but the racing access's address is not tied to {\tt malloc()}'s return value.
Here, reordering lines~6-7 before line~3 will allow {\tt x} and {\tt x2} to race.
Discarding the data race report as a false positive after checking just this one execution
would overlook such a bug,
but Iterative Deepening is guaranteed to explore the alternate interleaving,
in which the true data race will show up without {\tt free()} and {\tt malloc()} interposing,
so it is safe to suppress at first, as I will prove in \cref{sec:quicksand-realloc}.
Moreover,
in the context of Iterative Deepening, being able to discard certain data race candidates
allows Quicksand to skip exploring some entire state spaces,
and hence run fewer Landslides overall;
this is analogous to DPOR's ability to skip equivalent interleavings within a single Landslide instance.
Upcoming in the evaluation, \cref{sec:quicksand-eval-verif}'s \Cref{tab:drstatistix}
will show how many redundant state spaces Quicksand is able to prune with this technique.

\begin{figure}[h]
	\begin{center}
	\begin{tabular}{rll}
		& {\bf Thread 1} & {\bf Thread 2} \\
		1 & \texttt{\call{publish}(x);} & \\
		2 & \texttt{\hilight{assertfail}{x->foo = ...;}} & \\
		3 & \texttt{\call{free}(x);} \\
		4 & & \texttt{x2 = \call{get\_published\_x}();} \\
		5 & & \texttt{\ccomment{// x's memory recycled}} \\
		6 & & \texttt{y~=~\call{malloc}(\flow{sizeof} *y);} \\
		7 & & \texttt{\hilight{assertfail}{x2->foo = ...;}} \\
	\end{tabular}
	\end{center}
	\caption[Reallocation-pattern data race that hides a true bug.]
	{Reallocation-pattern data race that hides a true bug.
	If a single-pass Limited Happens-Before analysis discarded all data race candidates
	with intervening reallocations,
	it would miss the bug in this adversarial program.}
	\label{fig:recycle-bug}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Soundness}
\label{sec:quicksand-soundness}

Adding new data-race preemption points in a feedback loop can uncover bugs
not previously reachable by preempting on synchronization APIs alone,
as some prior model checkers do \cite{dbug-ssv},
but how does it compare to the other extreme end of the trade-off,
that is,
committing in advance to preempt on every single shared memory access \cite{spin,inspect}?
It turns out,
assuming sufficient CPU budget,
Iterative Deepening can in principle expose every possible program behaviour that
even that latter approach can find,
providing an equally strong verification guarantee.
This section presents a proof of this claim (\cref{sec:quicksand-convergence}),
as well as a supplementary proof (\cref{sec:quicksand-realloc})
of the soundness of pruning reallocation false positives discussed previously (\cref{sec:quicksand-id-realloc}).

I present these proofs as they appeared in the OOPSLA paper \cite{quicksand}:
written as sketches in informal prose,
to optimize for rapidly conveying an intuition for why it works
rather than to justify every internal step within the proof structure.%
\footnote{Also because this thesis is long enough already.}
% footnote yeah, i'm writing this last
% footnote of footnote yeah, the committee never read this part
A more rigorous treatment
is available in the tech report which accompanied the conference paper \cite{quicksand-soundness}.

{\bf Assumptions.}
The proofs are built on a DPOR definition which assumes sequentially-consistent memory hardware.
All algorithms involved are assumed to operate on a machine model of a single globally-consistent execution trace,
which fundamentally cannot account for memory reordering nondeterminism.
%\cref{sec:quicksand-discussion} discusses this limitation further; % that's a lie..
For existing work on combining DPOR with relaxed memory, I refer the reader to \cite{tsopso}.
They also assume the Limited Happens-Before definition
for the data race analysis.
I leave the case for Pure Happens-Before to future work,
although if I may appeal to intuition,
it requires only to show that for any data race candidate
Limited Happens-Before reports in a given execution,
that Pure Happens-Before does not,
either it will be a false positive,
or the latter will find it in an alternate execution within the same state space,
or the latter will find a different data race that ultimately leads to a bigger state space in which the first one may be found,
much like a generalization of \cref{sec:quicksand-realloc}.

\subsection{Convergence to total verification}
\label{sec:quicksand-convergence}

The proof of Iterative Deepening's soundness is in two parts.
In the first part, I prove that for any possible interleaving
one could execute with preemptions anywhere,
an equivalent interleaving must exist using only data-race and synchronization preemption points.
In the second, I prove that starting from synchronization preemption points only,
Iterative Deepening must eventually reach a state space containing such an interleaving,
no matter how many data races are involved.

\subsubsection{Equivalence}

\newcommand\ppnext[1]{\ensuremath{\mathsf{next}(#1)}}
\newcommand\ppinstr[1]{\ensuremath{\mathsf{instr}(#1)}}
\newcommand\ppothers[1]{\ensuremath{\mathsf{others}(#1)}}

Given a preemption point $p$,
let $\ppnext{p}$ denote the next transition after $p$ executed by the thread which ran immediately before $p$,
let $\ppinstr{p}$ denote the first instruction of $\ppnext{p}$,
and let $\ppothers{p}$ denote the transitions by other threads between $p$ and $\ppnext{p}$.

\vspace{0.5em}
\begin{lemma}[Equivalence of non-data-race preemption points]
	For any thread interleaving possible by preempting on any instruction,
	there exists an equivalent interleaving which uses only data-race and synchronization API preemption points.
        \label{lem:relevant}
\end{lemma}

\begin{proof}
Let $p$ be the first preemption point in the given interleaving
such that $\ppinstr{p}$ is not a data race with $\ppothers{p}$ nor is a synchronization API boundary.
Because $\ppinstr{p}$ is not a synchronization boundary,
no lock can be held during $\ppothers{p}$ that was also held by the first thread across $p$.
Hence, because $\ppinstr{p}$ is not a data race, it cannot be a shared memory conflict with $\ppothers{p}$ at all.
Let $i$ be the first instruction among $\ppnext{p}$ which is such a conflict, or a synchronization boundary.
If $i$ is a shared memory conflict, it must be a data race, for the same reasoning as above.
Modify the input interleaving by reordering $\ppinstr{p}$ until $i$, not including $i$, to before $\ppothers{p}$.
By the soundness of DPOR (\cref{sec:landslide-dpor}; \cite{dpor}), this is equivalent to the input interleaving.
In other words, $p$ has been transformed into $p'$ such that $\ppnext{p'} = i$,
which is a data race or synchronization boundary.
All other preemption points in the input trace can be inductively converted in the same manner.
\end{proof}

\subsubsection{Saturation}

For Iterative Deepening to ``eventually'' reach a certain state space,
all data-race preemption points involved must be {\em reachable} during the test.

\vspace{0.5em}
\begin{definition}[Reachability]
	A data race candidate, and its associated preemption point(s),
	are reachable if it will be identified by a model checker
	configured to preempt only on already-reachable preemption points.
\end{definition}
\vspace{0.5em}

Initially, the statically-available synchronization API preemption points (\cref{sec:quicksand-initial-pps})
are reachable.
Reachability of data-race preemption points is transitive.

\vspace{0.5em}
\begin{lemma}[Saturation of data races]
        Given any interleaving comprising only data-race and synchronization API preemption points,
        all involved preemption points are reachable.
        \label{lem:saturation}
\end{lemma}

\begin{proof}
Induct on the preemption points according to the order of their preemptions during an execution sequence.
Given that the interleaving prefix preceding some point $p$ is reachable,
the proof goal is that either $p$ be reachable,
or a new data race among $\ppothers{p}$, not previously reachable, be newly reachable.
The latter condition suffices because in a finitely-sized codebase,
there must be finitely many unique racing instruction pairs.
%, so induction on the number of new data-race preemption points among $\ppothers{p}$ will make $p$ itself reachable.

First, $p$ must be ``coalesced'' away, as well as any other not-yet-reachable points in $\ppothers{p}$.
Consider the alternate interleaving in which the first thread executes past $p$ until the first already-reachable point,
then the other threads among $\ppothers{p}$ execute the same way.
This interleaving's preemption points are all reachable,
so a state space $\mathcal{S}$ containing it will be tested.

If $p$ is a not-yet-reachable data-race preemption point,
it must be possible for some other thread to execute a data-racing instruction with $\ppinstr{p}$.
If this conflict was observed in the state space containing our coalesced interleaving, $p$ is reached.
Otherwise, appeal to the soundness property of DPOR:
%(\cref{sec:landslide-dpor}): % FIXME ugh, this section reference is so handwavy/imprecise
If a program behaviour is possible by interleaving threads at the boundaries of the given transitions,
it will be tested in the containing state space.
By contrapositive, to expose this behaviour,
one or more preemptions must occur in the middle of some transition, rather than at the boundaries.

Let us now see by contradiction that there cannot be {\em multiple} data-race preemption points
which must all be enabled before either data race can be identified;
i.e., a circular dependency.
Assume there does not exist a single transition $t_1 \in \mathcal{S}$
which alone can be split into $\{t_1',t_1''\}$ by a point $q$,
such that another thread's concurrent transition $t_2$ conflicts with $t_1''$.
By the soundness of DPOR, because all $t_2$s are independent with $t_1''$, $\mathcal{S} \equiv \mathcal{S} \cup q$.
Replacing $\mathcal{S}$ with $\mathcal{S} \cup q$ in the above assumption shows that no {\em pair} of new $q$s would expose new program behaviour, and inductively, no set of $q$s of any size, which contradicts the previous paragraph.
%
Hence, a single new not-yet-reachable data race is reachable in $\mathcal{S}$. Hence $p$ will be reached.
\end{proof}

\subsubsection{Convergence}

I name the overall soundness property ``convergence''
in reference to the way it must eventually arrive,
after potentially many iterated state spaces,
at full verification strength.

\vspace{0.5em}
\begin{theorem}[Convergence]
	If a bug can be exposed by any thread interleaving possible
	by preempting on all instructions during a specific test,
	Iterative Deepening will eventually test an equivalent interleaving which exposes the same bug.
        \label{thm:convergence}
\end{theorem}

\begin{proof}
	For any possible interleaving,
	Lemma \ref{lem:relevant} provides an equivalent one with only data-race and synchronization preemption points,
	and Lemma \ref{lem:saturation} proves all involved preemption points are reachable.
	Hence, Iterative Deepening will eventually test a state space containing the equivalent buggy interleaving.
\end{proof}

And thus Iterative Deepening is sound. % :)

\subsection{Suppressing reallocation false positives}
\label{sec:quicksand-realloc}

Next I prove that \cref{sec:quicksand-id-realloc}'s optimization
of discarding reallocation false positives is sound under Iterative Deepening.

\vspace{0.5em}
\begin{theorem}[Soundness of eliminating reallocation data race candidates]
        If a reallocation candidate is not a false positive,
DPOR will reorder threads such that
%DPOR will test an alternate thread interleaving in which
either
the accesses can race without fitting the reallocation pattern,
or a use-after-free bug will be reported immediately.
\end{theorem}

\begin{proof}
Any such program must contain an access $a_1$ by one thread T1,
followed by a {\tt free()} and a {\tt malloc()} possibly by either thread,
followed by an access $a_2$ by the other thread T2,
not depending on the result of the middle malloc.
Without loss of generality, fix T1 to perform the {\tt free()} and T2 the subsequent {\tt malloc()},
as shown in \Cref{fig:recycle-bug}.
The other cases are similar,
although note that if T2 performs the {\tt free()},
and the {\tt malloc()} is reordered before it,
T2's final access will be a use-after-free immediately.
Let us also assume the only way for the program to get pointers to heap memory is through {\tt malloc()};
hence, there must also be some ``publish'' action $p$ by T1 which communicates the address to T2.
Because this is a true potential data race,
$p$ must occur before $a_1$, as $a_2$ cannot be reordered before $p$.

The proof goal is that a preemption point be identified during T1 between $p$ and $a_1$.
The publish action must involve some thread communication,
whether through a shared data structure or message-passing API.
If locking or message-passing is used, the set of static synchronization preemption points
(\cref{sec:quicksand-initial-pps})
suffices to provide one.
Otherwise, $p$ (and the corresponding read by T2) will be a potential data race,
although that may itself be another reallocation candidate.
In this case, apply induction on the chain of pointers, if any, leading to the shared address containing $p$:
in the base case, $p$ is communicated via global data or message-passing,
and in the inductive step, DPOR will reorder threads sufficiently to identify a preemption point on $p$.
% the below feels kinda shaky :\ don't remember exactly how this works
% but if someone doubts, they can check out the TR
Note that this induction may result in several possible intermediate preemption points,
each requiring a new state space to be tested,
of course, \Cref{thm:convergence} guarantees this under Iterative Deepening.
Hence there will be a preemption point between $p$ and $a_1$ no matter the mode of communication.

With this preemption point,
DPOR will reorder $a_2$ before $a_1$, while not changing $a_2$'s location.
As T2's {\tt malloc()} now occurs before T1's {\tt free()}, it will allocate different memory.
Hence $a_1$ and $a_2$ %will be in the same allocation;
can race without appearing to fall under the reallocation pattern.
\end{proof}

This spells QED so we are done \cite{vargomax}. % even more :)))
Note that this proof does not rely on the existence of preemption points on
the internal lock of {\tt malloc()} or {\tt free()},
which is an ideal candidate to ignore via {\tt without\_function} (\cref{sec:landslide-pps})
to reduce state space size.
Future work may generalize this proof structure to not rely on specific knowledge
of {\tt malloc()}'s and {\tt free()}'s behaviour,
but instead to require only any intervening synchronization event,
thereby extending the overall soundness proof to accomodate Pure Happens-Before as well as Limited Happens-Before.
The experiments in future chapters of this thesis will assume that this holds.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation}
\label{sec:quicksand-implementation}

Quicksand is an independent program that wraps the execution of several stateless model checker instances.
It is expected that Landslide be this checker,
but any other tool which implements the same messaging interface would be compatible as well.
The implementation is roughly 3000 lines of C.
All source files mentioned in this section live in the {\tt id/} subdirectory of the Landslide repository,
with the exception of the Landslide extensions (listed last).
As \Cref{chap:landslide} was in some sense a developer's guide to Landslide,
this section will serve similarly for Quicksand.

\subsection{User interface}

The available command-line options for configuring its
CPU-time budget, exploration modes, and so on
are listed in \cref{sec:landslide-quicksand-options}.
Additionally, Quicksand periodically issues a progress report
at fixed intervals to inform the user on the completion, bug-finding, and/or estimated progress of each job.
\Cref{fig:quicksand-progress} shows an example.
I highlight a few notable features of the jobs therein
to serve as a concrete example that may cement the reader's intuition
of \cref{sec:quicksand-id}'s more abstract algorithm descriptions:

\begin{figure}[t]
	\begin{center}
		\footnotesize
	\begin{tabular}{l}
			% version from buggy run
		%\texttt{==== PROGRESS REPORT ====} \\
		%\texttt{total time elapsed: 40s} \\
		%\texttt{[JOB 0] COMPLETE (4 interleavings tested; 7s elapsed)} \\
		%\texttt{       PPs: \{ \}} \\
		%\texttt{[JOB 1] Running (10.677083\%; ETA 2m 15s)} \\
		%\texttt{       Log: id/ls-output.log.ujrk9U -- PPs: \{ 'mutex\_lock' \}} \\
		%\texttt{[JOB 2] BUG FOUND: landslide-trace-1544661430.29.html (51 interleavings tested; 1 preemptions)} \\
		%\texttt{       Log of lprintf()s: id/ls-setup.log.7UMGLr} \\
		%\texttt{       Log: id/ls-output.log.3Ol8rG -- PPs: \{ 'mutex\_unlock' \}} \\
		%\texttt{[JOB 3] CANCELLED} \\
		%\texttt{       PPs: \{ 'mutex\_lock' 'mutex\_unlock' \}} \\
		%\texttt{[JOB 5] COMPLETE (4 interleavings tested; 7s elapsed)} \\
		%\texttt{       PPs: \{ 'data race 5@ 0x1000ec5' \}} \\
		%\texttt{[JOB 13] Setting up...} \\
		%\texttt{       PPs: \{ 'data race 6@ 0x1000ec5' \}} \\
		%\texttt{[JOB 14] Pending...} \\
		%\texttt{       PPs: \{ 'mutex\_unlock' 'data race 6@ 0x1000ec5' \}} \\
		%\texttt{=========================} \\

		\texttt{\ccomment{==================================== PROGRESS REPORT ====================================}} \\
		\texttt{\flow{total time elapsed: 2m 52s}} \\
		\texttt{\ccomment{[JOB 0]} \ctype{COMPLETE (4 interleavings tested; 7s elapsed)}} \\
		\texttt{~~~~\ccomment{PPs: \{ \}}} \\
		\texttt{\ccomment{[JOB 1]} \flow{Running (21.932870\%; ETA 8m 14s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' \}}} \\
		% version that came from the actual test
		%\texttt{\ccomment{[JOB 2]} Running (46.373457\%; ETA 4m 35s)} \\
		%\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_unlock' \}}} \\
		\texttt{\ccomment{[JOB 2]} \hilight{assertfail}{BUG FOUND: landslide-trace-1544661430.29.html (51 interleavings tested)}} \\
		%\texttt{~~~~Log of lprintf()s: id/ls-setup.log.7UMGLr} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_unlock' \}}} \\
		\texttt{\ccomment{[JOB 3]} \flow{Running (9.852431\%; ETA 24m 32s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' 'mutex\_unlock' \}}} \\
		\texttt{\ccomment{[JOB 4]} \ctype{COMPLETE (6 interleavings tested; 9s elapsed)}} \\
		\texttt{~~~~\ccomment{PPs: \{ 'data race @ 0x102917' \}}} \\
		\texttt{\ccomment{[JOB 5]} \flow{Running (3.710938\%; ETA 1h 2m 14s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x102917' \}}} \\
		\texttt{\ccomment{[JOB 6]} \ctype{COMPLETE (4 interleavings tested; 8s elapsed)}} \\
		\texttt{~~~~\ccomment{PPs: \{ 'data race @ 0x1000ecf' \}}} \\
		\texttt{\ccomment{[JOB 7]} \flow{Running (6.119792\%; ETA 33m 14s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x1000ecf' \}}} \\
		\texttt{\ccomment{[JOB 11]} \flow{Running (3.670247\%; ETA 50m 16s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x102917' 'data race @ 0x1000ecf' \}}} \\
		\texttt{\ccomment{[JOB 8]} \call{Deferred... (33.340567\%; ETA 2h 6m 3s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_unlock' 'data race @ 0x102917' \}}} \\
		\texttt{\ccomment{[JOB 9]} \call{Deferred... (34.466226\%; ETA 2h 35m 37s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_unlock' 'data race @ 0x1000ecf' \}}} \\
		\texttt{\ccomment{[JOB 10]} \call{Deferred... (11.113790\%; ETA 4h 20m 31s)}} \\
		\texttt{~~~~ \ccomment{PPs: \{ 'mutex\_lock' 'data race @ 0x102917' \}}} \\
		% no, i deleted all of them pretending the other data races dont exist
		%\texttt{And 63 more pending jobs should time allow.} \\
		\texttt{\ccomment{=========================================================================================}} \\
	\end{tabular}
	\end{center}
	\caption{Example Quicksand progress report showing the various possible job states.}
	\label{fig:quicksand-progress}
\end{figure}

\begin{itemize}
	\item Jobs 0, 1, 2, and 3 are the initially-seeded state spaces (\cref{sec:quicksand-initial-pps}).
	\item Job 2 reports a bug found, and shows the filename of the HTML preemption trace
		(\cref{sec:landslide-bugreport}, \Cref{fig:bugreport})
		which the user should examine to diagnose it.%
		\footnote{I actually cheated by copy/pasting this job alone from a different run of Quicksand;
		the other jobs come from a test with the bug already fixed,
		in order that exploration progress far enough to defer some jobs for the sake of example.
		In a real execution, the superset jobs 3, 5, 7, 8, 9, and 11 would be cancelled.}
	\item Jobs 4 and 6 are the ``small'' jobs added to test the two data races in isolation;
		5 and 7 are the corresponding ``large'' jobs (\cref{sec:quicksand-dr-pps}).
	\item Job 11 is the maximal state space, containing all synchronization preemption points
		and both currently-known data races.
	\item The intermediate jobs 8, 9, and 10 have been suspended for having ETAs
		at least twice as large as the provided CPU budget (1 hour),
		according to the ETA scaling factor heuristic (\cref{sec:quicksand-heuristics}).
	\item Note that job 11's ETA is currently lower than 8's, 9's, and 10's, despite being a strict superset of each.
		This corresponds to the ETA inversion situation discussed in \cref{sec:quicksand-choosing}:
		Quicksand simply hasn't made as much progress into job 11 (compare their percentage estimates rather than ETAs)
		for its ETA to be accurate enough yet.
\end{itemize}
Future work could extend these progress reports to be more interactive,
allowing the user to reprioritize state spaces at her whim
or to disable certain data-race preemption points after checking them by hand,
as discussed in \cref{sec:future-friendly}.

Besides the progress reports, Quicksand also prints a notice for each new data race that Landslide detects,
like so, corresponding to the above progress report, for example:
\begin{center}
	%{\tt Found a racy access at 0x0100006f in txn (410user/progs/htm2.c:47)}
	\begin{tabular}{l}
	{\tt Found a racy access at 0x00102917 in deschedule <unknown>} \\
	{\tt Found a racy access at 0x01000ecf in cond\_signal (cond.c:101)}
	\end{tabular}
\end{center}
If using Limited Happens-Before instead of Pure,
it prints ``potentially-racy access'' instead.
This is implemented in {\tt pp\_new()} in {\tt pp.c}.
If the CPU budget runs out and Quicksand must stop exploring prematurely
(or the user's patience runs out and she interrupts it with ctrl-C),
it prints a final report of all data races it was not able to finish classifying as either buggy or benign,
and urges the user to finish checking them with visual inspection
({\tt print\_live\_data\_race\_pps()} in {\tt pp.c}).
It is this feature which one respondent in the student user survey (\cref{sec:education-reasons-worthwhile})
credited for finding an extra bug.

If the verbose option ({\tt -v}) is supplied,
Quicksand will also print one line per interleaving tested by all its Landslide instances,
showing the number of branches tested so far, the estimated percent progress, and the ETA,
as shown earlier in \cref{sec:landslide-estimate}.
This produces a lot more output, and can make progress reports hard to read as they scroll off the screen quickly,
but the author personally finds this mode less disorienting than ten seconds of pure silence between each progress report.
Of course, future work could improve this with a GUI, or at least a split-screen console view.
It will also cause the progress reports to report more detailed information,
such as which preemption points are nondeterministic data races (\cref{sec:quicksand-pps})
and number of reallocation false positives suppressed (\cref{sec:quicksand-id-realloc}).

\subsection{Model checker interface}
\label{sec:quicksand-impl-mc}

The interface with the model checker has two parts.
First, when starting each job, Quicksand creates a configuration file declaring which preemption points to use,
plus other test-case-specific options such as
which preemption points to suppress (\cref{sec:landslide-pps}),
especially those arising from the {\tt malloc()} lock (\cref{sec:quicksand-realloc}),
which functions DPOR and data race analysis should treat as trusted code (\cref{sec:landslide-config-landslide}),
whether to enable mutex-testing mode (\cref{sec:landslide-dynamicconfig}),
transactional memory (\cref{sec:tm-implementation}),
and so on.
This is done by {\tt run\_job()} in {\tt job.c}.

Then, a dedicated Quicksand thread
({\tt start\_job()} in {\tt job.c})
communicates with its corresponding model checker process via message-passing
over a FIFO pipe % not gonna cite io.c c.c
({\tt talk\_to\_\allowbreak{}child()} in {\tt messaging.c}).
Landslide messages after testing each interleaving to report updated progress and ETAs
as well as whenever a new data race candidate or bug is found.
Quicksand in turn replies whether to resume/suspend (due to too high ETA) or quit (due to timeout)
({\tt handle\_should\_continue()} in {\tt messaging.c}).
It suspends jobs simply by making Landslide wait on a message-passing reply.
Should Quicksand later re-schedule a suspended job, it sends a message to continue,
resuming Landslide right where it left off;
otherwise, it wakes it up only after time runs out, causing it to exit immediately.
The message-passing format is defined at the top of {\tt messaging.c},
and a matching definition appears in Landslide's source file of the same name.

\subsection{Architecture}

Quicksand's overall architecture is a thread pool of workers,
one for each CPU it was configured to use with {\tt -c} (\cref{sec:landslide-quicksand-options}).
These threads do not correspond directly to each active instance of Landslide,
as some may be deferred;
rather, each worker thread links up temporarily to a job thread, whose duties the previous paragraph describes,
and process them as the overall work-queue of state spaces to be tested demands.
Following is a brief description of each of Quicksand's major modules.

\begin{itemize}
	\item {\bf Job management} ({\tt job.c}):
		Contains the lifecycle code for job threads,
		generation of Landslide configuration files,
		and Linux process management code to launch child Landslide instances ({\tt run\_job()}).
	\item {\bf Messaging} ({\tt messaging.c}):
		Manages communication with child Landslides ({\tt talk\_\allowbreak{}to\_child()},
		implementing certain aspects of Iterative Deepening,
		creating new jobs in response to data race reports ({\tt handle\_data\_race()})
		and deferring too-big jobs in reponse to ETA updates  ({\tt handle\_estimate()}).
	\item {\bf Preemption point registry} ({\tt pp.c}):
		Tracks the set of known synchronization primitives (initialized by main)
		and data races ({\tt pp\_new()}),
		including set comparison routines ({\tt pp\_subset()})
		and computing a job's priority based on the types of included preemption points ({\tt unexplored\_priority()}).
	\item {\bf Workqueue} ({\tt work.c}):
		Implements the per-CPU worker threads,
		including the check for whether to switch priority from one job to another
		(\Cref{alg:shouldworkblock}, {\tt should\_work\_\allowbreak{}block()} and {\tt get\_job()}),
		as well as managing the shared workqueue of jobs overall ({\tt workqueue\_thread()}).
		Also implements the fixed-interval progress reporting ({\tt progress\_report\_thread()}).
	\item {\bf Bugs} ({\tt bug.c}):
		Tracks a list of found bugs for main to repeat at program exit,
		and implements the check for superset state spaces to be cancelled if a subset already found a bug
		({\tt bug\_already\_found()}).
	\item {\bf Options} ({\tt option.c}):
		Processes command-line options,
		checking for legality of various combinations of exploration modes.
		New options may be added with the convenient
		%, if scarily-implemented,
		macros {\tt DEF\_CMDLINE\_FLAG()} and {\tt DEF\_CMDLINE\_OPTION()}.
	\item {\bf Main} ({\tt main.c}):
		Initializes the default state spaces,
		waits for worker threads to terminate after either completion or time-out,
		and issues a final list of bug reports, data race reports, or congratulations as appropriate.
\end{itemize}

Finally, because in very large tests,
the number of suspended Landslide instances may grow without abatement,
Quicksand checks every progress report interval whether the memory footprint of these inactive Landslides
pose a threat to the system's total memory.
Implemented in {\tt cant\_swap()} \cite{cant-stop} in {\tt work.c},
it checks if the system's memory usage exceeds a fixed percentage of its total
({\tt RAM\_USAGE\_DANGERZONE}, default 90),
and if so,
abandons a fixed percentage of suspended Landslides
({\tt KILL\_DEFERRED\_JOBS}, default 50).
%
Generally, the currently-running Landslide instances should never threaten to hit swap,
as there can only be as many of those as CPUs,
but this also accounts for memory used by other processes,
so this is not guaranteed to avoid swapping on a heavily-stressed system
(such as running multiple Quicksands at once).
Naturally, if Quicksand ever needs to invoke this protocol,
any hope at a total verification is compromised.

\subsection{Exploration modes}
\label{sec:quicksand-impl-modes}

In addition to Iterative Deepening,
which Quicksand defaults to if no options are given to specify otherwise,
Quicksand also supports several alternate exploration strategies, as follows.

\begin{itemize}
	\item {\bf Single state space, basic DPOR} ({\tt -C}):
		Runs a single instance of Landslide configured to preempt
		on all statically-known synchronization preemption points.
		Corresponds to dBug's approach \cite{dbug-ssv}.
		Never adds any new preemption points based on data race reports.
	\item {\bf Single state space, ICB} ({\tt -I}):
		Runs a single instance of Landslide with preemption points as above,
		but running Iterative Context Bounding with BPOR (\cref{sec:landslide-icb})
		instead of plain DPOR.
		Corresponds to CHESS's approach \cite{chess}.
		Requires either {\tt -C} or {\tt -M} (see below).
	\item {\bf Single state space, preempt-everywhere} ({\tt -0}):
		Runs a single instance of Landslide as above,
		but preempting on every shared memory access, not just synchronization.
		Corresponds to the approach of SPIN \cite{spin} and Inspect \cite{inspect};
		CHESS supports this mode as well with optional compiler instrumentation.
		Requires {\tt -C}; may optionally be combined with {\tt -I}.
	\item {\bf Maximal state space mode} ({\tt -M}):
		Runs the na\"{i}ve version of Iterative Deepening shown in \Cref{alg:algorithm0},
		i.e.,
		immediately abandons any state space whenever a superset of it exists.
		This results in always testing the maximal state space only, with no inherent parallelism,
		and optimizes for the fastest verification when the user has reason to believe no bugs will exist.
		No prior work implements this approach.
		Note that this mode was implemented after \cite{quicksand}'s publication,
		and I will feature it in the evaluation of transactional memory
		(\cref{sec:tm-eval}) rather than in this chapter.
\end{itemize}

Quicksand restricts ICB to be usable only in modes when it runs only one Landslide at a time.
ICB is itself a heuristic search ordering strategy to uncover bugs faster,
so while technically easy to run Iterative Deepening with all jobs thereunder running ICB,
that would suffer both approaches' repeated work compounded.
\cref{sec:warpzone-heuristics} discusses integrating the two approaches to hopefully reap the benefits of both.
However, maximal state space mode does support ICB,
as it focuses on verification only,
but if the result is a time-out,
the user may find an ICB-style preemption-bounded partial verification useful.

\subsection{Landslide extensions}
\label{sec:quicksand-impl-landslide}

I have added several features to Landslide specifically for use under Quicksand.
Source files mentioned in this subsection live under the usual Landslide source directory.

The other end of the messaging protocol (\cref{sec:quicksand-impl-mc})
is implemented in {\tt messaging.c}.
When Quicksand suspends Landslide,
it detects how much time it spent asleep,
and corrects for that amount during its next ETA computation ({\tt fudge\_time()} in {\tt estimate.c}).
Landslide's data race analysis also includes a heuristic to avoid reporting ``too suspicious''
data race candidates which it believes arise from the initialization pattern \cite{eraser}:
if a conflicting access pair is single-order (\cref{sec:quicksand-heuristics})
and also arose during a known synchronization API's {\tt init()} or {\tt destroy()} function,
Landslide will not message it to Quicksand,
at least not until it is reclassified as both-order.

To recognize the reallocation pattern
discussed in \cref{sec:quicksand-id-realloc}
during data race analysis,
Landslide includes a generation counter in its heap allocation tracking (\cref{sec:landslide-memory}).
Each heap allocation is given a unique ID,
and when evaluating whether two heap accesses can race,
the IDs of their containing blocks must match
({\tt was\_freed\_remalloced()} in {\tt memory.c}),
in addition to the other requirements of Happens-Before.
If the generations do not match,
Landslide sets the {\tt free\_re\_malloc} flag in the messaging protocol to Quicksand.
If the race is later observed in a reordering which avoids the reallocation pattern
(such as in \Cref{fig:recycle-bug}),
Landslide will report it as normal,
and Quicksand will promote it to a normal preemption point in the registry
({\tt pp\_new()} in {\tt pp.c}, ``{\tt for realsies}'' case).
Also included in this message is a flag to indicate whether a data race was found
nondeterministically (i.e., not on the first interleaving), such as described in \cref{sec:quicksand-pps}.

Preempt-everywhere mode (\cref{sec:quicksand-impl-modes})
imposes a heavy burden on Landslide on account of the sheer number of preemption points involved.
First of all, because there are separate tracing entrypoints for memory accesses and instructions ({\tt instrument.c}),
it cannot simply invoke the checkpointing routine (\cref{sec:landslide-timetravel}) immediately.
Also, we must still exclude thread-local and kernel (if testing userspace) or user (if testing kernelspace) accesses.
Rather,
the memory analysis (\cref{sec:landslide-memory}) invokes
{\tt maybe\_preempt\_here()} in {\tt pp.c}
for every access it would ordinary record for DPOR.
If the access is outside of the current stack frame,
and not part of the mutexes (unless {\tt TESTING\_MUTEXES}),
this sets a scheduler action flag {\tt preempt\_for\_shm\_here}
which makes preemption point identification treat it the same as a data race (\cref{sec:landslide-pps}).
{\tt check\_withins()} is also modified to never switch to allowlist mode.
Finally,
Landslide increases its heuristic constant for infinite loop detection (\cref{sec:landslide-infloop})
on the first interleaving from 4000 to $2^{20}$,
to account for the increased orders of magnitude in preemptible events.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evaluation}
\label{sec:quicksand-eval}

\qrevision{In Quicksand, Iterative Deepening and data race analysis are intimately connected:
the former relies on the later to supply it with new preemption points, thereby refining its search for new concurrent behaviours,
while the latter relies on the former to thoroughly check all possible interleavings around its reported memory accesses and classify them as buggy or benign.
Despite this synergy, which is necessary for total verification soundness (\cref{sec:quicksand-soundness}),
each of these two techniques is a contribution in its own right when it comes to bug-finding performance.
Hence, this evaluation will measure not only the combined approach's full verification power,
but also the bug-finding performance of each technique separately,
as compared to state-of-the-art single-state-space ICB and DPOR.
I pose the following evaluation questions.}

\begin{enumerate}
	\item Does integrating data-race preemption points improve the accuracy of model checking?
		\begin{enumerate}
			\item Do data-race preemption points expose new bugs that couldn't be found with
				synchronization ones alone?
			\item Do data-race preemption points expose the same bugs
				the preempt-everywhere approach could find, faster?
			\item Does Quicksand provide more full verifications %of bug-free programs
				more quickly than the preempt-everywhere approach?
			% not related to new phrasing of Q1, and also the answer is "kinda sorta not really sometimes" anyway
			%\item Does Iterative Deepening find bugs faster in subset state spaces,
			%	even without data-race preemption points?
			\item How does the choice between Pure and Limited Happens-Before
				affect bug-finding and verification performance?
		\end{enumerate}
	\item Does testing alternate interleavings with model checking improve the accuracy of data race analysis?
		\begin{enumerate}
			\item Does Quicksand avoid false positives compared to single-execution Limited Happens-Before?
			\item Does Quicksand find data-race bugs that single-execution Pure Happens-Before or Limited Happens-Before alone would miss?
		\end{enumerate}
\end{enumerate}

\subsection{Experimental setup}
\label{sec:quicksand-expt-setup}

The test suite consists of 79 P2 student thread libraries (\cref{sec:pebbles}),
submitted in 15-410 during the Spring 2014, Fall 2014, and Spring 2015 semesters,%
\footnote{The 2014 semesters were before \Cref{chap:education}'s user study experiments,
and for Spring 2015 (the first semester thereof),
students who used Landslide during the project were excluded from this dataset.}
and 78 Pintos student kernels (\cref{sec:overview-pintos}),
submitted in Berkeley's CS162 and U. Chicago's CMSC 23000 during Spring 2015.
The P2s in this dataset average 1807 lines of C and x86 assembly code,
%, with a standard deviation of 489.5, % i don't know where hte pintos stdev went and i don't wanna recalc it
and the Pintoses average 718 lines (by {\tt diff} to the provided basecode),
for a total of 198,772 lines of code tested for this evaluation.

I chose P2s and Pintoses for this test suite because of the relative ease of generating hundreds of unique state spaces,
varied in size and correctness, and with a diverse set of bug types.%
\footnote{In addition to concurrency bugs,
many of the codebases exhibited {\em deterministic} bugs (i.e., encountered on the first interleaving tested),
which I fixed by hand before running these tests
to ensure that every bug in this study required meaningful work by the model checker.}
While many prior work stateless model checking papers
% TODO: find one that tests like... apache. to back up your claim of realest of the real world
\cite{chess-icb,optimal-dpor,mcr,rcmc}
% bpor could go here but it's already known bugs benchmarks, less the 'real worl' approach
% wow, ZKW15 is 121 programs! nice job!!
publish studies of single-digit or low-double-digit numbers of
bugs found in ``real-world'' programs,
sometimes reported to and confirmed by the upstream developers, %as severe,
to motivate stateless model checking to be used in production settings,
I believe this approach to be too anecdotal for comparing several model checking strategies {\em against each other},
and opt for this approach instead for better statistical significance.%
\footnote{Not to mention -- as I couldn't say in a conference paper, but can say now --
that extending Landslide to support native Linux programs,
complete with filesystem and network nondeterminism,
would have been an engineering burden beyond my ability to do alone and still graduate on time.}

\subsubsection{Test cases}
\label{sec:quicksand-eval-suite}

\newcommand\mxtest{\texttt{mutex\_test}\xspace}
\newcommand\tej{\texttt{thr\_exit\_join}\xspace}
\newcommand\bct{\texttt{broadcast\_test}\xspace}
\newcommand\paraguay{\texttt{paraguay}\xspace}
\newcommand\paradise{\texttt{paradise\_lost}\xspace}
\newcommand\rwldgr{\texttt{rwlock\_downgrade\_read\_test}\xspace}
\newcommand\prisema{\texttt{priority-sema}\xspace}
\newcommand\waitsimple{\texttt{wait-test}\xspace}
\newcommand\alarmsimul{\texttt{alarm-simultaneous}\xspace}

I tested P2s with six multithreaded programs:
\mxtest, for locking algorithm correctness,
\tej, a test of thread lifecycle,
\bct and \paraguay for condition variables,
\paradise for semaphores,
% nb: there used to be a "f u latex" comment here with a \\ after dgr, prob for margins
and \rwldgr for R/W locks.
These are the same tests I distributed Landslide with in \Cref{chap:education};
\cref{sec:education-pebbles-tests} describes them in further detail.
For \mxtest, \paradise, and \paraguay,
I used the {\tt without\_function} command to exclude
{\tt thr\_create()}, {\tt thr\_exit()}, and {\tt thr\_join()} preemption points,
and for \mxtest I enabled {\tt TESTING\_MUTEXES} (\cref{sec:landslide-dynamicconfig}).
I tested Pintoses with three programs from the class's provided test suite:
\prisema, a test of the kernel scheduling algorithm,
\alarmsimul, for the timer sleep routine,
and \waitsimple, for process lifecycle system calls.
These are a subset of those used in \Cref{chap:education}; see \cref{sec:education-pintos-tests}.
Some of the Pintoses were partially implemented,
so each test could only be run on a subset of the 78 submissions;
see the ``Number tested'' column in \Cref{tab:drbugs}.
For all tests,
I also excluded preemption points on {\tt malloc()}'s internal lock using {\tt without\_function}.
In total, the evaluation comprises 629 unique tests (i.e., pairs of a test program and a Pintos or P2),
at least 181 of which will be seen to expose bugs.

\subsubsection{Model checker configuration}
\label{sec:quicksand-expt-trials}

To evaluate the benefits of data-race preemption points and Iterative Deepening separately,
I ran the test suite under Quicksand in three different experimental configurations,
each of which was given a 1-hour budget and 10 CPUs for each test.

\begin{itemize}
	\item {\bf QS-Limited-HB}: Quicksand with Landslide configured to use Limited Happens-Before for its data race analysis ({\tt -H}),
	\item {\bf QS-Pure-HB}: Quicksand using Pure Happens-Before instead ({\tt -V}), and
	\item {\bf QS-Sync-Only}: Quicksand with initial preemption points only,
		as described in \cref{sec:quicksand-initial-pps},
		but never adding new ones from reported data races.
\end{itemize}

I represented the MC State of the Art%
\footnote{The author's DJ name.}
with three configurations of stand-alone Landslide on the same test suite,
corresponding to the search strategies discussed in \cref{sec:quicksand-impl-modes} and \cref{sec:quicksand-impl-landslide}.

\begin{itemize}
	\item {\bf SSS-MC-DPOR}: Single state space mode ({\tt -C})
		using the maximal preemption point set from \cref{sec:quicksand-initial-pps},
		explored with DPOR (\cref{sec:landslide-dpor}),
		%From prior work, dBug \cite{dbug-ssv} implements this approach, among others. %% nb -- already discussed above
        \item {\bf SSS-MC-ICB}: With preemption points as above,
		but instead using ICB \cite{chess-icb} with BPOR \cite{bpor} to find bugs faster
		({\tt -I}, \cref{sec:landslide-icb}), and
		%From prior work, CHESS \cite{chess} implements this approach.
        \item {\bf SSS-MC-Shared-Mem}:
		Using ICB+BPOR, configured to preempt on any shared memory access ({\tt -0})
                (decided at runtime, excluding threads' accesses to their own stacks),
                which in principle includes all possible data races.
		%From prior work, Inspect \cite{inspect} implements this approach,
		%and CHESS also supports this mode with optional compiler instrumentation.
\end{itemize}

Prior work has shown how to parallelize DPOR of a single state space across multiple processors \cite{parallel-dpor},
but it remains an open research problem how to extend the algorithm to ICB.
Hence, I optimistically gave all control experiments a linear speedup of 10 hours per test with 1 CPU;
i.e., assuming it could parallelize with 100\% efficiency.
To match this,
Quicksand reports both the CPU time and wall-clock time spent during its execution.
Comparing CPU time leads to a more fair comparison,
although Quicksand's inherent parallelism, which only a wall-clock time comparison would show,
is also a convenient benefit unto itself.
All tests ran on 12-core 3.2 GHz Xeon W3670 machines with 12GB of RAM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Bug-finding}
\label{sec:quicksand-eval-bugs}

\Cref{fig:dowefindbugsfaster-cpu}
plots the bug-finding performance of Quicksand's three experimental trials
against the three control approaches
in a cumulative distribution of total bugs found against elapsed CPU time.
The farthest-right point on each series indicates in how many total test cases that trial found a bug
after the 10 CPU-hour timeout.
\Cref{fig:dowefindbugsfaster-wall} shows
the same experiments, measured by wall-clock time until each bug was found instead.

\begin{figure}[h]
	\begin{center}
        \includegraphics[width=0.96\textwidth]{../proposal/dowefindbugsfaster-v2.pdf} \\
	\end{center}
	\caption[Quicksand's bug-finding performance measured in CPU time.]
		{Quicksand's bug-finding performance measured in CPU time.
		Quicksand finds 125\% as many bugs with data-race preemption points at the 10-hour mark,
		compared to the best prior work approach.
		Quicksand's startup overhead is exaggerated, as the control experiments are not parallelized.}
        \label{fig:dowefindbugsfaster-cpu}
\end{figure}
% TODO: fix placement of the legend in this graph so that it's not awful page back and forthing
\begin{figure}[h]
	\begin{center}
        \includegraphics[width=0.96\textwidth]{../proposal/dowefindbugsfaster-wallclock-v2.pdf} \\
	\end{center}
	\caption[Quicksand's bug-finding performance measured in wall-clock time.]
		{Quicksand's bug-finding performance measured in wall-clock time.
		Quicksand is parallelized tenfold; the vertical line indicates its 1 hour limit.}
        \label{fig:dowefindbugsfaster-wall}
\end{figure}

%\begin{figure}[p]
%	\begin{tabular}{c}
%        \includegraphics[width=0.71\textwidth]{../proposal/dowefindbugsfaster-v2.pdf} \\
%		\begin{tabular}{p{\textwidth}}
%                (a) Bugs found by Quicksand versus control experiments, measured in CPU time.
%                %as a function of elapsed CPU time.
%                Overall,
%                a more resource-fair comparison than (b),
%                although Quicksand's start-up overhead is exaggerated, as the SSS-MC tests are not parallelized. \\
%		\end{tabular}
%                \\
%                \\
%        \includegraphics[width=0.71\textwidth]{../proposal/dowefindbugsfaster-wallclock-v2.pdf} \\
%                %(b) Bugs found by elapsed wall-clock time.
%		\begin{tabular}{p{\textwidth}}
%                (b) Bugs found by Quicksand versus control experiments, measured in wall-clock time.
%                Quicksand is parallelized tenfold; the vertical line indicates its 1 hour limit. \\
%		\end{tabular}
%        \end{tabular}
%	\caption[Bug-finding performance comparison
%	between Quicksand and prior work.]
%	{Bug-finding performance comparison between
%        by several configurations of Quicksand and the single-state-space approaches.
%	Quicksand finds 125\% as many bugs
%        with data-race preemption points
%	at the 10-hour mark, compared to the best prior work approach.}
%        \label{fig:dowefindbugsfaster}
%\end{figure}

\subsubsection{Performance comparison}

Compared to SSS-MC-ICB (the fastest among the control experiments),
Quicksand finds more bugs within any fixed CPU budget greater than 200 seconds.
In other words, draw a vertical line at $x=N$ for any $N>200$ to represent timing out each test after $y$ seconds elapsed,
and Quicksand's bug total will exceed that of ICB.
SSS-MC-Shared-Mem initially suffers a substantial performance penalty from the sheer number of preemption points it must analyze,
but ultimately outstrips SSS-MC-ICB, which fundamentally cannot find data-race bugs,
after 135 CPU-minutes with its 100th bug found,
ultimately finishing the 10 CPU-hours as the best prior work approach in the long term.
Compared to SSS-MC-Shared-Mem, Quicksand's Limited HB version
finishes with 125\% as many bugs in total.

Regarding Quicksand's tenfold parallelism,
before the break-even point at 200 seconds,
it lags behind SSS-MC-ICB due to the additional start-up overhead
of testing many state spaces at once even though the easy bugs may be found extremely quickly in any of them.
However, converting ICB's early CPU-time advantage
into faster wall-clock performance remains an open research problem \cite{parallel-dpor}.
\Cref{fig:dowefindbugsfaster-wall} gives Quicksand full credit for its inherent parallelism,
which ICB cannot yet practically match:
with a processor allocation of 10 CPUs, it outperforms all prior work approaches
for any fixed budget of wall-clock time
(i.e., comparing across a vertical line at $x=N$ for any $N$).
% After 1 hour of wall-clock time, tenfold Quicksand performs 158\% as well as SSS-MC-ICB. % totally meaningless

The QS-Sync-Only experiment tests whether Iterative Deepening would be effective
even for model checking domains without data races,
such as distributed systems \cite{macemc,modist,samc,dbug-retreat,concuerror}
and programming languages whose type systems statically reject concurrent mutable shared state
\cite{erlang,haskell,rust-book}.
When Quicksand ignores all data race candidates,
its results are competitive with SSS-MC-DPOR, although SSS-MC-ICB outperforms it slightly.
This is unsurprising: the seed subsets of preemption points
that QS-Sync-Only is limited to
(\cref{sec:quicksand-initial-pps})
are much less flexible than ICB's preemption strategy.
This result suggests that in future work,
Quicksand should consider using ICB in parallel with its default configuration when it finds no data race candidates to test.
I discuss this possibility further in \cref{sec:warpzone-heuristics}.

On the other hand,
comparing QS-Limited-HB to SSS-MC-Shared-Mem
shows that Iterative Deepening thoroughly outperforms ICB when shared-memory preemptions come into play.
%We attribute this to the fact that
Statically configuring a preemption point for every shared memory access in advance
produces orders of magnitude more points than
waiting for an access to be identified as part of a data race at runtime.
%
In principle, DPOR and ICB+BPOR should suffice to identify and prune any equivalent thread interleavings
arising from extraneous preemption points on non-conflicting accesses.
However, in practice,
%we found that
the sheer number of accesses during each new execution
(often thousands)
added significant performance overhead to
%the MC when computing DPOR and backtracking.
DPOR's $O(n^2)$ memory independence computation (\cref{sec:landslide-dpor-conflix}),
as well as the $O(n)$ overhead of checkpointing the execution state at each preemption point (\cref{sec:landslide-timetravel}).
Iterative Deepening avoids this overhead by waiting until runtime
to identify fewer, more relevant preemption points dynamically,
and is hence more suitable for model checking when data races are involved.

\subsubsection{Types of bugs}

\Cref{tab:drbugs} provides more detail on each of the bugs shown in \Cref{fig:dowefindbugsfaster-cpu},
broken down by test case.
The left half shows the number found by each experimental approach,
with the totals of each column corresponding to the values at $x=10$ hours in \Cref{fig:dowefindbugsfaster-cpu}.
In \mxtest, which checks the lock implementation for correctly providing mutual exclusion
(rather than trusting its correctness, as all other tests do),
SSS-MC-ICB and SSS-MC-DPOR
found dramatically fewer bugs (just 1).
Prior work has proposed {\em abstraction reduction} \cite{dbug-phdthesis},
in which verifying correctness properties of synchronization primitives
allows subsequently trusting them in other tests which use them to mitigate state space explosion;
\cref{sec:tm-abstraction} will explore this technique further.
By contrast, QS-Limited-HB found 10 mutex bugs, and SSS-MC-Shared-Mem found 12.
In the scope of this chapter,
this serves as strong evidence that new low-level synchronization code must be verified with data-race preemption points,
whether combined with Iterative Deepening or ICB.

\begin{table}[t]
	\begin{center}
	\small
	\begin{tabular}{r|c||c|c|c|c|c}
		%\multicolumn{2}{c||}{} & \multicolumn{5}{c||}{\bf {Total bugs}} & \multicolumn{4}{c||}{\bf {Data-race bugs}} \\
		% ---
		& {\bf Num.} & \multicolumn{2}{c|}{\bf Quicksand} & \multicolumn{3}{c}{\bf {Single-state-space MC}}
		%& \multicolumn{2}{c|}{\bf {Limited HB}} & \multicolumn{2}{c||}{\bf {Pure HB}} &
		%{\bf Mutual} & {\bf Avg. tested}
		\\
		% ---
		{\bf Test} & {\bf tested} & {\bf LHB} & {\bf PHB} & {\bf ICB} & {\bf DPOR} & {\bf ShMem}
		%& {\bf All} & {\bf Nondet.} & {\bf {All}} & {\bf {Nondet.}}
		%& {\bf timeouts} & {\bf subset SSes}
		\\
		% ---
		\hline
		%         #test qs-lhb qs-phb icb dpor every dronly nondets(LHB) dronly(PHB) nondets(LHB) mutual-TO comp.SSes
		{\tt broadcast\_test}    & 79  & 8   & 8   & 5   & 6   & 7   \\ % & 2 & 1 & {2} & {1} & 7    & 112.3 \\
		{\tt thr\_exit\_join}    & 79  & 23  & 20  & 13  & 13  & 14  \\ % & 11& 4 & {7} & {3} & {12} & {69.7} \\
		{\tt mutex\_test}        & 79  & 10  & 9   & 1   & 1   & 12  \\ % & 9 & 1 & {8} & {1} & 0    & -     \\
		{\tt paradise\_lost}     & 79  & 17  & 16  & 12  & 11  & 12  \\ % & 7 & 3 & {6} & {2} & {50} & {77.4} \\
		{\tt paraguay}           & 79  & 10  & 8   & 5   & 5   & 11  \\ % & 6 & 1 & {3} & {2} & 45   & {59.6} \\
		{\tt rwlock\_downgrade}  & 79  & 27  & 26  & 25  & 23  & 28  \\ % & 4 & 1 & {3} & {0} & {44} & {86.3} \\
		\hline
		{\tt priority-sema}      & 59  & 7   & 7   & 1   & 1   & 8   \\ % & 6 & 4 & {6} & {6} & 2    & 13.0  \\
		{\tt alarm-simultaneous} & 44  & 21  & 12  & 16  & 5   & 29  \\ % & 17& 1 & {7} & {6} & {17} & {7.8}  \\
		{\tt wait-simple}        & 52  & 30  & 26  & 24  & 23  & 1   \\ % & 7 & 2 & {2} & {0} & {15} & {33.8} \\
		\hline
		{\bf Total} & 629 & 153 & 132 & 102 & 88  & 122 \\ % 69& 15& {44}& {21}& {192}& {65.8} \\
	\end{tabular}
	\end{center}
	\caption[Summary of bugs found by each test program.]
	{Summary of bugs
	%and data races
	found by each test program.
	QS-LHB and QS-PHB are Quicksand; ICB/DPOR/ShMem are the controls (\cref{sec:quicksand-expt-trials}).
	}
	\label{tab:drbugs}
\end{table}

To ensure that the corpus of P2 and Pintos bugs gives an unbiased comparison between Quicksand and ICB,
I also counted the preemption bounds at which ICB found each of its bugs,
i.e., the minimum number of involuntary thread switches each bug required to expose.
\Cref{tab:icb-bounds} shows the distribution of these bounds,
which is consistent with the results of \cite[Table 2]{chess-icb},
reproduced in the rightmost column
(obtained under a different test suite, of course, of only 5 programs).
This shows no bias towards bugs that would be harder for ICB to find.
In fact, this evaluation's preemption bound distribution is {\em more} heavily biased towards fewer preemptions,
suggesting that if anything,
my test suite is even friendlier still to ICB than that of prior work.

% TODO: check placement
\begin{table}[t]
	\begin{center}
		\small
	\begin{tabular}{r||c|c||c}
		{\bf Bound} & {\bf SSS-MC-ICB} & {\bf SSS-MC-Shared-Mem} & {\bf Prior work ICB} \cite{chess-icb} \\
		\hline
		0         & 2     & 1     & 3 \\
		1         & 82    & 86    & 7 \\
		2         & 16    & 32    & 5 \\
		3         & 2     & 3     & 1 \\
		4+        & 0     & 0     & 0 \\
		\hline
		\bf Total & 102   & 122   & 16 \\
	\end{tabular}
	\end{center}
	\caption[Distribution preemption bounds among bugs found by ICB.]
	{Distribution of preemption bounds among bugs found by ICB control experiments.
	Bound 0 means the bug was found by switching threads only on {\tt yield} calls.}
	\label{tab:icb-bounds}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Verification}
\label{sec:quicksand-eval-verif}

\qrevision{The previous section showed that Quicksand's suite of bug-finding heuristics,
built around Iterative Deepening,
outperform the best single-state-space approaches,
even after correcting
% in a way fair to the state of the art; indeed, {\em unfair} to landslide, by assuming perfect 10x speedup for control expts
for its inherent parallelism.
This section will hold Quicksand to its promise to uphold the other side of the trade-off as well:
that it reach full verification on correct tests reasonably quickly.}

\subsubsection{Full verification}

\Cref{fig:totalverif} plots the cumulative distribution of total verifications provided by each approach,
in the same style of graph as \Cref{fig:dowefindbugsfaster-cpu} and \Cref{fig:dowefindbugsfaster-wall}.
For 167 of the 629 tests,
QS-Pure-HB was able to reach and complete the maximal state space with no bugs found,
hence providing the total verification guarantee justified by the proofs in \cref{sec:quicksand-soundness}.
QS-Limited-HB completed a verification for 153 of 629 tests,
slightly slower on account of Limited Happens-Before's higher false positive rate.
%(which Quicksand must confirm each time by running an extra instance of Landslide). % explained below
The next best approach for verifications was SSS-MC-Shared-Mem, which completed its search in only 39 cases.

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=0.96\textwidth]{../proposal/totalverifs-v2.pdf}
	\end{center}
	\caption[Verification performance comparison
	between Quicksand and prior work.]
	{Verification performance comparison between
	Quicksand and single-state-space approaches.
	Among the latter, only SSS-MC-Shared-Mem is theoretically capable of verifying any test with data races;
	the others' series include only tests with no data races whatsoever,
	in which case synchronization preemption points alone suffice for a full verification.}
	\label{fig:totalverif}
\end{figure}

Ultimately, using Limited Happens-Before for finding data race candidates allowed Quicksand to find more bugs,
while Pure Happens-Before allowed for reaching full verification faster.
I attribute this trade-off to the fact that
Limited Happens-Before need not wait to test many alternate thread interleavings before
finding a data race candidate to begin with;
%a potential data race candidate is confirmed;
rather, it can add new jobs to start testing potential races immediately.%
\footnote{Upcoming, \Cref{tab:drstatistix} will corroborate this conclusion:
the difference is most dramatic in {\tt alarm-\allowbreak{}simultaneous},
the test where Quicksand struggled most to finish even small subset jobs.}
%
On the other hand, Limited Happens-Before can get overwhelmed by too many false positives,
needing to refute such candidates by testing new state spaces for each one,
while Pure Happens-Before can refute false positives {\em en passant}
by testing alternate interleavings in its original state spaces.
%In both cases, the performance differences seem to become significant only after about 10 minutes of CPU time,
%which suggests... I don't actually know!
This suggests that
%each approach has merit, and that
model checkers which incorporate data race analysis should implement both modes
and offer the user to choose based on their desired and/or expected testing outcome.

The only testing modes which are theoretically capable of verifying any test with data races
were QS-Pure-HB, QS-Limited-HB, and SSS-MC-Shared-Mem (i.e., preempt-everywhere mode).
When QS-Sync-Only, SSS-MC-DPOR, and SSS-MC-ICB
complete their respective maximal state spaces (i.e., all synchronization preemption points),
that constitutes a full verification only in the case where no data races were identified at all,
meaning Iterative Deepening would search no deeper than that anyway.
Therefore, in \Cref{fig:totalverif},
the data series for these latter three configurations
represent only completed tests with no data races.
Even though SSS-MC-Shared-Mem tends to hang out in the same neighbourhood as them,
note that SSS-MC-Shared-Mem is still steadily increasing in verifications provided at the 10-hour cutoff
(let alone the Quicksand ones),
while the other three seem to reach a plateau of around 20-30 tests relatively soon.

\qrevision{A single-state-space model checker could rely on the user
to properly synchronize all reported data races,
in accordance with the philosophy that even non-failing races should count as bugs
\cite{miscompile-benign,data-races-are-evil},
ultimately improving the number of tests it can verify with no data races.
However, RacerX \cite{racerx} showed that overwhelming the user with warnings about non-failing behaviours
jeopardizes their patience for the tool,
which motivates Quicksand to follow in the footsteps of Portend \cite{portend} instead.}

Overall, including data-race preemption points increases verification capacity by 4.25x.
Assuming sequentially-consistent hardware,
QS-Pure-HB classified many true data races as benign,
while the SSS-MC-ICB approach could at best report such races to the user.
This graph's results show that code written in a natural environment by inexpert users (students)
generally does not obey the sort of strict coding discipline necessary
for a model checker to make simplifying assumptions such as ``no data races'',
justifying this chapter's claim that data-race preemption points are essential to model checking.

\subsubsection{Partial verification}
\label{sec:quicksand-eval-partial}

When a model checking job times out,
the user would more likely prefer a summary of what parts of the test were verified
rather than to write off all the CPU time spent as wasted.
To this end,
Quicksand
%instead
reports which subsets of preemption points resulted in state spaces that did complete in time,
in hopes that the user can supplement such a result with her own intuition
by inspecting the code corresponding to the preemption points not tested (especially data races).
From prior work, Preemption Sealing \cite{sealing}
has argued the value of similar {\em compositional testing} when full verification is intractable,
deferring to the user's expertise to judge the value of each subset of preemption points verified.
\Cref{tab:partialverifs} shows Quicksand's partial verification results on timed-out tests.

\begin{table}[h]
	\begin{center}
	\small
	\begin{tabular}{r|c||c|c}
		% ---
		& {\bf Num.} & {\bf Mutual} & {\bf Avg. tested} \\
		{\bf Test} & {\bf tested} & {\bf timeouts} & {\bf subset SSes} \\
		% ---
		\hline
		%                        #test mutual-TO comp.SSes
		{\tt broadcast\_test}    & 79  & 7    & 112.3 \\
		{\tt thr\_exit\_join}    & 79  & {12} & {69.7} \\
		{\tt mutex\_test}        & 79  & 0    & -     \\
		{\tt paradise\_lost}     & 79  & {50} & {77.4} \\
		{\tt paraguay}           & 79  & 45   & {59.6} \\
		{\tt rwlock\_downgrade}  & 79  & {44} & {86.3} \\
		\hline
		{\tt priority-sema}      & 59  & 2    & 13.0  \\
		{\tt alarm-simultaneous} & 44  & {17} & {7.8}  \\
		{\tt wait-simple}        & 52  & {15} & {33.8} \\
		\hline
		{\bf Total}              & 629 & {192}& {65.8} \\
	\end{tabular}
	\end{center}
	\caption[Summary of partial verification results on timed-out tests.]
	{Summary of partial verification results on timed-out tests.
	``Mutual timeouts'' counts how often both QS-Limited-HB and SSS-MC-ICB
	(the best bug-finding approach from each group)
	timed out. %with no bug found.
	Among those, ``Average tested subset SSes'' counts how many partial verifications
	QS-Limited-HB provided on average for each test. %(\sect{\ref{sec:eval-sssmc}}). % ???
	}
	\label{tab:partialverifs}
\end{table}

On 229 tests, SSS-MC-ICB timed out after 10 hours with no bugs found. % thesis note - pretty sure this *isn't* preempt-everywhere
Among these tests, QS-Limited-HB % thesis note -- i think that's what past-me meant. they just wrote, 'quicksand' but.
found bugs in 37.
The other 192 represent cases where neither Quicksand nor ICB were able to provide a conclusive result either way.%
\footnote{Thesis note: SSS-MC-Shared-Mem was added
%in a subsequent revision to \cite{quicksand}
%from when this analysis was conducted
subsequently to this analysis's publication in \cite{quicksand},
at which time SSS-MC-ICB was the best-performing approach among control experiments.
Nevertheless, mutual timeouts among all six testing approaches constituted roughly one third of the test suite.}
For these 192,
I show the number of state spaces Quicksand was able to complete in the
``Average tested subset SSes'' column.
% of \Cref{tab:drbugs}. % thesis - now split into sep table
%While obviously not as strong as full verification,
These completions guarantee that, if the test program could expose a bug,
it would depend on a data race not discovered yet,
or be reachable only under a superset combination of preemption points not yet reached.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data race analysis}
\label{sec:quicksand-eval-nondets}

Beyond finding new bugs and completing full verifications with data-race preemption points,
I evaluated Quicksand's performance for classifying data race candidates in two ways:
its ability to check nondeterministic data races not reachable under a single-pass analysis (\cref{sec:quicksand-pps})
and its ability to suppress reallocation false positives (\cref{sec:quicksand-id-realloc}).
\Cref{tab:drstatistix} presents the results for this section.

\begin{table}[t]
	\begin{center}
	\footnotesize
	\begin{tabular}{r|c||c|c|c|c||c|c|c||c}
		\multicolumn{2}{c||}{} & \multicolumn{4}{c||}{\bf {Data-race bugs}}
		& \multicolumn{3}{c||}{\bf {Verifications}} \\
		% ---
		& {\bf Num.}
		%& \multicolumn{2}{c|}{\bf Quicksand} & \multicolumn{3}{c||}{\bf {State-of-the-art}}
		& \multicolumn{2}{c|}{\bf {Limited HB}}
		& \multicolumn{2}{c||}{\bf {Pure HB}}
		& \multicolumn{3}{c||}{\bf {Pure HB}}
		& \multicolumn{1}{c}{\bf {Realloc.}}
		\\
		% ---
		{\bf Test} & {\bf tested}
		%& {\bf LHB} & {\bf PHB} & {\bf ICB} & {\bf DPOR} & {\bf ShMem}
		& {\bf All} & {\bf N.D.} & {\bf {All}} & {\bf {N.D.}}
		& {\bf DR PPs} & {\bf Benign} & {\bf Untested} & {\bf FPs} \\
		% ---
		\hline
		%                      #test dronly nond dronly nond
		%                                                   drpps benign untest FRMs
		{\tt broadcast\_test}    & 79  & 2 & 1 & {2} & {1} & 655  & 97  & 150 & 52  \\
		{\tt thr\_exit\_join}    & 79  & 11& 4 & {7} & {3} & 566  & 68  & 249 & 338 \\
		{\tt mutex\_test}        & 79  & 9 & 1 & {8} & {1} & 911  & 127 & 44  & 7   \\
		{\tt paradise\_lost}     & 79  & 7 & 3 & {6} & {2} & 783  & 2   & 414 & 166 \\
		{\tt paraguay}           & 79  & 6 & 1 & {3} & {2} & 936  & 9   & 510 & 180 \\
		{\tt rwlock\_downgrade}  & 79  & 4 & 1 & {3} & {0} & 543  & 1   & 310 & 156 \\
		\hline
		{\tt priority-sema}      & 59  & 6 & 4 & {6} & {6} & 65   & 51  & 3   & 0   \\
		{\tt alarm-simultaneous} & 44  & 17& 1 & {7} & {6} & 35   & 0   & 29  & 35  \\
		{\tt wait-simple}        & 52  & 7 & 2 & {2} & {0} & 71   & 1   & 28  & 31  \\
		\hline
		{\bf Total}              & 629 & 69& 15& {44}& {21}& 4565 & 356 & 1737& 965 \\
	\end{tabular}
	\end{center}
	\caption[Data race statistics among Quicksand experiments.]
	{Data race statistics among Quicksand experiments.
	``Data-race bugs'' counts, among Quicksand's bugs, how many required data-race preemption points to expose;
	among those, the ``N.D.'' (``nondeterministic'') columns show how many candidates
	required model checking to identify
	in the first place
	(\cref{sec:quicksand-eval-nondets}).
	%
	``Total DR PPs'' counts how many unique data-racing instructions
	QS-Pure-HB identified among tests where it found no bugs.
	Among those, ``Benign'' counts how many were refuted as non-failing,
	while ``Untested'' counts how many could not be checked in the time limit.
	Finally, ``Realloc. FPs'' counts how many reallocation false positives QS-Limited-HB suppressed.
	}
	\label{tab:drstatistix}
\end{table}

\subsubsection{Nondeterministic data races}

Some memory accesses may be hidden in a control flow path that requires a nondeterministic preemption to be executed
(\cref{sec:quicksand-pps}).
In such cases, a single-pass dynamic data race detector
might not achieve the coverage necessary
to identify a racing access pair as a candidate at all,
let alone check the resulting behaviour with such as Landslide.
I instrumented Landslide to report these to Quicksand
and counted how many such led to Quicksand finding new bugs when used as preemption points.
Such bugs could be considered {\em false negatives} of the single-pass approach.
The left half of \Cref{tab:drstatistix}
breaks down the types of bugs
found in each test case,
showing both the total number of data-race bugs
and the number among those that required such nondeterministic data races to expose.
% I denote these data race reports as {\em nondeterministic},
% while those that could be found on the first interleaving .....
%
To ensure a fair comparison, I disabled Quicksand's reallocation false positive suppression
(\cref{sec:quicksand-id-realloc}, itself evaluated in the next section)
for this experiment.
This prevents Landslide from suppressing an observed reallocation data race candidate on the first interleaving,
which would falsely classify it as nondeterministic,
even though a single-pass would not (indeed, should not) suppress such candidates.

\Cref{fig:dr-falsenegs}
%compares the types of data race candidates necessary to expose each data-race bug in the test suite.
visualizes the difference between single-pass and model-checking-enabled data race analysis.
The first and third series represent the bugs found using preemption points from single-pass data race candidates only,
% not entirely true, as portend could be given data race traces from an MC
%but they don't do it in their paper, so i feel comfortable making this claim
i.e., the state-of-the-art approach used by RaceFuzzer \cite{racefuzzer} and Portend \cite{portend}.
The second and fourth series show all data-race bugs Quicksand found,
which includes the former type as well as new bugs involving nondeterministic races.
QS-Limited-HB found a nice 69 data-race bugs in total, % nice
15 of which %could not be found with single-pass data race candidates alone.
required nondeterministic data-race preemption points to expose.
QS-Pure-HB is even more dependent thereupon, %on nondeterministic data-race preemption points,
%requiring nondeterministic data-race preemption points
requiring them in 21 cases among its 44 total data-race bugs.
Moreover, although the frequency
of these nondeterministic races varies across the different test cases
(for example, almost all in {\tt broadcast\_test} were nondeterministic; almost none in {\tt mutex\_test}),
they are still at least present in all tests,
meaning it is not just an issue of writing ``better'' test cases to avoid them.

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=0.87\textwidth]{nondets.pdf}
	\end{center}
	\caption[Some bugs require nondeterministic data-race preemption points to expose.]
	{Some bugs require nondeterministic data-race preemption points to expose.
	Incorporating these data races,
	which are not observed under single-pass analysis,
	%which stateless model checking integration to identify to begin with,
	as new preemption points
	allowed Quicksand to find
	% lhb: 127.77%
	% phb: 191.30%
	128\% (Limited Happens-Before) to 191\% (Pure Happens-Before) as many data-race bugs
	compared to using single-pass candidates alone.
	}
	\label{fig:dr-falsenegs}
\end{figure}

Note that I do not compare how much testing time is required before identifying the data races %candidates
involved in each bug.
While single-pass data races are all found after a single test execution,
Quicksand may potentially take up to all 10 CPU-hours before identifying a nondeterministic data race.
However, prior work data race tools \cite{tsan,fasttrack},
being not integrated with a model checker,
are not intended to discover new candidates under subsequent runs.
Running a single-pass data race tool repeatedly for 10 CPU-hours could potentially uncover some nondeterministic candidates,
but stress testing's comparative problem with achieving reliable coverage is already well-understood
\cite{chess-icb,gambit},
so I hope the reader will consider this experiment enough evidence for model checking already.
Likewise, replay-based tools such as RaceFuzzer \cite{racefuzzer} and Portend \cite{portend}
depend upon the data race detector to provide an execution trace leading to each candidate.
This result suggests that
such tools could benefit from a similar feedback loop as is used in Iterative Deepening,
for example, to discover new transitively-reachable data races while testing initial ones,
even if full verification not necessarily be their goal.

\subsubsection{Reallocation false positive suppression}

In \cref{sec:quicksand-realloc} I showed the soundness of
suppressing data race reports between two heap accesses when the surrounding memory was re-allocated in between.
\Cref{tab:drstatistix}'s ``Realloc FPs'' column shows the total number of such data race candidates for each test program,
totaling 965 across all tests.
% NB. Calculated this by grepping QS-LHB id-logs for "for realsies" (see quicksand pp.c).
Among these, only 64 were observed to avoid the reallocation in an alternate interleaving,
thereupon being promoted to real data-race preemption points.
\cref{sec:quicksand-realloc}'s proof guarantees the safety of pruning all state spaces resulting from the 901 others.
%
Among the 64 true data races, %which initially fit the malloc-recycle pattern,
none exposed a new bug when used as a preemption point.
This suggests that for other data race tools,
suppressing reallocation candidates may be a productive heuristic,
even if unsound without Iterative Deepening.
However, Quicksand was able to correctly identify the 64 violations of that heuristic, among 26 distinct tests,
and fall back to classifying them with DPOR.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:quicksand-discussion}

This section will list the current limitations of Quicksand and Iterative Deepening
and discuss opportunities for future improvement.

\subsection{Experimental bias}

\qrevision{The evaluation design (\cref{sec:quicksand-expt-trials})
contains two major shortcomings
that, to my surprise, no conference reviewer, audience member, or colleague ever called me out on.
Firstly, the single-state-space preempt-everywhere
strategy was conducted only with ICB enabled (SSS-MC-ShMem).
This resulted in reasonable bug-finding performance,
ultimately reaching 80\% as many bugs found as Quicksand's best (QS-Limited-HB) in \Cref{fig:dowefindbugsfaster-cpu}.
However, ICB tends to repeat work across multiple preemption bound iterations, %hurts its overall completion time,
as evidenced between SSS-MC-ICB and SSS-MC-DPOR in \Cref{fig:totalverif}.
Correspondingly, a version of SSS-MC-ShMem configured to use traditional DPOR without ICB would
effectively begin with a preemption bound of infinity
and perhaps be more competitive with Quicksand on verifications.
%by avoiding ICB's tendency to repeat interleavings. %across iterations.
Of course, this would trade off against its bug-finding performance,
but an expert user could compensate by deciding between the two modes
depending whether she thinks the test is more likely to be buggy or correct.
Granting such user involvement,
Quicksand's maximal state space mode (\cref{sec:quicksand-impl-modes})
would correspondingly verify more tests than QS-Pure-HB, %within those 10 CPU-hours,
especially if it were given 10 wall-clock hours on 1 CPU rather than 1 on 10.
Future work could also improve both Quicksand's and ICB's ability to identify and skip redundant work
across their respective iterations,
as discussed below.

Secondly, and more fundamentally, representing state-of-the-art approaches by reimplementing them in one's own tool is fraught.
The comparison between Iterative Deepening and ICB in
\cref{sec:quicksand-eval-bugs} and \cref{sec:quicksand-eval-verif}
could possibly have been conflated by Landslide's implementation of ICB and/or DPOR being slower
on account of the simulated execution environment (\cref{sec:landslide-architecture}).
A more rigorously scientific comparison would extend a prior work model checker, such as CHESS \cite{chess},
to support dynamically-configured data-race preemption points,
and evaluate Quicksand with it versus its own ICB implementation as well,
to isolate any such conflating factors.
Concurrently with these results' publication in OOPSLA \cite{quicksand},
more advanced state space reduction algorithms were proposed,
such as
%Maximal Causality Reduction (MCR)
MCR \cite{mcr} and RCMC \cite{rcmc} (\cref{sec:related-smc}).
It is not immediately obvious that these techniques' benefits would be orthogonal with Iterative Deepening;
in other words, the benefit of Quicksand with a MCR- or RCMC-enabled model checker might be reduced
compared to the benefit shown in \cref{sec:quicksand-eval-bugs} and \cref{sec:quicksand-eval-verif}.
Future model checkers' evaluations should strive to fairly represent these and other latest algorithms in their comparisons.}
%Future comparisons of model-checking strategies should strive to reach these higher bars of scientific rigor.}

\subsection{Avoiding redundant work}

When Quicksand extends a small state space with more preemption points,
the new state space is guaranteed to test a superset of interleavings compared to the old one.
Because Quicksand prioritizes completing small state spaces before their descendants,
the superset state spaces we run later will repeat each branch of their already-completed subsets,
and any interleaving which does not preempt threads on any of the new preemption points will be repeated work.
%
% lol i never did this
%We measured the proportion of repeated work among completed state spaces across our test suite;
%on average, {\bf \large 999\%} of the interleavings in each test were repeated, with some tests as high as {\bf \large 9999\%}.
This may make Quicksand slower than the single-state-space approach to find certain bugs,
for example, if both {\tt mutex\_lock()} and {\tt mutex\_unlock()} preemption points
together expose a bug, but not either alone.
Predicting whether an upcoming interleaving has already been tested is not straightforward,
but future implementations
of Iterative Deepening and/or ICB
could incorporate cross-job memoization
to prune some or all such repeated work.

Similarly, when pursuing total verification,
if the state space resulting from preempting on every instruction
(or equivalently, the maximal state space, thanks to \cref{sec:quicksand-soundness})
could be completed in time,
a model checker which immediately jumped to that state space,
abandoning all smaller subsets would certainly achieve verification faster.
Quicksand's maximal state space mode ({\tt -M}, see \cref{sec:quicksand-impl-modes})
can strike a middle ground between Iterative Deepening and single-state-space preempt-everywhere,%
\footnote{Thesis note: {\tt -M} mode was implemented after the conference paper's publication \cite{quicksand},
and will be evaluated alongside transactional memory later in \cref{sec:tm-eval}.}
but future implementations of Iterative Deepening could prioritize the maximal state space more flexibly still.
For example, pinning its job to one of the available processors regardless of the status of any smaller jobs
would avoid getting too flooded with smaller jobs to even begin the maximal job before time runs out.
When full verification is infeasible,
completing even an intermediate-sized job would allow immediately pruning all subset jobs thereof,
perhaps using a form of binary search (on the preemption point set size) to find an appropriately-sized intermediate job.

\subsection{Preemption point subsets}
\label{sec:quicksand-discussion-subsets}

Quicksand was able to partially guarantee safety for some preemption points
in 93\% of tests with too-large maximal state spaces (\cref{sec:quicksand-eval-partial}).
However, in 6 cases, no more than the minimal state space could be verified,
and in 18 others, no state spaces were completed at all.
Larger state spaces often result from finer-grained locking,
which can indicate a more intricate concurrent algorithm or an unnecessarily complicated design (or both).
Such programs may require even more rigorous verification than a program with a single global lock,
making them important to consider for future work.
While Quicksand uses {\tt within\_function} (\cref{sec:quicksand-impl-mc})
{\em statically} to restrict where preemption points could arise in advance of the test,
future
Iterative Deepening
implementations could use this mechanism to {\em dynamically} subset preemption points further,
making partial verification of larger tests possible,
potentially even involving the user with interface options
to enable and disable preemption points of her choosing at run-time.
\cref{sec:warpzone-heuristics} discusses this possibility further.

\subsubsection{Static data race analysis}

In \cref{sec:quicksand-eval-bugs}, I evaluated the state-of-the-art approach's ability to find data-race-induced failures
by configuring a static predicate to preempt on any non-stack memory access
({\tt -0}, see \cref{sec:quicksand-impl-modes}).
This introduced hundreds of new preemption points on each new test execution,
with a prohibitive performance impact.
While this performance could be improved by
relaxing the preemption strategy,
instead using a static or single-pass analysis to find data race candidates in advance \cite{portend},
that would sacrifice soundness of the verification guarantee, as I showed in \cref{sec:quicksand-eval-nondets}.
However, Quicksand itself could employ static data race analysis such as RacerX \cite{racerx},
or single-pass dynamic analysis such as ThreadSanitizer \cite{tsan} in future work.
% These tools tend to err on the side of false positives,
% but also include .....
Any data race candidates identified in advance could heuristically be included in Quicksand's initial seed preemption point sets
(\cref{sec:quicksand-initial-pps}),
enabling it to focus on the most suspicious races immediately,
rather than waiting for them to be identified after potentially many iterations of model checking.

\subsection{Partial verification}
\label{sec:quicksand-discussion-partial}

% Likewise,
When full verification is not computationally feasible,
some jobs with data-race preemption points will inevitably time out,
and Quicksand cannot guarantee those races are
false positives or
benign, even though no bug was found.
In the ``Untested DR PPs'' column of \Cref{tab:drstatistix},
I show how many such candidates Quicksand (with Pure Happens-Before) could not verify in each test,
ultimately totaling 38\% of all data races in tests which timed out.
In prior work,
Portend introduced the {\em k-witness harmless} metric \cite{portend}
for heuristically classifying the likelihood that each data race lead to a failure or be benign.
Quicksand could incorporate this metric to guide the user's attention
to the unverified data races most likely to be worth her time.
%
In \cref{sec:quicksand-eval-partial} I presented partial verification results
measured in tens or hundreds of subset state spaces completed on average per test case.
However,
%On the other hand,
attempting to maximize the raw number of completed state spaces
is not necessarily the most user-friendly way to present partial verifications.
For starters, those numbers included small state spaces which were subsets of other state spaces also completed;
the user need not examine both subset and superset separately to understand what was tested.
Future work should at least perform basic set comparisons
to present only the non-redundant state spaces completed when time runs out.
For a further research challenge,
user studies could help to determine the most effective interface for presenting these partial results
from a software development perspective,
which I discuss further in \cref{sec:future-friendly}.

Quicksand is not the first concurrency tester to provide a partial verification guarantee
when it times out on too-large tests.
Probabilistic Concurrency Testing (PCT)
\cite{randomized-scheduler}
proposes to use random exploration of the state space and quantify the probability
that a bug may remain in some untested interleaving after a time-out,
eschewing DPOR's depth-first search model to
instead sample broad cross-sections of large state spaces.
However, it proposes no alternate reduction strategy, making full verification impractical,
and furthermore is opaque to the user about which parts of her code were actually tested.
Meanwhile, ICB proposes to inform the user
of the maximum number of preemptions used to test any individual interleaving,
under the assurance that most bugs are likely to be found with fewer preemptions (\Cref{tab:icb-bounds}).
Iterative Deepening
%offers a clear benefit to the expert user
%via the {\tt within\_function} command,
%which enables her
allows the expert user
to restrict a test's scope via the {\tt within\_function} command to only the modules of a codebase she wishes to test.
These guarantees could each be useful to developers in different scenarios,
and future work could combine the three approaches to provide all benefits at once,
for example, using ETAs to heuristically decide when to switch between DPOR, ICB, and/or PCT in large state spaces,
as discussed further in \cref{sec:warpzone-heuristics}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

\qrevision{In order to supplant conventional stress testing,
which, despite its
%tendency to overlook subtle and severe nondeterministic bugs,
%lack of any formal coverage guarantees,
inability to reliably expose, reproduce, or verify absent bugs in any finite amount of testing time,
remains a popular choice for concurrency programmers of all skill levels,
stateless model checking must meet users' needs regarding realistic testing budgets.
This chapter has presented Quicksand, which automatically navigates the trade-off
between fast bug-finding and formal verification depending on the size of the test.
My contributions have been as follows.

\begin{itemize}
	\item Iterative Deepening (\cref{sec:quicksand-id}),
		an algorithm for model checkers to simultaneously test multiple state spaces,
		incorporating new preemption points identified with dynamic analysis on the fly.
	\item A proof of convergence (\cref{sec:quicksand-convergence}),
		showing that for any verification obtained under even the most extreme preemption strategy,
		Iterative Deepening with data race analysis provides an equivalently strong one,
		with far fewer preemption points necessary.
	\item A technique for suppressing certain false positive data race candidates
		under Limited Happens-Before (\cref{sec:landslide-lhb})
		by identifying intervening {\tt malloc()} and {\tt free()} calls
		(\cref{sec:quicksand-id-realloc}),
		and a corresponding soundness proof when this technique is used under Iterative Deepening
		(\cref{sec:quicksand-realloc}).
	\item Quicksand (\cref{sec:quicksand-implementation}),
		an Iterative Deepening implementation which incorporates several heuristics for prioritizing
		which state spaces are most likely to uncover bugs % this claim is not scientifically justified
		or, should no bugs exist therein,
		which ones are most likely to complete within a user-specified fixed CPU budget,
		as informed by state space estimation (\cref{sec:landslide-estimate}).
	\item A 629-test evaluation of Quicksand
		against several prior state-of-the-art model checking approaches implemented in Landslide
		(\cref{sec:quicksand-eval}),
		which showed that Quicksand provides both faster bug-finding (\cref{sec:quicksand-eval-bugs})
		and more full verifications (\cref{sec:quicksand-eval-verif}),
		delivering ``the best of both worlds'' as promised,
		and also demonstrated the need for a bidirectional feedback loop
		between model checking and data race analysis
		(\cref{sec:quicksand-eval-nondets}).
\end{itemize}

The next chapter will tell of my experience and results deploying Landslide in an educational setting,
equipped with Quicksand to allow even inexperienced student users to benefit from stateless model checking
with little to no manual configuration burden.}
