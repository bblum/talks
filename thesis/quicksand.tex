% TODO: scan for abbrs like PP, MC, SSS-MC - well mc is ok but rephrase if necessary anyway
\chapter{Quicksand}
\label{chap:quicksand}
\inspirationalquote{
% original - on second thought, i'm not actually gonna put this in
% the nuance in japanese is more desperate, more disorganized, and less generally heroic-seeming
% i think the english translation actually works better for an inspirational quote
%{\footnotesize 嫌な事も悲しい事もあったけど、守りたい物だってたくさんこの世界にはあったから。} \\
There are awful, sad things in this world.
But there are a lot of things worth protecting, too.
}
%{Kaname Madoka, Mahou Shoujo Madoka{\raisebox{0.1em}{$\scriptstyle \bigstar$}}Magica}
% TODO: make the star italic
% TODO: see https://tex.stackexchange.com/questions/63179/shear-transform-a-box/63188#63188
{Kaname Madoka, Puella Magi Madoka{\raisebox{0.1em}{$\scriptstyle \bigstar$}}Magica}
%\inspirationalquote{Always, somewhere, someone is fighting for you.
%As long as you remember her, you are not alone.}
%{Mahou Shoujo Madoka{\raisebox{0.1em}{$\scriptstyle \bigstar$}}Magica}

% TODO: intro

% TODO: mention that all source files in this chapter are relative to id/ subdir in the repo

The contributions of this chapter were published as
{\em Stateless Model Checking with Data-Race Preemption Points}
in OOPSLA 2016 \cite{quicksand}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preemption points}
\label{sec:quicksand-pps}

% reference figure (nb color scheme tree)
% its pps were drawn on every instruction
% for larger test cases, this is not practical
% consider the example program of so and so (show mx/yield prog)
% here is a resulting state space
% this needs a DR preemption point to FAB
% qs example (take from thesis slides)

% TODO make sure to define maximal and mminnimal

% TODO: define "data race" (pure hb) vs "data race candidate" (limited); also do scane of this chapater for conisstencey

% TODO: use this somehow
Committing in advance to
preempt on every instruction is certain to expose any possible bug under the given test case,
but invites massive state space explosion.
Even as DPOR helps to skip equivalent interleavings of non-conflicting transitions,
DPOR itself is $O(n^2)$ in the number of preemption points in a single execution,
which is not compatible with such an approach.
Accordingly, stateless model checkers must find more efficient ways to be able to uncover bugs such as these.

In related work,
Portend \cite{portend} has already suggested combining data race analysis with preemption-driven artificial scheduling,
although it obtains its data-race candidates from a stand-alone, single-pass analysis.
In order to make sure we identify every one of a program's data races that could possibly arise under the given test case,
we must check many different interleavings to begin with,
perform the Portend approach for every data race we find,
which may in turn uncover more data races
(hidden in flow control paths reachable only through interleavings of the first race, perhaps),
and then continue model checking the multiple data races together
in a sort of bidirectional feedback loop between the two algorithms.
I will refer to data races that require model checking to expose to begin with as
{\em nondeterministic data races}. % TODO: rename, this name is awful
In the next section,
\cref{sec:quicksand-id} will show how I achieve this in Quicksand, and
\cref{sec:quicksand-soundness} will justify the technique's formal verification power.
In the evaluation (\cref{sec:quicksand-eval}),
\cref{sec:quicksand-eval-nondets} in particular will justify the need
for this feedback loop between model checking and data race analysis
by showing that many bugs require nondeterministic data races to expose.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Iterative Deepening}
\label{sec:quicksand-id}

To address the problem of choosing meaningful preemption points,
I have developed an algorithm called {\em Iterative Deepening},
implemented in a wrapper program specific to Landslide called {\em Quicksand}.
Named after the analogous technique in chess artificial intelligence \cite{iterative-deepening-chess-ai},
Iterative Deepening
is a search strategy,
for exponentially-sized state spaces in general,
which
makes progressively deeper searches of the state space until the CPU budget is exhausted.
In this context, the depth roughly corresponds to the subset of preemption points used.
Hence, Quicksand
schedules multiple Landslide instances in parallel to
test many different subsets of the available preemption points,

For the remainder of the chapter, I will use Iterative Deepening to refer to the algorithm in the abstract,
which could in principle apply to any stateless model checking domain,
and Quicksand to refer to the specific implementation,
which relies on data race analysis and specific heuristics to optimize its testing approach
for kernels and thread libraries.
I will also henceforth refer to each unique set of preemption points as a {\em job}.

%\subsection{Design}

% TODO: put fig:id here, explain generally multiple state spaces

Note that Iterative Deepening is a {\em wrapper} algorithm around stateless MC.
A model checker is still used to test each state space, and other reduction techniques such as DPOR
are still applicable in each.
Moreover, because Iterative Deepening treats the set of preemption points as mutable,
it can add new preemption points reactively based on any runtime analysis.
Here
will focus on run-time data race analysis~\cite{tsan,fasttrack} as the mechanism for finding new preemption candidates.
The next section (\cref{sec:quicksand-soundness})
will prove that in fact,
in addition to statically-known synchronization preemption points,
this suffices to provide at least as strong verification guarantees as any other possible preemption point set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Changing state spaces}

To introduce the Iterative Deepening algorithm,
I will first show a simple approach for handling new preemption points in the absence of any CPU budget restriction.

Given unlimited CPU time for testing,
one would always want to switch to the new maximal state space whenever adding a new preemption point.
The maximal state space is guaranteed to subsume all execution sequences reachable in any subset state space,
so considering any incomplete subset of the known preemption points would be duplicate work.
\Cref{alg:algorithm0} demonstrates this na\"ive approach.
It is seeded with the set of all statically-known synchronization API preemption points,
and invoked whenever a new data-race candidate is found.
%
The upcoming proofs in \cref{sec:quicksand-soundness},
being concerned with the verification guarantee provided when the search may complete within the CPU budget,
are based on this simple version of Iterative Deepening.
The user may also wish to configure her testing tool to prefer this approach, at her discretion,
such as when she believes all bugs have been fixed and wants a verification as fast as possible;
% TODO: clarify sec reference to -M flag
\cref{sec:quicksand-implementation} discusses this execution mode further.

\newcommand\AllPPs{\ensuremath{\mathcal{A}}}
\newcommand\PendingJobs{\ensuremath{\mathcal{P}}}
\newcommand\SuspendedJobs{\ensuremath{\mathcal{S}}}
\newcommand\GetETA[1]{ETA(#1)}
\newcommand\GetPPSet[1]{PPSet(#1)}

\begin{algorithm}[h]
	\SetKwInOut{Input}{Input}
	\Input{$j$, the currently-running job}
	\Input{\AllPPs, the set of all known preemption points} %, sorted by decreasing heuristic priority}
	\eIf{$\exists p \in \AllPPs . p \not\in \GetPPSet{j}$}{
		return NewJob(\AllPPs) // New maximal state space
	}{
		return $j$ // $j$ is still maximal
	}
	\caption{Na\"ive Iterative Deepening method}
	\label{alg:algorithm0}
\end{algorithm}

However, in many tests of even modestly-sized programs,
full verification is not feasible,
and focusing on the maximal state space alone is likely to be fruitless.
%
Hence, Iterative Deepening also allows for prioritizing subset jobs
based on number of preemption points, ETA, and whether data race candidates are included among their preemption points.
It relies on state-space estimation \cite{estimation}
to predict which jobs are likely to complete within a reasonable time,
before actually testing a large fraction of interleavings for each.
The overall goal is to decide automatically when to defer testing a state space,
so an inexpert user can provide only her total CPU budget as a test parameter,
and to enable completing appropriately-sized jobs within that budget.
Quicksand seeks to maximize completed state spaces,
as each one serves as a guarantee that all possible interleavings therein were tested;
\cref{sec:quicksand-discussion} discusses some limitations of this approach.
The next three subsections will show how to schedule these smaller jobs
based on their preemption points and ETAs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Initial preemption points}
\label{sec:quicksand-initial-pps}

Iterative Deepening must be seeded with a set of initial state spaces,
which can be any number of subsets of the statically-available preemption points
that prior work model checkers would use.
The upcoming soundness proof relies on the maximal state space being included among these for verification's sake,
but to optimize for finding bugs faster,
implementations may wish to simultaneously to try testing subsets thereof.

For testing user-space code, Quicksand begins with the four jobs from \Cref{fig:id}:
$\{yield\}$,
$\{yield,lock\}$,
$\{yield,unlock\}$,
and $\{yield,lock,unlock\}$,
By extension, these also induce preemptions on any other primitives
which use
internal locks,
such as condition variables or semaphores.
Preempting on voluntary switches such as {\tt yield} is always necessary to maintain
Landslide's invariant that only one thread runs between consecutive preemption points,
so the {\tt yield} preemption point is always implicitly enabled.

For kernel-level testing, interrupt-disabling is analogous to locking,
so preemptions must also be introduced
just before a disable-interrupt opcode (on x86, {\tt cli})
and just after interrupts are re-enabled (on x86, {\tt sti}).
During data race analysis, {\tt cli} and {\tt sti} are treated as a single global lock
(note that {\tt cli}'d memory accesses can still race with others that have interrupts on).%
\footnote{Some kernels disable preemption without disabling interrupts,
which can be communicated to the MC using manual annotations,
and must be treated similarly.
This also assumes uni-processor scheduling; for SMP kernels, replace {\tt cli}/{\tt sti} with spinlocks.}
Quicksand is configured to begin with
$\{yield\}$,
$\{yield,lock\}$,
$\{yield,unlock\}$,
$\{yield,cli\}$,
$\{yield,sti\}$,
and $\{yield,lock,$ $unlock,cli,sti\}$.
As a heuristic, it doesn't test every intermediate subset such as $\{lock,sti\}$,
which would result in $2^p$ jobs right off the bat,
although this could potentially be improved in future work (\cref{sec:quicksand-discussion}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data-race preemption points}
\label{sec:quicksand-dr-pps}

As discussed in \cref{sec:quicksand-pps},
%runtime data race detection (\cref{sec:background-datarace})
%may find candidate unsynchronized memory conflicts that should be investigated further.
data races may beget new interleavings not reachable by preempting on synchronization API boundaries alone.
Because each data race indicates an access pair that can interleave at instruction granularity,
different program behaviour may arise if the threads are preempted just before the racing instructions,
some of which the programmer may not have even expected, i.e., be bugs,
and it is logical to apply model checking to find or verify the absence of such bugs.
%it is logical to re-execute the test and issue preemptions just before those instructions
%to test alternate thread interleavings.

With Iterative Deepening,
this is a simple matter of creating a new state space
with an additional preemption point enabled on the racing instructions by each thread,
as shown in \Cref{alg:handledatarace}.
I will term these {\em data-race preemption points},
and they will form the foundation of Quicksand's contribution.
Note that even though a data race may involve two different instructions,
$\alpha$ and $\beta$, Quicksand's strategy is to add new state spaces with only one new racing instruction at a time.
Rather than adding a single large state space,
configured to preempt on both involved instructions,
i.e., $AB =$ \GetPPSet{$j_0$} $\cup$ $\alpha$ $\cup$ $\beta$,
it prefers to add multiple smaller jobs which have a higher chance of completing in time, i.e.,
$A =$ \GetPPSet{$j_0$} $\cup$ $\alpha$ and
$B =$ \GetPPSet{$j_0$} $\cup$ $\beta$.
If $A$ and $B$ are bug-free, they will in turn add $AB$ later during their own execution.
The condition on line~1 ensures that we avoid duplicating any state spaces with multiple data-race preemption points;
for example, $AB$ is reachable by multiple paths through its different subsets $A$ and $B$,
but should of course be tested only once.

\newcommand\AllJobs{\ensuremath{\mathcal{J}}}
\begin{algorithm}[t]
	\SetKwInOut{Input}{Input}
	\Input{$j_0$, the currently-running job}
	\Input{\AllJobs, the set of all existing (or completed) jobs}
	\Input{$\alpha$, an instruction reported by the MC as part of a racing access pair}
	\If{$\forall j \in \AllJobs,$
	\GetPPSet{$j_0$} $\cup$ $\alpha$
	$\not\subseteq$
	\GetPPSet{$j$}
	}{
		AddNewJob(\GetPPSet{$j_0$} $\cup$ $\alpha$, HeuristicPriority($\alpha$)) \\
	}
	\If{$\forall j \in \AllJobs,$ \GetPPSet{$j$} $\neq \{yield, \alpha\}$}{
		AddNewJob($\{yield, \alpha\}$, HeuristicPriority($\alpha$))
	}
	\caption{Adding new jobs with data-race preemption points.}
	\label{alg:handledatarace}
\end{algorithm}

Furthermore,
Iterative Deepening allows not always strictly increasing the number of preemption points
whenever a new data race is identified.
For each instruction involved in a data race, Quicksand adds two new jobs:
a ``small'' job to preempt on that instruction only (line~5),
and a ``big'' job to preempt on that instruction as well as each preemption point used by the reporting job (line~2).
%
Hence,
each {\em pair} of racing accesses will spawn four new jobs.
\Cref{fig:new-dr-jobs} visualizes the resulting overall workflow in Quicksand,
including the four such jobs resulting from one data race report.%
\footnote{As an optimization,
though the big jobs should be expected to uncover more data races and in turn
produce even bigger jobs still,
small jobs should be forbidden from ``reproducing'',
as their purpose is only fast heuristic bug-finding rather than exhaustive coverage;
see {\tt handle\_data\_race()} in {\tt messaging.c}.}
%
The rationale of spawning multiple jobs is that one cannot know in advance which will be most fruitful:
while the big job risks not completing in time,
the small job risks missing the data race entirely if the original preemption points were required to expose it.
In practice, I have observed many bugs found quickly by these small jobs,
and many other bugs missed by the small jobs found eventually by the big jobs.
This phenomenon motivates Iterative Deepening to prioritize jobs at run-time.

\begin{figure}[t]
        %\includegraphics[width=0.48\textwidth]{dr-jobs-v2.pdf}
        asdfsaf
        % TODO: put the figure form yr snake fight
	\caption[Quicksand incorporates data race reports as new preemption points at run-time.]
		{Quicksand incorporates data race reports as new preemption points at run-time,
		by managing the exploration of multiple state spaces,
		communicating with each MC instance to receive ETAs, data race candidates, and bug reports.
                %When an access pair is reported as a data race candidate,
                When a data race is reported,
                a new preemption point is added for each involved access,
                and new jobs are added for later testing,
                corresponding to different combinations of those with the existing preemption points.}
        \label{fig:new-dr-jobs}
\end{figure}

The new state spaces may expose a failure, in which case Iterative Deepening must stop and report a data-race bug,
or complete successfully, indicating a {\em benign} (i.e., false-positive) data race.
They may also uncover a new data-race candidate entirely in some alternate interleaving,
in which case we may iteratively advance to a superset state space which will preempt at both racing access pairs.
Being constrained by a CPU budget,
Iterative Deepening may time out before completing a data race's associated state space,
in which case the data race remains neither confirmed nor refuted.
%Depending on how much burden the implementation wants to impose on the user,
%it may then report it as a
%report a potential false positive that the user must handle
In such cases, Quicksand elects to impose some burden on the user
by reporting it as a potential false positive
and recommend that she investigate it by hand to judge for herself whether it be a bug.
% TODO: fix this to point to partial verif
% TODO (also) make sure that all other quicksand-discussion references get updated if appropriate
\cref{sec:quicksand-discussion} will discuss future opportunities for improving
debugging output in cases of such {\em partial verification}.
However, experience shows that this interactivity pays off:
in the next chapter's educational user study (\cref{sec:education-eval}),
one student reported during the survey that they used this recommendation,
combined with their own intuition,
to find a bug that Quicksand was not able to find alone (\cref{sec:education-reasons-worthwhile}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Choosing the best job}
\label{sec:quicksand-choosing}

With a limited CPU budget, many larger tests are likely to be fail to complete in time,
and smaller tests are likely to be more fruitful at finding bugs quickly.
A model checker's state space estimation (\cref{sec:landslide-estimate})
can provide a hint to select between these jobs.
How to handle jobs whose ETAs are too high for the given CPU budget
is the heart of Iterative Deepening,
and is listed formally in \Cref{alg:shouldworkblock}.%
\footnote{
Though its worst-case performance is $O(mn)$ in the
%number of pending and suspended jobs,
sizes of $\mathcal{P}$ and $\mathcal{S}$,
in practice the non-constant portion beyond line~4 runs very infrequently
and is negligible compared to the exponentially-sized state spaces.}.

\begin{algorithm}[t]
	\SetKwInOut{Input}{Input}
	%\textbf{Function} GetBestJob($j_0$, PendingJobs, SuspendedJobs): \\
	\Input{$j_0$, the currently-running job}
	\Input{\PendingJobs, the list of pending jobs, sorted by decreasing heuristic priority}
	\Input{\SuspendedJobs, the list of already-suspended jobs, sorted by increasing ETA}
	\Input{$T$, the remaining time in the CPU budget}
	\If{\GetETA{$j_0$} $<$ HeuristicETAFactor $\times$ $T$}{
		return $j_0$ // Common case: job is expected to finish.
	}
	\ForEach{job $j_P \in$ \PendingJobs}{
		// Don't run a pending job if a subset of it is already suspended; its ETA would be at least as bad. \\
		\If {$\forall j_S \in$ \SuspendedJobs, \GetPPSet{$j_S$} $\not\subset$ \GetPPSet{$j_P$}}{
			return $j_P$
		}
	}
	%// no pending jobs; maybe resume a suspended job \\
	\ForEach{job $j_S \in$ \SuspendedJobs}{
		\If{\GetPPSet{$j_0$} $\not\subset$ \GetPPSet{$j_S$}
			$\land$
			\GetETA{$j_0$} $>$ \GetETA{$j_S$}}{
			// If a subset of $j_S$ is also suspended, don't run the larger one first. \\
			\If{$\forall j_{S2} \in$ \SuspendedJobs, \GetPPSet{$j_{S2}$} $\not\subset$ \GetPPSet{$j_S$}}{
				return $j_S$
			}
		}
	}
	return $j_0$ // \GetETA{$j_0$} was bad, but no other $j$ was better.
	\caption{Suspending exploration of a state space in favor of a potentially smaller one.}
	\label{alg:shouldworkblock}
\end{algorithm}

Its main feature is understanding that if \GetPPSet{$j_1$} $\subset$ \GetPPSet{$j_2$},
and $j_1$ is suspended,
then $j_2$'s state space is guaranteed to be strictly larger, so $j_2$ will take at least as long.
Hence, as long as $j_1$ is suspended on account of being too big,
$j_2$ should not be tested either,
unless $j_1$ is later resumed and its ETA improves over time after further execution.
%reveals that it might finish in time after all.
Similarly, whenever a job finds a bug, all pending superset jobs may safely be cancelled,
as they are guaranteed to contain the same program behaviour, and likely to simply find the same bug again.
%
Implementation-wise,
Quicksand receives an updated estimate from each Landslide instance whenever it finishes executing a new interleaving,
and separates them accordingly
into a set of {\em suspended} jobs,
i.e., partially-explored state spaces with high ETAs,
and a set of {\em pending} jobs,
i.e., untested ones with unknown ETAs.
When Landslide reports an ETA too high for some job,
it is compared with other pending and suspended jobs to find another one more likely to complete in time.%
\footnote{Note that when Quicksand is configured to use multiple CPUs,
simultaneously-running jobs are not considered among the set of possible jbos to switch to,
so if there are fewer total jobs with ETA lower than the time budget than the allowed parallelism factor,
some CPUs may end up speculatively running large jobs
in hopes that the ETA turns out to be an overestimate.}

Iterative Deepening also accounts for the inherent inaccuracy of ETA estimates.
Line~1 heuristically scales up the time remaining to avoid suspending jobs too aggressively
in case their ETAs are actually overestimated.
Lines~12-15 account for the
%bizarre
possibility that among two suspended jobs,
%given two jobs,
%%$j_1,j_2$,
\GetPPSet{$j_1$} $\subset$ \GetPPSet{$j_2$}
but
\GetETA{$j_1$} $>$ \GetETA{$j_2$}.
This may seem surprising,
but can often arise because estimates tend to get more accurate over time,
and $j_1$ perhaps ran much longer, on account of being overall smaller,
before becoming suspended.
In such scenarios,
the algorithm heuristically assumes the smaller job's ETA is more accurate,
in order to avoid repeatedly resuming larger jobs briefly only to find that their ETAs keep getting worse and worse
(in other words, it lets us avoid thrashing in Quicksand). % ¯\_(ツ)_/¯

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Heuristics}
\label{sec:quicksand-heuristics}

As predicting the ETAs of state spaces of unknown size
and using that plus size of a set of preemption points as a proxy for how likely a job is to find bugs or complete
is a fundamentally messy process,
it is appropriate to equip the algorithm with some heuristics informed by experience.
\Cref{alg:shouldworkblock} allows the option to heuristically scale a job's ETA
when comparing it to the overall time budget,
which can compensate for any inaccuracy by the estimator.
Quicksand uses a scaling factor defaulting to 2,
chosen based on experiments from prior work \cite{estimation}.
%though we allow changing it via the command line.
It also includes a heuristic to
never suspend jobs before they pass a certain threshold of interleavings tested,
with a default of 32,
informed by my personal experience that ETAs require around that much progress into the state space
before they stabilize (at least relative to each other on similar state spaces,
not necessarily relative to the ultimate true size).%
\footnote{These two heuristics are configurable with the
{\tt -e} and {\tt -E} command-line options, respectively,
as discussed in \cref{sec:landslide-quicksand-options}.}

Landslide classifies data-race candidates as {\em both-order} or {\em single-order},
as defined in prior work \cite{portend},
based on whether it observed the racing instructions ordered in both possible sequences or only one
in the original state space, respectively.
Single-order candidates are more likely to be false positives (\cref{sec:background-datarace}),
although preempting during the access itself is necessary to say for sure.
Hence, Quicskand add preemption points for both types of candidates,
and heuristically prioritizes jobs with both-order data races
over those with only single-order data races.
The HeuristicPriority($\alpha$) call in \Cref{alg:handledatarace} corresponds to this strategy.
For single-order races, Quicksand does not initially add a preemption point for the later access at all:
if preempting on the first access is capable of reordering the race,
it will be updated to both-order in the new state space, and the second preemption point will be added then.
\cref{sec:warpzone-heuristics} will discuss opportunities for future work to expand
these heuristics with more nuanced search strategies still.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Reallocation false positives}
\label{sec:quicksand-id-realloc}

Finally, I identified a particular class of false positive data-race candidates
under the Limited Happens-Before analysis (\cref{sec:background-datarace})
in which the associated memory was recycled by re-allocation between the two accesses,
and claim that it is safe to completely disregard them when considering where to add new preemption points.
Figure~\ref{fig:recycle} shows a common code pattern and interleaving which can expose such behaviour.
If the {\tt malloc} on line~4 returns the same address passed to {\tt free} on line~2,
then lines~1 and 7 will be flagged as a potential data race.
I term this a {\em reallocation false-positive data-race candidiate}.
To the human eye, this is obviously a false positive:
reordering lines~4-7 before lines~1-2 will cause {\tt malloc} to return a different region of allocated memory,
in turn causing {\tt x} and {\tt y} to no longer collide.
In studying a similar pattern, the Eraser tool from prior work \cite{eraser}
found that Thread 2's logic usually corresponds to an initialization pattern,
but for generality I have added an arbitrary {\tt publish} action to the example on line~6.

% TODO: fix syntax hilight
% TODO check figure placement
% TODO check figure camption
\begin{figure}[t]
	\begin{center}
	\begin{tabular}{rll}
		& \multicolumn{2}{c}{\texttt{struct x \{ int foo; int baz; \} *x;}} \\
		& \multicolumn{2}{c}{\texttt{struct y \{ int bar; \} *y;~~~~~~~~~~}} \\
		\\
		& {\bf Thread 1} & {\bf Thread 2} \\
		1 & \texttt{\hilight{brickred}{x->foo = ...;}} & \\
		2 & \texttt{\hilight{olivegreen}{free}(x);} \\
		3 & & \texttt{\hilight{commentblue}{// x's memory reallocated}} \\
		4 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
		5 & & \texttt{\hilight{commentblue}{// ...initialize...}}\\
		6 & & \texttt{publish(y);} \\
		7 & & \texttt{\hilight{brickred}{y->bar = ...;}} \\
	\end{tabular}
	\end{center}
	\caption{A common execution pattern with {\tt malloc()} that produces false positive data race candidates.}
	\label{fig:recycle}
\end{figure}

As long as the allocation heap is properly synchronized,
a Pure Happens-Before analysis should identify a happens-before edge
between line~2's {\tt free} and line~4's {\tt malloc},
and it would report no race.
However, the upcoming evaluation will show that Limited Happens-Before retains some advantages over Pure
(\cref{sec:quicksand-eval-bugs}),
so it is useful to be able to automatically suppress data-race candidates
that are certain to end up being false positives when reordered.
Such collisions could instead be avoided with a hacked allocator which never recycles memory,
but this could unacceptably impact performance in {\tt malloc}-heavy tests.

The ability to disregard reallocation false positives is unique to Iterative Deepening.
When limited to a single test execution, suppressing any data race candidate matching this pattern is unsound.
Consider the more unusual program in Figure~\ref{fig:recycle-bug},
in which the memory is recycled the same way, but the racing access's address is not tied to {\tt malloc}'s return value.
Here, reordering lines~6-7 before line~3 will allow {\tt x} and {\tt x2} to race.
Discarding the data race report as a false positive after checking just this one execution
would overlook such a bug,
but Iterative Deepening is guaranteed to explore the alternate interleaving,
in which the true data race will show up without {\tt free()} and {\tt malloc()} interposing,
so it is safe to suppress at first, as I will prove in \cref{sec:quicksand-realloc}.
Moreover,
in the context of Iterative Deepening, being able to discard certain data race candidates
allows Quicksand to skip exploring some entire state spaces,
and hence run fewer Landslides overall;
this is analogous to DPOR's ability to skip equivalent interleavings within a single Landslide instance.
Upcoming in the evaluation, \cref{sec:quicksand-eval-verif}'s \Cref{tab:drstatistics}
will show how many redundant state spaces Quicksand is able to prune with this technique.

% TODO smae as above
\begin{figure}[t]
	\begin{tabular}{rll}
		& {\bf Thread 1} & {\bf Thread 2} \\
		1 & \texttt{publish(x);} & \\
		2 & \texttt{\hilight{brickred}{x->foo = ...;}} & \\
		3 & \texttt{\hilight{olivegreen}{free}(x);} \\
		4 & & \texttt{x2 = get\_published\_x();} \\
		5 & & \texttt{\hilight{commentblue}{// x's memory recycled}} \\
		6 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
		7 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	\end{tabular}
	\caption{If a single-pass Limited HB analysis discarded candidates matching the malloc-recycle pattern,
it would miss the bug in this adversarial program.}
	\label{fig:recycle-bug}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Soundness}
\label{sec:quicksand-soundness}

Adding new data-race preemption points in a feedback loop can uncover bugs
not previously reachable by preempting on synchronization APIs alone,
as some prior model checkers do \cite{dbug-ssv},
but how does it compare to the other extreme end of the trade-off,
that is,
committing in advance to preempt on every single shared memory access \cite{spin,inspect}?
It turns out,
assuming sufficient CPU budget,
Iterative Deepening can in principle expose every possible program behaviour that
even that latter approach can find,
providing an equally strong verification guarantee.
This section presents a proof of this claim (\cref{sec:quicksand-convergence}),
as well as a supplementary proof (\cref{sec:quicksand-realloc})
of the soundness of pruning reallocation false positives discussed previously (\cref{sec:quicksand-id-realloc}).

I am presenting these proofs as they appeared in the OOPSLA paper \cite{quicksand}:
written as sketches in informal prose,
to optimize for rapidly conveying an intuition for why it works
rather than to justify every internal step within the proof structure.%
\footnote{Also because I am already over 200 pages in this thesis, all told.}
% footnote yeah, i'm writing this last
% footnote of footnote yeah, the committee never read this part
A more rigorous treatment
is available in the tech report which accompanied the conference paper \cite{quicksand-soundness}.

{\bf Assumptions.}
The proofs are built on a DPOR definition which assumes sequentially-consistent memory hardware.
All algorithms involved are assumed to operate on a machine model of a single globally-consistent execution trace,
which fundamentally cannot account for memory reordering nondeterminism.
\cref{sec:quicksand-discussion} discusses this limitation further;
for existing work on combining DPOR with relaxed memory, I refer the reader to \cite{tsopso}.
They also assume the Limited Happens-Before definition
for the data-race analysis.
I leave the case for Pure Happens-Before to future work,
although if I may appeal to intuition,
it requires only to show that for any data-race candidate
Limited Happens-Before reports in a given execution,
that Pure Happens-Before does not,
either it will be a false positive,
or the latter will find it in an alternate execution within the same state space,
or the latter will find a different data race that ultimately leads to a bigger state space in which the first one may be found,
much like a generalization of \cref{sec:quicksand-realloc}.

\subsection{Convergence to total verification}
\label{sec:quicksand-convergence}

The proof of Iterative Deepening's soundness is in two parts.
In the first part, I prove that for any possible interleaving
one could execute with preemptions anywhere,
an equivalent interleaving must exist using only data-race and synchronization preemption points.
In the second, I prove that starting from synchronization preemption points only,
Iterative Deepening must eventually reach a state space containing such an interleaving,
no matter how many data races are involved.

\newcommand\ppnext[1]{\ensuremath{\mathsf{next}(#1)}}
\newcommand\ppinstr[1]{\ensuremath{\mathsf{instr}(#1)}}
\newcommand\ppothers[1]{\ensuremath{\mathsf{others}(#1)}}

Given a preemption point $p$,
let $\ppnext{p}$ denote the next transition after $p$ executed by the thread which ran immediately before $p$,
let $\ppinstr{p}$ denote the first instruction of $\ppnext{p}$,
and let $\ppothers{p}$ denote the transitions by other threads between $p$ and $\ppnext{p}$.

% TODO: decide if these subsection headers are good, or, not
\subsubsection{Equivalence}

\begin{lemma}[Equivalence of non-data-race preemption points]
	For any thread interleaving possible by preempting on any instruction,
	there exists an equivalent interleaving which uses only data-race and synchronization API preemption points.
        \label{lem:relevant}
\end{lemma}

\begin{proof}
Let $p$ be the first preemption point in the given interleaving
such that $\ppinstr{p}$ is not a data race with $\ppothers{p}$ nor is a synchronization API boundary.
Because $\ppinstr{p}$ is not a synchronization boundary,
no lock can be held during $\ppothers{p}$ that was also held by the first thread across $p$.
Hence, because $\ppinstr{p}$ is not a data race, it cannot be a shared memory conflict with $\ppothers{p}$ at all.
Let $i$ be the first instruction among $\ppnext{p}$ which is such a conflict, or a synchronization boundary.
If $i$ is a shared memory conflict, it must be a data race, for the same reasoning as above.
Modify the input interleaving by reordering $\ppinstr{p}$ until $i$, not including $i$, to before $\ppothers{p}$.
% TODO: fix this handwavey citation to at least point to something that says what soundness of dpor means
By the soundness of DPOR \cite{dpor}, this is equivalent to the input interleaving.
In other words, $p$ has been transformed into $p'$ such that $\ppnext{p'} = i$,
which is a data race or synchronization boundary.
All other preemption points in the input trace can be inductively converted in the same manner.
\end{proof}

\subsubsection{Saturation}

For Iterative Deepening to ``eventually'' reach a certain state space,
all data-race preemption points involved must be {\em reachable} during the test.

\begin{definition}[Reachability]
	A data race candidate, and its associated preemption point(s),
	are reachable if it will be identified by a model checker
	configured to preempt only on already-reachable preemption points.
\end{definition}

Initially, the statically-available synchronization API preemption points (\cref{sec:quicksand-initial-pps})
are reachable.
Reachability of data-race preemption points is transitive.

\begin{lemma}[Saturation of data races]
        Given any interleaving comprising only data-race and synchronization API preemption points,
        all involved preemption points are reachable.
        \label{lem:saturation}
\end{lemma}

\begin{proof}
Induct on the preemption points according to the order of their preemptions during an execution sequence.
Given that the interleaving prefix preceding some point $p$ is reachable,
the proof goal is that either $p$ be reachable,
or a new data race among $\ppothers{p}$, not previously reachable, be newly reachable.
The latter condition suffices because in a finitely-sized codebase,
there must be finitely many unique racing instruction pairs.
%, so induction on the number of new data-race preemption points among $\ppothers{p}$ will make $p$ itself reachable.

First, $p$ must be ``coalesced'' away, as well as any other not-yet-reachable points in $\ppothers{p}$.
Consider the alternate interleaving in which the first thread executes past $p$ until the first already-reachable point,
then the other threads among $\ppothers{p}$ execute the same way.
This interleaving's preemption points are all reachable,
so a state space $\mathcal{S}$ containing it will be tested.

If $p$ is a not-yet-reachable data-race preemption point,
it must be possible for some other thread to execute a data-racing instruction with $\ppinstr{p}$.
If this conflict was observed in the state space containing our coalesced interleaving, $p$ is reached.
Otherwise, appeal to the soundness property of DPOR:
%(\cref{sec:landslide-dpor}): % FIXME ugh, this section reference is so handwavy/imprecise
If a program behaviour is possible by interleaving threads at the boundaries of the given transitions,
it will be tested in the containing state space.
By contrapositive, to expose this behaviour,
one or more preemptions must occur in the middle of some transition, rather than at the boundaries.

Let us now see by contradiction that there cannot be {\em multiple} data-race preemption points
which must all be enabled before either data race can be identified;
i.e., a circular dependency.
Assume there does not exist a single transition $t_1 \in \mathcal{S}$
which alone can be split into $\{t_1',t_1''\}$ by a point $q$,
such that another thread's concurrent transition $t_2$ conflicts with $t_1''$.
By the soundness of DPOR, because all $t_2$s are independent with $t_1''$, $\mathcal{S} \equiv \mathcal{S} \cup q$.
Replacing $\mathcal{S}$ with $\mathcal{S} \cup q$ in the above assumption shows that no {\em pair} of new $q$s would expose new program behaviour, and inductively, no set of $q$s of any size, which contradicts the previous paragraph.
%
Hence, a single new not-yet-reachable data race is reachable in $\mathcal{S}$. Hence $p$ will be reached.
\end{proof}

\subsubsection{Convergence}

I name the overall soundness property ``convergence''
in reference to the way it must eventually arrive,
after potentially many iterated state spaces,
at full verification strength.

\begin{theorem}[Convergence]
	If a bug can be exposed by any thread interleaving possible
	by preempting on all instructions during a specific test,
	Iterative Deepening will eventually test an equivalent interleaving which exposes the same bug.
        \label{thm:convergence}
\end{theorem}

\begin{proof}
	For any possible interleaving,
	Lemma \ref{lem:relevant} provides an equivalent one with only data-race and synchronization preemption points,
	and Lemma \ref{lem:saturation} proves all involved preemption points are reachable.
	Hence, Iterative Deepening will eventually test a state space containing the equivalent buggy interleaving.
\end{proof}

And thus Iterative Deepening is sound. % :)

\subsection{Suppressing reallocation false positives}
\label{sec:quicksand-realloc}

Next I prove that \cref{sec:quicksand-id-realloc}'s optimization
of discarding reallocation false positives is sound under Iterative Deepening.

\begin{theorem}[Soundness of eliminating reallocation data-race candidates]
        If a reallocation candidate is not a false positive,
DPOR will reorder threads such that
%DPOR will test an alternate thread interleaving in which
either
the accesses can race without fitting the reallocation pattern,
or a use-after-free bug will be reported immediately.
\end{theorem}

\begin{proof}
Any such program must contain an access $a_1$ by one thread T1,
followed by a {\tt free} and a {\tt malloc} possibly by either thread,
followed by an access $a_2$ by the other thread T2,
not depending on the result of the middle malloc.
Without loss of generality, fix T1 to perform the {\tt free} and T2 the subsequent {\tt malloc},
as shown in \Cref{fig:recycle-bug}.
The other cases are similar,
although note that if T2 performs the {\tt free},
and the {\tt malloc} is reordered before it,
T2's final access will be a use-after-free immediately.
Let us also assume the only way for the program to get pointers to heap memory is through {\tt malloc};
hence, there must also be some ``publish'' action $p$ by T1 which communicates the address to T2.
Because this is a true potential data race,
$p$ must occur before $a_1$, as $a_2$ cannot be reordered before $p$.

The proof goal is that a preemption point be identified during T1 between $p$ and $a_1$.
The publish action must involve some thread communication,
whether through a shared data structure or message-passing API.
If locking or message-passing is used, the set of static synchronization preemption points
(\cref{sec:quicksand-initial-pps})
suffices to provide one.
Otherwise, $p$ (and the corresponding read by T2) will be a potential data race,
although that may itself be another reallocation candidate.
In this case, apply induction on the chain of pointers, if any, leading to the shared address containing $p$:
in the base case, $p$ is communicated via global data or message-passing,
and in the inductive step, DPOR will reorder threads sufficiently to identify a preemption point on $p$.
% the below feels kinda shaky :\ don't remember exactly how this works
% but if someone doubts, they can check out the TR
Note that this induction may result in several possible intermediate preemption points,
each requiring a new state space to be tested,
of course, \Cref{thm:convergence} guarantees this under Iterative Deepening.
Hence there will be a preemption point between $p$ and $a_1$ no matter the mode of communication.

With this preemption point,
DPOR will reorder $a_2$ before $a_1$, while not changing $a_2$'s location.
As T2's {\tt malloc} now occurs before T1's {\tt free}, it will allocate different memory.
Hence $a_1$ and $a_2$ %will be in the same allocation;
can race without appearing to fall under the reallocation pattern.
\end{proof}

This spells QED so we are done \cite{vargomax}. % even more :)))
Note that this proof does not rely on the existence of preemption points on
the internal lock of {\tt malloc} or {\tt free},
which is an ideal candidate to ignore via {\tt without\_function} (\cref{sec:landslide-pps})
to reduce state space size.
Future work may generalize this proof structure to not rely on specific knowledge
of {\tt malloc()}'s and {\tt free()}'s behaviour,
but instead to require only any intervening synchronization event,
thereby extending the overall soundness proof to accomodate Pure Happens-Before as well as Limited Happens-Before.
The experiments in future chapters of this thesis will assume that this holds.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation}
\label{sec:quicksand-implementation}

Quicksand is an independent program that wraps the execution of several stateless model checker instances.
It is expected that Landslide be this checker,
but any other tool which implements the same messaging interface would be compatible as well.
The implementation is roughly 3000 lines of C.
All source files mentioned in this section live in the {\tt id/} subdirectory of the Landslide repository,
with the exception of the Landslide extensions listed last.
As \Cref{chap:landslide} was in some sense a developer's guide to Landslide,
this section will serve similarly for Quicksand.

\subsection{User interface}

The available command-line options for configuring its
CPU-time budget, exploration modes, and so on
are listed in \cref{sec:landslide-quicksand-options}.
Additionally, Quicksand periodically issues a progress report
at fixed intervals to inform the user on the completion, bug-finding, and/or estimated progress of each job.
\Cref{fig:quicksand-progress} shows an example.
I highlight a few notable features of the jobs therein
to serve as a concrete example that may cement the reader's intuition
of \cref{sec:quicksand-id}'s more abstract algorithm descriptions:
\begin{itemize}
	\item Jobs 0, 1, 2, and 3 are the initially-seeded state spaces (\cref{sec:quicksand-initial-pps}).
	\item Job 2 reports a bug found, and shows the filename of the HTML preemption trace
		(\cref{sec:landslide-bugreport}, \Cref{fig:bugreport})
		which the user should examine to diagnose it.%
		\footnote{I actually cheated by copy/pasting this job alone from a different run of Quicksand;
		the other jobs come from a test with the bug already fixed,
		in order that exploration progress far enough to defer some jobs for the sake of example.
		In a real execution, jobs 3, 5, 7, 8, 9, and 11 would be cancelled.}
	\item Jobs 4 and 6 are the ``small'' jobs added to test the two data races in isolation;
		5 and 7 are the corresponding ``large'' jobs (\cref{sec:quicksand-dr-pps}).
	\item Job 11 is the maximal state space, containing all synchronization preemption points
		and both currently-known data races.
	\item The intermediate jobs 8, 9, and 10 have been suspended for having ETAs
		at least twice as large as the provided CPU budget (1 hour),
		according to the ETA scaling factor heuristic (\cref{sec:quicksand-heuristics}).
	\item Note that job 11's ETA is currently lower than 8's, 9's, and 10's, despite being a strict superset of each.
		This corresponds to the surprising ETA inversion situation discussed in \cref{sec:quicksand-choosing}:
		Quicksand simply hasn't made as much progress into job 11 (compare their percentage estimates rather than ETAs)
		for its ETA to be accurate enough yet.
\end{itemize}
Future work could extend these progress reports to be more interactive,
allowing the user to reprioritize state spaces at her whim
or to disable certain data-race preemption points after checking them by hand,
as discussed in \cref{sec:future-friendly}.

% TODO: syn hi
\begin{figure}[t]
	\begin{center}
		\footnotesize
	\begin{tabular}{l}
			% version from buggy run
		%\texttt{==== PROGRESS REPORT ====} \\
		%\texttt{total time elapsed: 40s} \\
		%\texttt{[JOB 0] COMPLETE (4 interleavings tested; 7s elapsed)} \\
		%\texttt{       PPs: \{ \}} \\
		%\texttt{[JOB 1] Running (10.677083\%; ETA 2m 15s)} \\
		%\texttt{       Log: id/ls-output.log.ujrk9U -- PPs: \{ 'mutex\_lock' \}} \\
		%\texttt{[JOB 2] BUG FOUND: landslide-trace-1544661430.29.html (51 interleavings tested; 1 preemptions)} \\
		%\texttt{       Log of lprintf()s: id/ls-setup.log.7UMGLr} \\
		%\texttt{       Log: id/ls-output.log.3Ol8rG -- PPs: \{ 'mutex\_unlock' \}} \\
		%\texttt{[JOB 3] CANCELLED} \\
		%\texttt{       PPs: \{ 'mutex\_lock' 'mutex\_unlock' \}} \\
		%\texttt{[JOB 5] COMPLETE (4 interleavings tested; 7s elapsed)} \\
		%\texttt{       PPs: \{ 'data race 5@ 0x1000ec5' \}} \\
		%\texttt{[JOB 13] Setting up...} \\
		%\texttt{       PPs: \{ 'data race 6@ 0x1000ec5' \}} \\
		%\texttt{[JOB 14] Pending...} \\
		%\texttt{       PPs: \{ 'mutex\_unlock' 'data race 6@ 0x1000ec5' \}} \\
		%\texttt{=========================} \\

		\texttt{==== PROGRESS REPORT ====} \\
		\texttt{total time elapsed: 2m 52s} \\
		\texttt{[JOB 0] COMPLETE (4 interleavings tested; 7s elapsed)} \\
		\texttt{~~~~PPs: \{ \}} \\
		\texttt{[JOB 1] Running (21.932870\%; ETA 8m 14s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' \}} \\
		% version that came from the actual test
		%\texttt{[JOB 2] Running (46.373457\%; ETA 4m 35s)} \\
		%\texttt{~~~~ PPs: \{ 'mutex\_unlock' \}} \\
		\texttt{[JOB 2] BUG FOUND: landslide-trace-1544661430.29.html (51 interleavings tested)} \\
		%\texttt{~~~~Log of lprintf()s: id/ls-setup.log.7UMGLr} \\
		\texttt{~~~~ PPs: \{ 'mutex\_unlock' \}} \\
		\texttt{[JOB 3] Running (9.852431\%; ETA 24m 32s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' 'mutex\_unlock' \}} \\
		\texttt{[JOB 4] COMPLETE (6 interleavings tested; 9s elapsed)} \\
		\texttt{~~~~PPs: \{ 'data race @ 0x102917' \}} \\
		\texttt{[JOB 5] Running (3.710938\%; ETA 1h 2m 14s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x102917' \}} \\
		\texttt{[JOB 6] COMPLETE (4 interleavings tested; 8s elapsed)} \\
		\texttt{~~~~PPs: \{ 'data race @ 0x1000ecf' \}} \\
		\texttt{[JOB 7] Running (6.119792\%; ETA 33m 14s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x1000ecf' \}} \\
		\texttt{[JOB 11] Running (3.670247\%; ETA 50m 16s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' 'mutex\_unlock' 'data race @ 0x102917' 'data race @ 0x1000ecf' \}} \\
		\texttt{[JOB 8] Deferred... (33.340567\%; ETA 2h 6m 3s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_unlock' 'data race @ 0x102917' \}} \\
		\texttt{[JOB 9] Deferred... (34.466226\%; ETA 2h 35m 37s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_unlock' 'data race @ 0x1000ecf' \}} \\
		\texttt{[JOB 10] Deferred... (11.113790\%; ETA 4h 20m 31s)} \\
		\texttt{~~~~ PPs: \{ 'mutex\_lock' 'data race @ 0x102917' \}} \\
		% no, i deleted all of them pretending the other data races dont exist
		%\texttt{And 63 more pending jobs should time allow.} \\
		\texttt{=========================} \\
	\end{tabular}
	\end{center}
	\caption{Example Quicksand progress report showing the various possible job states.}
	\label{fig:quicksand-progress}
\end{figure}

Besides the progress reports, Quicksand also prints a notice for each new data race that Landslide detects,
like so, corresponding to the above progress report, for example:
\begin{center}
	%{\tt Found a racy access at 0x0100006f in txn (410user/progs/htm2.c:47)}
	\begin{tabular}{l}
	{\tt Found a racy access at 0x00102917 in deschedule <unknown>} \\
	{\tt Found a racy access at 0x01000ecf in cond\_signal (cond.c:101)}
	\end{tabular}
\end{center}
If using Limited Happens-Before instead of Pure,
it prints ``potentially-racy access'' instead.
This is implemented in {\tt pp\_new()} in {\tt pp.c}.
If the CPU budget runs out and Quicksand must stop exploring prematurely
(or the user's patience runs out and she interrupts it with ctrl-C),
it prints a final report of all data races it was not able to finish classifying as either buggy or benign,
and urges the user to finish checking them with visual inspection
({\tt print\_live\_data\_race\_pps()} in {\tt pp.c}).
It is this feature which one respondent in the student user survey (\cref{sec:education-reasons-worthwhile})
credited for finding an extra bug.

If the verbose option ({\tt -v}) is supplied,
Quicksand will also print one line per interleaving tested by all its Landslide instances,
showing the number of branches tested so far, the estimated percent progress, and the ETA,
as shown earlier in \cref{sec:landslide-estimate}.
This produces a lot more output, and can make progress reports hard to read as they scroll off the screen quickly,
but the author personally finds this mode less disorienting than ten seconds of pure silence between each progress report.
Of course, future work could improve this with a GUI, or at least a split-screen console view.
It will also cause the progress reports to report more detailed information,
such as which preemption points are nondeterministic data-races (\cref{sec:quicksand-pps})
and number of reallocation false positives suppressed (\cref{sec:quicksand-id-realloc}).

\subsection{Model checker interface}
\label{sec:quicksand-impl-mc}

The interface with the model checker has two parts.
First, when starting each job, Quicksand creates a configuration file declaring which preemption points to use,
plus other test-case-specific options such as
which preemption points to suppress (\cref{sec:landslide-pps}),
especially those arising from the {\tt malloc} lock (\cref{sec:quicksand-realloc}),
which functions DPOR and data-race analysis should treat as trusted code (\cref{sec:landslide-config-landslide}),
whether to enable mutex-testing mode (\cref{sec:landslide-dynamicconfig}),
transactional memory (\cref{sec:tm-implementation}),
and so on.
This is done by {\tt run\_job()} in {\tt job.c}.

Then, a dedicated Quicksand thread
({\tt start\_job()} in {\tt job.c})
communicates with the MC process via message-passing
over a FIFO pipe % not gonna cite io.c c.c
({\tt talk\_to\_child()} in {\tt messaging.c}).
Landslide messages after testing each interleaving to report updated progress and ETAs
as well as whenever a new data-race candidate or bug is found.
Quicksand in turn replies whether to resume/suspend (due to too high ETA) or quit (due to timeout)
({\tt handle\_should\_continue()} in {\tt messaging.c}).
It suspends jobs simply by making Landslide wait on a message-passing reply.
Should Quicksand later re-schedule a suspended job, it sends a message to continue,
resuming Landslide right where it left off;
otherwise, it wakes it up only after time runs out, causing it to exit immediately.
The message-passing format is defined at the top of {\tt messaging.c},
and a matching definition appears in Landslide's source file of the same name.

\subsection{Architecture}

Quicksand's overall architecture is a thread pool of workers,
one for each CPU it was configured to use with {\tt -c} (\cref{sec:landslide-quicksand-options}).
These threads do not correspond directly to each active instance of Landslide,
as some may be deferred;
rather, each worker thread links up temporarily to a job thread, whose duties the previous paragraph describes,
and process them as the overall work-queue of state spaces to be tested demands.
Following is a brief description of each of Quicksand's major modules.

\begin{itemize}
	\item {\bf Job management} ({\tt job.c}):
		Contains the lifecycle code for job threads,
		generation of Landslide configuration files,
		and Linux process management code to launch child Landslide instances ({\tt run\_job()}).
	\item {\bf Messaging} ({\tt messaging.c}):
		Manages communication with child Landslides ({\tt talk\_to\_child()},
		implementing certain aspects of Iterative Deepening,
		creating new jobs in response to data race reports ({\tt handle\_data\_race()})
		and deferring too-big jobs in reponse to ETA updates  ({\tt handle\_estimate()}).
	\item {\bf Preemption point registry} ({\tt pp.c}):
		Tracks the set of known synchronization primitives (initialized by main)
		and data races ({\tt pp\_new()}),
		including set comparison routines ({\tt pp\_subset()})
		and computing a job's priority based on the types of included preemption points ({\tt unexplored\_priority()}).
	\item {\bf Workqueue} ({\tt work.c}):
		Implements the per-CPU worker threads,
		including the check for whether to switch priority from one job to another
		(\Cref{alg:shouldworkblock}, {\tt should\_work\_block()} and {\tt get\_job()}),
		as well as managing the shared workqueue of jobs overall ({\tt workqueue\_thread()}).
		Also implements the fixed-interval progress reporting ({\tt progress\_report\_thread()}).
	\item {\bf Bugs} ({\tt bug.c}):
		Tracks a list of found bugs for main to repeat at program exit,
		and implements the check for superset state spaces to be cancelled if a subset already found a bug
		({\tt bug\_already\_found()}).
	\item {\bf Options} ({\tt option.c}):
		Processes command-line options,
		checking for legality of various combinations of exploration modes.
		New options may be added with the convenient, if scarily-implemented,
		macros {\tt DEF\_CMDLINE\_FLAG()} and {\tt DEF\_CMDLINE\_OPTION()}.
	\item {\bf Main} ({\tt main.c}):
		Initializes the default state spaces,
		waits for worker threads to terminate after either completion or time-out,
		and issues a final list of bug reports, data race reports, or congratulations as appropriate.
\end{itemize}

Finally, because in very large tests,
the number of suspended Landslide instances may grow without abatement,
Quicksand checks every progress report interval whether the memory footprint of these inactive Landslides
pose a threat to the system's total memory.
Implemented in {\tt cant\_swap()} \cite{cant-stop} in {\tt work.c},
it checks if the system's memory usage exceeds a fixed percentage of its total
({\tt RAM\_USAGE\_DANGERZONE}, default 90),
and if so,
abandons a fixed percentage of suspended Landslides
({\tt KILL\_DEFERRED\_JOBS}, default 50).
%
Generally, the currently-running Landslide instances should never threaten to hit swap,
as there can only be as many of those as CPUs,
but this also accounts for memory used by other processes,
so this is not guaranteed to avoid swapping on a heavily-stressed system
(such as running multiple Quicksands at once).
Naturally, if Quicksand ever needs to invoke this protocol,
any hope at a total verification is compromised.

\subsection{Exploration modes}
\label{sec:quicksand-impl-modes}

In addition to Iterative Deepening,
which Quicksand defaults to if no options are given to specify otherwise,
Quicksand also supports several alternate exploration strategies, as follows.

\begin{itemize}
	\item {\bf Single state space, basic DPOR} ({\tt -C}):
		Runs a single instance of Landslide configured to preempt on all statically-known synchronization PPs.
		Corresponds to dBug's approach \cite{dbug-ssv}.
		Never adds any new preemption points based on data race reports.
	\item {\bf Single state space, ICB} ({\tt -I}):
		Runs a single instance of Landslide with preemption points as above,
		but running Iterative Context Bounding with BPOR (\cref{sec:landslide-icb})
		instead of plain DPOR.
		Corresponds to Chess's approach \cite{chess}.
		Requires either {\tt -C} or {\tt -M} (see below).
	\item {\bf Single state space, preempt-everywhere} ({\tt -0}, i.e., numeral zero):
		Runs a single instance of Landslide as above,
		but preempting on every shared memory access, not just synchronization.
		Corresponds to the approach of SPIN \cite{spin} and Inspect \cite{inspect}.
		May optionally be combined with {\tt -I}.
	\item {\bf Maximal state space mode} ({\tt -M})
		Runs the na\"{i}ve version of Iterative Deepening shown in \Cref{alg:algorithm0},
		i.e.,
		immediately abandons any state space whenever a superset of it exists.
		This results in always testing the maximal state space only, with no inherent parallelism,
		and optimizes for the fastest verification when the user has reason to believe no bugs will exist.
		No prior work implements this approach.
		Note that this mode was implemented after \cite{quicksand}'s publication,
		and I will feature it in the evaluation of transactional memory
		(\cref{sec:tm-eval}) rather than in this chapter.
\end{itemize}

Note that Quicksand restricts ICB to be usable only in modes when it is running only one Landslide at a time.
ICB is itself a heuristic search ordering strategy to uncover bugs faster,
so while technically easy to run Iterative Deepening with all jobs thereunder running ICB,
that would suffer both approaches' repeated work compounded.
\cref{sec:warpzone-heuristics} discusses integrating the two approaches to hopefully reap the benefits of both.
However, maximal state space mode does support ICB,
as the former focuses on verification only,
but if the result is a time-out,
the user may find an ICB-style preemption-bounded partial verification useful.

\subsection{Landslide extensions}
\label{sec:quicksand-impl-landslide}

I have added several features to Landslide specifically for use under Quicksand.
Source files mentioned in this subsection live under the usual Landslide source directory.

The other end of the messaging protocol (\cref{sec:quicksand-impl-mc})
is implemented in {\tt messaging.c}.
When Quicksand suspends Landslide,
it detects how much time it spent asleep,
and corrects for that amount during its next ETA computation ({\tt fudge\_time()} in {\tt estimate.c}).
Landslide's data race analysis also includes a heuristic to avoid reporting ``too suspicious''
data-race candidates which it believes arise from the initialization pattern \cite{eraser}:
if a conflicting access pair is single-order (\cref{sec:quicksand-heuristics})
and also arose during a known synchronization API's {\tt init()} or {\tt destroy()} function,
Landslide will not message it to Quicksand,
at least not until it is reclassified as both-order.

To recognize the reallocation pattern
discussed in \cref{sec:quicksand-id-realloc}
during data race analysis,
Landslide includes a generation counter in its heap allocation tracking (\cref{sec:landslide-memory}).
Each heap allocation is given a unique ID,
and when evaluating whether two heap accesses can race,
the IDs of their containing blocks must match
({\tt was\_freed\_remalloced()} in {\tt memory.c}),
in addition to the other requirements of Happens-Before.

Preempt-everywhere mode (\cref{sec:quicksand-impl-modes})
imposes a heavy burden on Landslide on account of the sheer number of preemption points involved.
First of all, because there are separate tracing entrypoints for memory accesses and instructions ({\tt instrument.c}),
it cannot simply invoke the checkpointing routine (\cref{sec:landslide-timetravel}) immediately.
Also, we must still exclude thread-local and kernel (if testing userspace) or user (if testing kernelspace) accesses.
Rather,
the memory analysis (\cref{sec:landslide-memory}) invokes
{\tt maybe\_preempt\_here()} in {\tt pp.c}
for every access it would ordinary record for DPOR.
If the access is outside of the current stack frame,
and not part of the mutexes (unless {\tt TESTING\_MUTEXES}),
this sets a scheduler action flag {\tt preempt\_for\_shm\_here}
which makes preemption point identification treat it the same as a data race (\cref{sec:landslide-pps}).
{\tt check\_withins()} is also modified to never switch to allowlist mode.
Finally,
Landslide increases its heuristic constant for infinite loop detection (\cref{sec:landslide-infloop})
on the first interleaving from 4000 to $2^{20}$,
to account for the increased orders of magnitude in state space size.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evaluation}
\label{sec:quicksand-eval}

\subsection{Finding bugs}
\label{sec:quicksand-eval-bugs}

\subsection{Verification}
\label{sec:quicksand-eval-verif}

\subsection{Nondeterministic data races}
\label{sec:quicksand-eval-nondets}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:quicksand-discussion}

% identifying & skipping redundancies in smaller ID state spaces via memoization (same applies to ICB!)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

quicksand is gr9
