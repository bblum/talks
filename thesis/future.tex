\chapter{Future Work}
\label{chap:warpzone}
\revision{
\inspirationalquote{
	\begin{tabular}{p{0.62\textwidth}}
		"Journey before destination."
		\\
		Some may call it a simple platitude, but it is far more.
		A journey will have pain and failure.
		It is not only the steps forward that we must accept.
		It is the stumbles. The trials. The knowledge that we will fail.
		% That we will hurt those around us.
		\\
		% But
		If we stop, if we accept the person we are when we fall, the journey ends.
		% That failure /becomes/ our destination.
		To love the journey is to accept no such end.
		% I have found, through painful experience,
		% that the most important step a person can take is always the /next/ one.
	\end{tabular}}
{Dalinar Kholin, Oathbringer}
}

Each of the previous three chapters concluded by
discussing specific limitations,
listing concrete and immediate ways to address them
with existing techniques
(\cref{sec:quicksand-discussion},
\cref{sec:education-discussion},
\cref{sec:tm-discussion}).
Meanwhile, this chapter takes a broader interpretation of ``future work'',
namely,
how might future Landslides solve research problems I didn't even pose to begin with.
%The reader looking for their own thesis topic would most likely find it here.
%The reader should beware of wild speculation ahead
%which may assume solutions to extremely difficult problems with a wave of the hand.

\section{User-friendliness}
\label{sec:future-friendly}

In the user study survey (\cref{sec:education-eval-survey}),
students most often complained
that interpreting Landslide's preemption traces to diagnose and understand their bugs was too difficult.
While the understanding step of course requires human intuition,
there is certainly room to improve the diagnosis step beyond just showing the user one static HTML table.
Related works \revisionminor{such as} Symbiosis \cite{symbiosis}
can find a minimal difference between the failing trace and a non-failing one,
which would allow the user to effortlessly pinpoint which preemptions are closest to the true root cause.
Further, using ICB \cite{chess-icb} to show the user a minimum set of preemptions necessary to expose the bug
could help her narrow down possible diagnoses more quickly.
Finally, the preemption trace itself could be interactive,
allowing the user to click and drag to reorder thread transitions and see how the interleaving would change,
or to click and drag preemption points across the source code to figure out how much need to be atomic.

State space size management remains an issue, as ever.
While Quicksand's professed selling point is that the user need input only a CPU budget,
at the same time,
pruning uninteresting branches out of the overall state space
would allow Quicksand to achieve more meaningful results in that same budget.
Theoretical advances in state space reduction come out every year (\cref{sec:related-algs}),
but the user's human intuition can also contribute if properly encouraged.
For the P2 tests (\cref{sec:education-pebbles-tests}),
I configured Quicksand by hand to issue appropriate {\tt without\_function} commands to Landslide
(\cref{sec:landslide-pps}),
and even more still for the HTM tests (\cref{sec:tm-eval-exp-setup}),
but a user writing her own tests would have to configure DPOR by hand.
A more mature version would coach the user to decide which functions focus the test on,
using state space estimation to give an idea of expected testing time,
and listing the variables/locations of DPOR's memory conflicts
to help her identify more candidate functions to potentially ignore.
% there are a LOT of "hmm"s here for future research to address
% most basically like, a modification could have a side effect that would lead to changed behaviour
% arising from a preemption in a *subsequent* function
% so really this can't be limited to just PPs in the changed functions, but dataflow arising therefrom as well
Finally, Landslide could integrate with a version control system to do incremental testing,
automatically analyzing the functions touched by each patch,
and heuristically prioritizing preemption points therein
to quickly check small updates on top of an already-verified codebase.

%\section{Test cases}
\section{Verification}
\label{sec:warpzone-verif}

In its current form, Landslide is limited to testing only those behaviours that the test case it's hooked up to can generate.
The most obvious limitation of this is resource exhaustion scenarios:
stateless model checking simply cannot handle tests long-running enough to exhaust system memory
(succumbing to exponential explosion long before),
% "involve" here, for subjunctive?
so cannot exercise any flow control that involves {\tt malloc()} failing, for example.
This specific issue could be solved using by-hand annotations to block all preemption points until just before exhaustion,
%(requires model-checking expertise on the programmer's part)
or by extending Landslide to inject allocation failures at {\tt malloc()} callsites (akin to {\tt \_xbegin()}).
%(assumes certain behavioural properties of the allocation library).
However,
these require the user to realize in advance that she should worry about allocation-failure bugs,
and to configure Landslide specifically to target them.
In general, a mature testing tool should not require the user to
know in advance where her bugs might be
before being able to conduct an effective test.
%
In future work, a stateless model checking framework could collaborate with its user to semi-automatically design better tests.
% i hate the way maple actually does it, in principle, but i need to cite smth here
Concurrency coverage metrics such as proposed by Maple \cite{maple}
% wild speculation
could be extended to capture possible behaviours under any test input,
not just within the fixed state space under one given test,
and symbolic execution frameworks such as Contessa~\cite{contessa}
could search for possible inputs to suggest changes which might expose them.
In cases where not-yet-covered conditional branches require
certain function return values,
such as {\tt malloc()} failing,
the tool could offer to add failure injection with the user's approval,
or at least prompt her to write a new test with that as a subgoal.

In the case study of submitted P2 bugs (\cref{sec:education-eval-bug-case-study}),
I noticed several submissions of a common pattern
in which Landslide overlooked the {\tt thr\_exit()} use-after-free bug:
they all manually recycled the exited thread's stack using an internal free-list,
rather than calling {\tt free()} or {\tt remove\_pages},
so Landslide's heap-checker failed to see anything out of the ordinary about the subsequent writes to it.
Explicit annotations about the custom free-list's invariants could make Landslide treat it like {\tt free()}
and catch the errant write,
but that begs the question of knowing about the bug in advance.
Catching this bug would require extending the test case to {\tt thr\_fork()} a new thread
to reuse the old stack and suffer data corruption from the stray write.
In this case, the user might happen to find this just by increasing the number of threads/iterations,
which is just good testing practice,
but in general, automatically inferring such data structure invariants
to suggest better assertions
% is this true??
remains an open problem.
Future work might combine Landslide's ability to prove correctness for finite $K,N$ parameters
with a formal induction proof that generalizes the result,
finding a minimum number of threads necessary to expose all behaviours
(at least \revisionminor{three} in this example),
% 2 papers rec'd from https://twitter.com/bblum0/status/1018233122750640130
% although i checked these & couldn't figure out how if at all they were doing generalization
although I know of no related work which addresses the second half of this problem.
Likewise, \cref{sec:tm-abstraction}'s abstraction reduction requires the user
to believe that {\tt lock}({\tt spinlock}) and friends correctly express the mutual exclusion property in informal code%
\footnote{In \Cref{fig:htm-lock}(a), the
{\tt \flow{if} (!\call{\_xtest()}) \call{thr\_yield}(\const{-1});}
part required expert knowledge of HTM semantics to write correctly:
an unconditional yield there
would cause % oops
the transaction to abort every time,
verifying mutual exclusion in the failure path only.}.
Future work could further check such tests against external formal specifications
% better citation? that silly planning assignment of ours even?
%analogously to seL4 \cite{sel4},
to make the abstraction reduction more trustworthy.

%\section{Verification}

As important as Quicksand's convergence theorem (\cref{sec:quicksand-soundness}),
the HTM equivalence proofs (\cref{sec:tm-design}),
and other soundness results from prior work are,
they fall short of fully end-to-end formal verification
in terms of trusting the output of stateless model checkers in practice.
In addition to the issue of test cases,
%discussed above,
there is also currently no guarantee that Landslide's concrete implementation
matches the theoretical properties.
My personal faith in Landslide's implementation comes from years of empirical observation:
inspecting small state spaces
(such as \Cref{fig:retry-reduction})
by hand
to check that preemption points show up in the right places
and that DPOR prunes the expected equivalences;
as well as checking that the relationships between larger state spaces satisfy expected invariants,
such as when testing two sets of preemption points, one a subset of the other,
or testing the same but one with an additional reduction applied,
% this first "the" realllly helps disambiguate the sentence
the one's resulting state space must be smaller than the other's.
Nevertheless, discrepancies may still lurk undiscovered:
the failure injection bug described in \cref{sec:tm-eval-exp-setup}
took until implementing retry set reduction to discover,
well after publishing the first experimental results in \cite{sigbovik-htm}.
As the concurrency model becomes more complex,
more opportunities arise for the implementation to deviate from what the soundness theorem actually proves.
Kernels like seL4 \cite{sel4} and CertiKOS \cite{certikos}
and concurrency-aware compilers like CompCertTSO \cite{compcerttso},
all formally verified against external specifications,
provide important pioneering steps in this direction.%
\footnote{Of course, being verified themselves, these projects have no need for a verified Landslide,
but checking unverified (e.g., student) code with such would still be an improvement.}

\section{Heuristics}
\label{sec:warpzone-heuristics}

% TODO: does this need some estimate progress graphs
% some RE ones would even need a log scale y axis maybe
In my experience,
the WBE algorithm (used in Landslide for estimating number of interleavings) consistently underestimates,
being often seen to count (nearly) monotonically up toward the true value as exploration progresses,
while the RE algorithm (used in Landslide for estimating total execution time) can be unstable and erratic,
bouncing wildly among orders of magnitude even in the space of ten or fewer adjacent interleavings.
These flaws are especially visible in the {\tt avl\_fixed} transactional verification results (\Cref{tab:tm-verifs}).
Both estimation algorithms
use the known structure of the tree as a model for the unknown
(see \cref{sec:landslide-estimate}),
but make no use of domain-specific knowledge such as which threads were chosen to run at each preemption point.
For example, consider the root of the left subtree in \Cref{fig:tree},
thread 1's \dporTA{{\tt tmp1++}}.
At that moment thread 1 has 1 more instruction left to execute, while thread 2 has 3.
If thread 1's last instruction is chosen to run next,
there can only be one way to run thread 2's 3 steps thereafter (${3+0 \choose 0} = 1$);
if thread 2's first instruction is chosen to run next,
there will be 3 ways to interleave thread 1's last among thread 2's remaining 2 (${2+1 \choose 1} = 3$).
In general, the largest child subtree at any preemption point will be the one resulting from running the thread with the most transitions left,
or more formally, fixing $N+M=C$, ${N+M \choose N}$ is maximized when $N \approx M$.
WBE and RE could both be relatively easily extended to incorporate this observation,
using knowledge from branches already tested to guess (still heuristically) appropriate values for $N$ and $M$.
Predicting more advanced aspects of state space structure,
such as subtrees pruned by sleep set reduction
(\cref{sec:landslide-sleepsets}; $\bigstar$4 in \Cref{fig:dpor-example-2}),
would likely require analyzing DPOR's memory conflicts as well.

There is much room to expand Landslide's use of heuristics to balance verification with fast bug-finding.
Landslide's maximal state space mode (\cref{sec:tm-verif}) currently requires the user to decide in advance
whether she thinks a full verification is possible within the time limit,
and supply {\tt -M} if so,
sacrificing some bug-finding power up front
(or just running the test twice).
Quicksand could make this decision automatically,
always dedicating one of its available CPUs to the maximal state space
while the rest run Iterative Deepening as normal.
Currently, Landslide explores each state space sequentially,
but if extended with Distributed DPOR \cite{parallel-dpor},
Quicksand could also dynamically allocate more or fewer CPUs to the maximal state space according to its ETA.
% ICB incorporations
% into quicksand - when SS estimates are too high, fall back on a preemption bounded version to find bugs - improve the partial verif
% into education - provide more partial verifs to students (but is it clear they'll understand the subtleties of it?)
% into txn - incorporate failure injection into the model
Likewise, Quicksand could
incorporate ICB \cite{chess-icb}
to get the best of both worlds:
when testing smaller data-race jobs,
start them in ICB mode to begin with,
and when the ETAs of larger jobs (including the maximal one) grow too large,
downgrade them to ICB to try to at least get a partial verification for that preemption point set
rather than discarding it entirely.
ICB could also be extended to include HTM failure injections as part of its model,
counting them either as part of the overall preemption bound
or under a separate abort bound.
State space estimation under ICB currently
counts only DPOR's tagged branches that don't get skipped under the preemption bound,
estimating that bound's state space size
and resetting whenever the bound increases;
it could also be extended to be ICB-aware,
counting branches skipped due to the bound separately
and computing two estimates at once,
which would in turn allow Quicksand to make more informed decisions about when to use ICB.

% arugment why ML is NOT appropriate for smc in general -- if you try to train it to choose thread interleavings / search ordering,
% even if you're already in not-enough-cpu-time heuristics land, you're biasing it to find only the types of bugs you've already seen
% and destroying its ability to find novelties
% if your ML provides a partial verification, it is impossible for a human to understand what that verification means

%% commenting this first part out bc it will probably aggro garth...
%As a matter of personal philosophy,
%I would strongly caution against using machine learning to try to expose bugs faster.
Machine learning has become popular recently as a magic cure-all for many programming problems,
but is also notorious for amplifying any biases in its training set
(or in the minds of its developers)
in unpredictable ways
that have been shown to harm people of color \cite{conceptnet-bias,gender-shades},
women \cite{gender-bias-ai,amazon-ai},
and transgender people \cite{misgendering-machines}.
In the domain of concurrency testing,
%careless application of
such bias would be unlikely to result in interpersonal discrimination,
but
%I believe
it would translate to
%being able to find
finding only types of bugs
already seen in the training data,
abandoning any novel bug patterns to further obscurity.
Granted,
Iterative Deepening and
ICB also deprioritize ``deeper'' bugs,
as measured by number of unique or total preemptions, respectively,
%in terms of minimum necessary preemption count,
%but this strategy is informed by empirical evidence
%% TODO: upgrade citation to also have a section reference to that icb bound table from quicksand eval
%\cite{chess-icb},
%and
but when a bug is not found
these strategies also enable the user to understand the nature of the partial verification.
%
Machine learning would be more appropriate for improving state space estimation,
whose output is already a black-box oracle from the user's perspective,
and where the worst case of being wrong
is that Quicksand prioritize its jobs suboptimally. % subjunctive
In-progress estimates fluctuate depending on many factors,
such as interleaving-dependent flow control,
and I suspect deeper patterns may exist among multiple different state spaces,
for example,
from the same test program with different $K,N$ parameters.
For any future researchers who wish to study such patterns,
% with machine learning... don't feel like i can do justice to discussing its flaws with real citations
I have made the estimation logs from the HTM experiments (\cref{sec:tm-eval})
freely available at \url{https://github.com/bblum/thesis-htm-logs}.
%
Nevertheless,
I firmly believe that using machine learning as a bug-finding heuristic
without compensating extremely carefully for its inherent biases
would run counter to this thesis's central tenets of transparency and user agency.
Any overall search heuristic
%for concurrency testing
must be designed to support the human user first and foremost,
that she may readily understand partial verification results
and participate effectively in the test case refinement strategies discussed
upchapter. % this is a word now.

%%%%

% not gonna bother with this

% in the maximal state space, the "tag all evil ancestors" thing justified in my MS thesis figure 31337
% is not necessary, bc if it's the maximal state space, you know that data race PPs would separate the accesses in C1/C2/C3.
% but, actually figuring out if you're in the maximal state space on-the-fly to justify not tagging?
% (but but, does this even matter, is this an optimization at all?)
% i'm actually not even sure this would be sound even on maximal, because of RMW instructions, their 2 evence are inseparable

