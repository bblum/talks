\chapter{Future Work}
\label{chap:warpzone}
% TODO: ask for permission for this one
% https://twitter.com/Poem4your_sprog/status/878747092788838400
\inspirationalquote{
\begin{tabular}{p{0.51\textwidth}}
A little bit of being kind,
a tiny open door; \\
A nicer slice of peace of mind
begets a little more. \\
It won't correct the world tonight,
nor change tomorrow too; \\
But maybe if you do it right,
you'll find it changes you.
\end{tabular}}
{Sam "Poem\_for\_your\_sprog" Garland}

Each of the previous three chapters concluded by
discussing specific limitations,
listing concrete and immediate ways to address them
with existing techniques
(\sect{\ref{sec:quicksand-discussion}},
\sect{\ref{sec:education-discussion}},
\sect{\ref{sec:tm-discussion}}).
Meanwhile, this chapter takes a broader interpretation of ``future work'',
namely,
how might future Landslides solve research problems I didn't even pose to begin with.
%The reader looking for their own thesis topic would most likely find it here.
%The reader should beware of wild speculation ahead
%which may assume solutions to extremely difficult problems with a wave of the hand.

\subsubsection{User-friendliness}

In the user study survey (\sect{\ref{sec:education-eval-survey}}),
students most often complained
that interpreting Landslide's preemption traces to diagnose and understand their bugs was too difficult.
While the understanding step of course requires human intuition,
there is certainly room to improve the diagnosis step beyond just showing the user one static HTML table.
Related works like Symbiosis \cite{symbiosis} can find a minimal difference between the failing trace and a non-failing one,
which would allow the user to effortlessly pinpoint which preemptions are closest to the true root cause.
Further, using ICB \cite{chess-icb} to show the user a minimum set of preemptions necessary to expose the bug
could help her narrow down possible diagnoses more quickly.
Finally, the preemption trace itself could be interactive,
allowing the user to click and drag to reorder thread transitions and see how the interleaving would change,
or to click and drag preemption points across the source code to figure out how much need to be atomic.

State space size management remains an issue, as ever.
While Quicksand's professed selling point is that the user need input only a CPU budget,
at the same time,
pruning out the overall state space would allow Quicksand to achieve more meaningful results in that same budget.
Theoretical advances in state space reduction come out every year (\sect{\ref{sec:related-algs}}),
but the user's human intuition can also contribute if properly encouraged.
For the P2 tests (\sect{\ref{sec:education-pebbles-tests}}),
I configured Quicksand by hand to issue appropriate {\tt without\_function} commands to Landslide
(\sect{\ref{sec:landslide-pps}}),
and even more still for the HTM tests (\sect{\ref{sec:tm-eval-exp-setup}}),
but a user writing her own tests would have to configure DPOR by hand.
A more mature version would coach the user to decide which functions focus the test on,
using state space estimation to give an idea of expected testing time,
and listing DPOR's memory conflicts to help her identify more candidate functions to potentially ignore.
% there are a LOT of "hmm"s here for future research to address
% most basically like, a modification could have a side effect that would lead to changed behaviour
% arising from a preemption in a *subsequent* function
% so really this can't be limited to just PPs in the changed functions, but dataflow arising therefrom as well
Finally, Landslide could integrate with a version control system to do incremental testing,
automatically analyzing the functions touched by each patch,
and heuristically prioritizing preemption points therein
to quickly check small updates on top of an already-verified codebase.

\subsubsection{Test cases}

In its current form, Landslide is limited to testing only those behaviours that the test case it's hooked up to can generate.
The most obvious limitation of this is resource exhaustion scenarios:
stateless model checking simply cannot handle tests long-running enough to exhaust system memory
(succumbing to exponential explosion long before),
% "involve" here, for subjunctive?
so cannot exercise any flow control that involves {\tt malloc()} failing, for example.
This specific issue could be solved using by-hand annotations to block all preemption points until just before exhaustion,
%(requires model-checking expertise on the programmer's part)
or by extending Landslide to inject allocation failures at {\tt malloc()} callsites (akin to {\tt \_xbegin()}).
%(assumes certain behavioural properties of the allocation library).
However,
these require the user to realize in advance that she should worry about allocation-failure bugs,
and to configure Landslide specifically to target them.
In general, a mature testing tool should not require the user to
know in advance where her bugs might be
before being able to conduct an effective test.

In future work, a stateless model checking framework could collaborate with its user to semi-automatically design better tests.
% i hate the way maple actually does it, in principle, but i need to cite smth here
Concurrency coverage metrics such as proposed by Maple \cite{maple}
% wild speculation
could be extended to capture possible program behaviours under any test input,
not just within the fixed state space under one given test,
and symbolic execution frameworks such as Contessa \cite{contessa}
could search for possible test inputs to suggest changes to the test case which might expose them.
In cases where not-yet-covered conditional branches require
certain function return values,
such as {\tt malloc()} failing,
the tool could offer to add failure injection with the user's approval,
or at least prompt her to write a new test with that as a subgoal.

In the case study of submitted P2 bugs (\sect{\ref{sec:education-eval-bug-case-study}}),
I noticed several submissions of a common pattern
in which Landslide overlooked the {\tt thr\_exit()} use-after-free bug:
they all manually recycled the exited thread's stack using an internal free-list,
rather than calling {\tt free()} or {\tt remove\_pages},
so Landslide's heap-checker failed to see anything out of the ordinary about the subsequent writes to it.
Explicit annotations about the custom free-list's invariants could make Landslide treat it like {\tt free()}
and catch the errant write,
but that begs the question of knowing about the bug in advance.
Catching this bug would require extending the test case to {\tt thr\_fork()} a new thread
to reuse the old stack and suffer data corruption from the stray write.
In this case, the user might happen to find this just by increasing the number of threads/iterations,
which is just good verification principles,
but in general, automatically inferring such data structure invariants
to suggest better assertions
% is this true??
remains an open problem.

% test case design, writing code that actually checks the properties you're interested in
% for example the mutex test, with the if (!xtest) yield check
% then even after you got the right properties, optimizing the state space
% with without_function, ignore_sym, etc, while preserving the guarantee

\subsubsection{Verification}

% soundness concerns - the xbegin/delay-xbegin pp soundness bug popped up in the implementation, despite the soundness thm
% current SoA for this is to manually inspect the state spaces that arize for small K,N and just hope...
% as concurrency model becomes more complex, more opportunities for the implementation to deviate from what
% the soundness theorem actually proves
% how to prove landslide is actually doing what you think? analogous to sel4 spec/impl verif...

% extending landslide's verification for a limited nr of K N to infinite with induction/proof assistance

% - this should prob go in quicksand chapater
% identifying & skipping redundancies in smaller ID state spaces via memoization (same applies to ICB!)

% arugment why ML is NOT appropriate for smc in general -- if you try to train it to choose thread interleavings / search ordering,
% even if you're already in not-enough-cpu-time heuristics land, you're biasing it to find only the types of bugs you've already seen
% and destroying its ability to find novelties
% if your ML provides a partial verification, it is impossible for a human to understand what that verification means

\subsubsection{Heuristics}

In the author's experience,
the WBE algorithm (used in Landslide for estimating number of interleavings) consistently underestimates,
being often seen to count (nearly) monotonically up toward the true value as exploration progresses,
while the RE algorithm (used in Landslide for estimating total execution time) can be unstable and erratic,
bouncing wildly among orders of magnitude even in the space of ten or fewer adjacent interleavings.
These flaws are especially visible in the {\tt avl\_fixed} transactional verification results (Table~\ref{tab:tm-verifs}).
% TODO: simpler approach would be to account for like, "T1->T1" prefix subtree likely to be smaller than "T1->T2" prefix subtree
% because T1->T1->... means T1 has 2 fewer events left to schedule and (M+N-2 choose M-2) tends to be smaller than (M+N-1 choose M-1)
% for roughly similar M/N;
% estimator could account for this somehow... not sure how but
% likewise, estimator could account for retry sets by checking the size of the retry set and multiplying by 1/4 or 1/2 or w/e
% TODO: cite smth about machine learning
% TODO: publish the htm evaluation logs
% state space estimation could probably be drastically improved with machine learning
% accordingly, all the state space estimate logs (ie, quicksand logs) from the tsx chapter are made open-source on so-and-so

% ICB incorporations
% into quicksand - when SS estimates are too high, fall back on a preemption bounded version to find bugs - improve the partial verif
% into education - provide more partial verifs to students (but is it clear they'll understand the subtleties of it?)
% into txn - incorporate failure injection into the model

%%%%

% not gonna bother with this

% in the maximal state space, the "tag all evil ancestors" thing justified in my MS thesis figure 31337
% is not necessary, bc if it's the maximal state space, you know that data race PPs would separate the accesses in C1/C2/C3.
% but, actually figuring out if you're in the maximal state space on-the-fly to justify not tagging?
% (but but, does this even matter, is this an optimization at all?)
% i'm actually not even sure this would be sound even on maximal, because of RMW instructions, their 2 evence are inseparable

